{"version":3,"sources":["00-nav.js","01-header.js","03-page-versions.js","04-mobile-navbar.js","05-highlight.js","06-clipboard.js","07-on-this-page.js","08-lunr.js","09-search.js"],"names":["expandParents","element","panel","parentNode","matches","parentHeader","previousElementSibling","classList","remove","querySelector","add","Array","from","document","querySelectorAll","pop","select","versionVar","versions","getVersions","Object","entries","forEach","component","componentName","componentVersionIndex","componentSelectVersion","selectedIndex","setComponentVersion","options","value","i","length","getAttribute","setVersions","window","sessionStorage","setItem","JSON","stringify","parse","getItem","version","showSelector","hideSelector","navShow","s","addEventListener","event","this","versionIndex","disabled","x","mdc","ripple","MDCRipple","attachTo","target","item","parentElement","nextElementSibling","contains","navToggle","getElementById","iconButton","MDCIconButtonToggle","mainContainer","navContainer","topAppBar","MDCTopAppBar","toggle","selector","e","stopPropagation","documentElement","innerWidth","navbarToggles","prototype","slice","call","el","dataset","hljs","initHighlighting","codeBlocks","copyIcon","createElement","innerText","icon","cloneNode","insertBefore","childNodes","ClipboardJS","text","lines","split","splice","join","on","trigger","_tippy","setContent","tippy","delegate","content","animation","theme","delay","placement","hideOnClick","onHidden","instance","headers","toc","header","li","tagName","setAttribute","h","id","scroll","top","offsetTop","left","behavior","setTimeout","appendChild","referenceElement","activeHeader","lastActiveHeader","referencePoint","getBoundingClientRect","activeId","global","step2list","step3list","v","C","re_mgr0","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","root","factory","lunr","config","builder","Builder","pipeline","trimmer","stopWordFilter","stemmer","searchPipeline","build","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","substr","toUpperCase","test","replace","fp","exec","toLowerCase","utils","warn","message","console","asString","obj","toString","clone","create","keys","key","val","isArray","TypeError","FieldRef","docRef","fieldName","stringValue","_stringValue","joiner","fromString","n","indexOf","fieldRef","undefined","Set","elements","complete","intersect","other","union","empty","object","a","b","intersection","push","concat","idf","posting","documentCount","documentsWithTerm","Math","log","abs","Token","str","metadata","update","fn","tokenizer","map","t","trim","len","tokens","sliceEnd","sliceStart","sliceLength","charAt","match","separator","tokenMetadata","Pipeline","_stack","registeredFunctions","registerFunction","label","warnIfFunctionNotRegistered","load","serialised","fnName","Error","arguments","after","existingFn","newFn","pos","before","run","stackLength","memo","j","result","k","runString","token","reset","toJSON","Vector","_magnitude","positionForIndex","index","start","end","pivotPoint","floor","pivotIndex","insert","insertIdx","upsert","position","magnitude","sumOfSquares","elementsLength","sqrt","dot","otherVector","dotProduct","aLen","bLen","aVal","bVal","similarity","toArray","output","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","icate","ative","alize","iciti","ical","ful","ness","c","RegExp","generateStopWordFilter","stopWords","words","reduce","stopWord","TokenSet","final","edges","_nextId","fromArray","arr","finish","fromClause","clause","fromFuzzyString","term","editDistance","stack","node","editsRemaining","noEditNode","char","deletionNode","frame","substitutionNode","insertionNode","transposeNode","charA","charB","next","prefix","edge","_str","labels","sort","qNode","qEdges","qLen","nEdges","nLen","q","qEdge","nEdge","previousWord","uncheckedNodes","minimizedNodes","word","commonPrefix","minimize","child","nextNode","parent","downTo","childKey","Index","attrs","invertedIndex","fieldVectors","tokenSet","fields","search","queryString","query","QueryParser","Query","matchingFields","queryVectors","termFieldCache","requiredMatches","prohibitedMatches","clauses","terms","clauseMatches","usePipeline","m","termTokenSet","expandedTerms","presence","REQUIRED","field","expandedTerm","termIndex","_index","fieldPosting","matchingDocumentRefs","termField","matchingDocumentsSet","PROHIBITED","boost","l","fieldMatch","matchingDocumentRef","matchingFieldRef","MatchData","allRequiredMatches","allProhibitedMatches","matchingFieldRefs","results","isNegated","docMatch","fieldVector","score","matchData","combine","ref","serializedIndex","serializedVectors","serializedInvertedIndex","tokenSetBuilder","tuple","_ref","_fields","_documents","fieldTermFrequencies","fieldLengths","_b","_k1","metadataWhitelist","attributes","RangeError","number","k1","doc","extractor","fieldTerms","metadataKey","calculateAverageFieldLengths","fieldRefs","numberOfFields","accumulator","documentsWithField","averageFieldLength","createFieldVectors","fieldRefsLength","termIdfCache","fieldLength","termFrequencies","termsLength","fieldBoost","docBoost","scoreWithPrecision","tf","round","createTokenSet","use","args","unshift","apply","clonedMetadata","metadataKeys","otherMatchData","allFields","wildcard","String","NONE","LEADING","TRAILING","OPTIONAL","QueryParseError","name","QueryLexer","lexemes","escapeCharPositions","state","lexText","sliceString","subSlices","emit","type","escapeCharacter","EOS","width","ignore","backup","acceptDigitRun","charCode","charCodeAt","more","FIELD","TERM","EDIT_DISTANCE","BOOST","PRESENCE","lexField","lexer","lexTerm","lexEditDistance","lexBoost","lexEOS","termSeparator","currentClause","lexemeIdx","parseClause","peekLexeme","consumeLexeme","lexeme","nextClause","completedClause","parser","parsePresence","parseField","parseTerm","errorMessage","nextLexeme","possibleFields","f","parseEditDistance","parseBoost","parseInt","isNaN","define","amd","exports","module","searchButton","searchCancelButton","searchClearButton","clearSearch","searchInput","dispatchEvent","KeyboardEvent","enterOrSpacebarPressed","code","keyCode","which","toggleSearch","searchResult","toolbarContainer","regularTopBar","searchTopBar","antoraLunr","body","highlightText","hits","highlightSpan","textEnd","contextAfter","contextBefore","createTextNode","highlightTitle","hash","title","titles","filter","titleEnd","createSearchResult","store","searchResultDataset","url","includes","substring","positions","highlightHit","documentTitle","documentHit","documentHitLink","href","hit","searchResultItem","createSearchResultItem","searchIndex","firstChild","removeChild","createNoResult","init","data","func","wait","immediate","timeout","assign","context","callNow","clearTimeout"],"mappings":"CAAA,WACA,cAMA,SAAAA,EAAAC,GACA,IAAAC,EAAAD,EAAAE,WACA,IAAAD,EAAAE,QAAA,uBACA,OAEA,IAAAC,EAAAH,EAAAI,uBACAJ,EAAAK,UAAAC,OAAA,QACAH,EAAAI,cAAA,mBAAAF,UAAAG,IAAA,YACAV,EAAAK,GAVAL,CADAW,MAAAC,KAAAC,SAAAC,iBAAA,qBAAAC,MAAAZ,YAeA,IAAAa,EAAAH,SAAAC,iBAAA,mBACAG,EAAA,oBACAC,EAAAC,IAEA,GAAAD,EAOAE,OAAAC,QAAAH,GAAAI,QAAA,SAAAC,GACA,IAAAC,EAAAD,EAAA,GACAE,EAAAF,EAAA,GACAG,EAAAb,SAAAJ,cAAA,0BAAAe,EAAA,MACAE,EAAAC,cAAAF,EAEAG,EAAAJ,EADAE,EAAAG,QAAAJ,GAAAK,aAZA,CACAZ,EAAA,GACA,IAAA,IAAAa,EAAA,EAAAA,EAAAf,EAAAgB,OAAAD,IACAb,EAAAF,EAAAe,GAAAE,aAAA,mBAAA,EAEAC,EAAAhB,GAYA,SAAAgB,EAAAhB,GACA,OAAAiB,OAAAC,eAAAC,QAAApB,EAAAqB,KAAAC,UAAArB,IAGA,SAAAC,IACA,OAAAmB,KAAAE,MAAAL,OAAAC,eAAAK,QAAAxB,IAGA,SAAAW,EAAAL,EAAAmB,GACA,IAAAC,EAAA,sCAAApB,EAAA,oBAAAmB,EAAA,KACAE,EAAA,sCAAArB,EAAA,gBACAsB,EAAAhC,SAAAJ,cAAAkC,GACA9B,SAAAJ,cAAAmC,GACArC,UAAAG,IAAA,QACAmC,EAAAtC,UAAAC,OAAA,QAGA,IAAAuB,EAAA,EAAAA,EAAAf,EAAAgB,OAAAD,IAAA,CACA,IAAAe,EAAA9B,EAAAe,GACAe,EAAAC,iBAAA,SAAA,SAAAC,GACA,IAAAzB,EAAA0B,KAAAhB,aAAA,kBACAiB,EAAAD,KAAAtB,cACAe,EAAAO,KAAApB,QAAAqB,GAAApB,MACAZ,EAAAC,IACAD,EAAAK,GAAA2B,EACAhB,EAAAhB,GACAU,EAAAL,EAAAmB,KAIA,IAAAI,EAAAjB,QAAAG,SACAc,EAAAvC,UAAAG,IAAA,kBACAoC,EAAAK,UAAA,GAMA,IAAAC,EAAAvC,SAAAC,iBAAA,8DACA,IAAAiB,EAAA,EAAAA,EAAAqB,EAAApB,OAAAD,IACAsB,IAAAC,OAAAC,UAAAC,SAAAJ,EAAArB,IACAqB,EAAArB,GAAAgB,iBAAA,QAAA,SAAAC,GACA,IAAAS,EAAAT,EAAAS,OACAC,EAAAD,EAAArD,QAAA,QAAAqD,EAAAnD,uBAAAmD,EACAvD,EAAAwD,EAAAC,cAAAC,mBACAF,EAAAnD,UAAAsD,SAAA,aACAH,EAAAnD,UAAAC,OAAA,YACAN,EAAAK,UAAAG,IAAA,UAEAgD,EAAAnD,UAAAG,IAAA,YACAR,EAAAK,UAAAC,OAAA,WAMA,IAAAsD,EAAAjD,SAAAkD,eAAA,sBACAV,IAAAW,WAAAC,oBAAAT,SAAAM,GACAA,EAAAf,iBAAA,QAAA,WAEA,IAAAmB,EAAArD,SAAAJ,cAAA,QACA0D,EAAAtD,SAAAJ,cAAA,qBACA0D,EAAA5D,UAAAsD,SAAA,SACAK,EAAA3D,UAAAG,IAAA,QACAyD,EAAA5D,UAAAC,OAAA,UAGA0D,EAAA3D,UAAAC,OAAA,QACA2D,EAAA5D,UAAAG,IAAA,WA5GA,GCAA2C,IAAAe,UAAAC,aAAAb,SAAA3C,SAAAJ,cAAA,qBCAA,WACA,aAEA,IAAA6D,EAAAzD,SAAAJ,cAAA,uCACA,GAAA6D,EAAA,CAEA,IAAAC,EAAA1D,SAAAJ,cAAA,kBAEA6D,EAAAvB,iBAAA,QAAA,SAAAyB,GACAD,EAAAhE,UAAA+D,OAAA,aAEAE,EAAAC,oBAGA5D,SAAA6D,gBAAA3B,iBAAA,QAAA,WACAwB,EAAAhE,UAAAC,OAAA,gBAfA,GCAAK,SAAAkC,iBAAA,mBAAA,WAEAZ,OAAAwC,YAAA,MACA9D,SAAAJ,cAAA,qBACAF,UAAAG,IAAA,QAIA,IAAAkE,EAAAjE,MAAAkE,UAAAC,MAAAC,KAAAlE,SAAAC,iBAAA,kBAAA,GACA,IAAA8D,EAAA5C,QACA4C,EAAAtD,QAAA,SAAA0D,GACAA,EAAAjC,iBAAA,QAAA,SAAAyB,GACAA,EAAAC,kBACAO,EAAAzE,UAAA+D,OAAA,aACAzD,SAAAkD,eAAAiB,EAAAC,QAAAxB,QAAAlD,UAAA+D,OAAA,aACAzD,SAAA6D,gBAAAnE,UAAA+D,OAAA,4BAMAnC,OAAAY,iBAAA,SAAA,WAGA,GADAlC,SAAAJ,cAAA,iDACAF,UAAAsD,SAAA,QAAA,CAEA,IAAAK,EAAArD,SAAAJ,cAAA,QACAyD,EAAA3D,UAAAsD,SAAA,SACAK,EAAA3D,UAAAC,OAAA,QAIA,IAAA2D,EAAAtD,SAAAJ,cAAA,qBACA,KAAA0B,OAAAwC,YACAR,EAAA5D,UAAAsD,SAAA,SACAM,EAAA5D,UAAAC,OAAA,QAMA2B,OAAAwC,WAAA,OACAR,EAAA5D,UAAAsD,SAAA,SACAM,EAAA5D,UAAAG,IAAA,WCzCAwE,KAAAC,mBCFA,WACA,aAEA,IAAAC,EAAAvE,SAAAC,iBAAA,2BACAuE,EAAAxE,SAAAyE,cAAA,KACAD,EAAA9E,UAAA,gCACA8E,EAAAE,UAAA,YACA,IAAA,IAAAxD,EAAA,EAAAA,EAAAqD,EAAApD,OAAAD,IAAA,CACA,IAAAyD,EAAAH,EAAAI,WAAA,GACAL,EAAArD,GAAA2D,aAAAF,EAAAJ,EAAArD,GAAA4D,WAAA,IAIA,IAAAC,YAAA,iCAAA,CACAC,KAAA,SAAApC,GACA,IAAAqC,EAAArC,EAAAtD,WAAAoF,UAAAQ,MAAA,MAEA,OADAD,EAAAE,OAAA,EAAA,GACAF,EAAAG,KAAA,SAIAC,GAAA,UAAA,SAAA1B,GACAA,EAAA2B,QAAAC,OAAAC,WAAA,aAGAC,MAAAC,SAAA,0BAAA,CACA9C,OAAA,iCACA+C,QAAA,oBACAC,UAAA,aACAC,MAAA,YACAC,MAAA,CAAA,IAAA,GACAC,UAAA,SACAC,aAAA,EACAC,SAAA,SAAAC,GACAA,EAAAV,WAAA,wBAlCA,GCAA,WACA,aAKA,IAFA,IAAAW,EAAAnG,SAAAJ,cAAA,kBAAAK,iBAAA,0BACAmG,EAAApG,SAAAkD,eAAA,OACAhC,EAAA,EAAAA,EAAAiF,EAAAhF,OAAAD,IAAA,CACA,IAAAmF,EAAAF,EAAAjF,GACAoF,EAAAtG,SAAAyE,cAAA,MACA6B,EAAA5G,UAAAG,IAAA,YACAyG,EAAA5G,UAAAG,IAAAwG,EAAAE,SACAD,EAAA5B,UAAA2B,EAAA3B,UACA4B,EAAAE,aAAA,WAAAH,EAAAjF,aAAA,OACAkF,EAAApE,iBAAA,QAAA,WACA,IAAAuE,EAAAC,EAAAtE,KAAAhB,aAAA,YACAqF,EAAA,QAAAC,EAAA1G,SAAAkD,eAAAwD,GACA1G,SAAAJ,cAAA,MACA0B,OAAAqF,OAAA,CACAC,IAAAH,EAAAI,UAAA,GACAC,KAAA,EACAC,SAAA,WAEAN,EAAA/G,UAAAG,IAAA,iBACAmH,WAAA,WAAAP,EAAA/G,UAAAC,OAAA,kBAAA,OAEAyG,EAAAa,YAAAX,GAIA,IAAAY,EAAAlH,SAAAJ,cAAA,WAAAN,WACAgC,OAAAY,iBAAA,SAAA,WAGA,IAFA,IAAAiF,EAAAC,EAAApH,SAAAJ,cAAA,oBACAyH,EAAAH,EAAAL,UAAA,MACA3F,EAAAiF,EAAAhF,OAAA,EAAA,GAAAD,EAAAA,IAAA,CAEA,GADAiF,EAAAjF,GAAAoG,wBAAAV,IACAS,EAAA,CACA,IAAAE,EAAApB,EAAAjF,GAAAE,aAAA,MACA+F,EAAAnH,SAAAJ,cAAA,uBAAA2H,EAAA,MACA,OAKAJ,GAAAA,IAAAC,IACAD,EAAAzH,UAAAG,IAAA,UACAuH,GACAA,EAAA1H,UAAAC,OAAA,aA9CA,GCMA,WAiCA,IAoCA6H,EAw2BAC,EAwBAC,EAWAC,EACAC,EAQAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EAEAC,EACAC,EAEAC,EACAC,EACAC,EA64EAC,EAAAC,EA71GAC,EAAA,SAAAC,GACA,IAAAC,EAAA,IAAAF,EAAAG,QAaA,OAXAD,EAAAE,SAAA1J,IACAsJ,EAAAK,QACAL,EAAAM,eACAN,EAAAO,SAGAL,EAAAM,eAAA9J,IACAsJ,EAAAO,SAGAN,EAAAlF,KAAAmF,EAAAA,GACAA,EAAAO,SAo8BA,SAAAC,EAAAC,GACA,IAAAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEA,GAAAP,EAAA3I,OAAA,EAAA,OAAA2I,EAiBA,GAdA,MADAG,EAAAH,EAAAQ,OAAA,EAAA,MAEAR,EAAAG,EAAAM,cAAAT,EAAAQ,OAAA,IAKAH,EAAAjC,GADAgC,EAAAjC,GAGAuC,KAAAV,GAAAA,EAAAA,EAAAW,QAAAP,EAAA,QACAC,EAAAK,KAAAV,KAAAA,EAAAA,EAAAW,QAAAN,EAAA,SAIAA,EAAA/B,GADA8B,EAAA/B,GAEAqC,KAAAV,GAAA,CACA,IAAAY,EAAAR,EAAAS,KAAAb,IACAI,EAAArC,GACA2C,KAAAE,EAAA,MACAR,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,UAEA,GAAAC,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,IACAK,EAAAnC,GACAwC,KAAAT,KAGAK,EAAA7B,EACA8B,EAAA7B,GAFA2B,EAAA7B,GAGAkC,KAJAV,EAAAC,GAIAD,GAAA,IACAM,EAAAI,KAAAV,IAAAI,EAAA7B,EAAAyB,EAAAA,EAAAW,QAAAP,EAAA,KACAG,EAAAG,KAAAV,KAAAA,GAAA,MAuCA,IAlCAI,EAAAzB,GACA+B,KAAAV,KAGAA,GADAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACA,MAIAI,EAAAxB,GACA8B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAAtC,EAAAuC,MAKAE,EAAAvB,GACA6B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GACAE,EAAAU,EAAA,IACAR,EAAArC,GACA2C,KAAAT,KACAD,EAAAC,EAAArC,EAAAsC,KAMAG,EAAAtB,GADAqB,EAAAtB,GAEA4B,KAAAV,GAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,IACAI,EAAApC,GACA0C,KAAAT,KACAD,EAAAC,QAEA,GAAAI,EAAAK,KAAAV,GAAA,CAEAC,GADAW,EAAAP,EAAAQ,KAAAb,IACA,GAAAY,EAAA,IACAP,EAAArC,GACA0C,KAAAT,KACAD,EAAAC,GA8BA,OAzBAG,EAAApB,GACA0B,KAAAV,KAEAC,GADAW,EAAAR,EAAAS,KAAAb,IACA,GAEAK,EAAApC,EACAqC,EAAApB,IAFAkB,EAAApC,GAGA0C,KAAAT,IAAAI,EAAAK,KAAAT,KAAAK,EAAAI,KAAAT,MACAD,EAAAC,IAKAI,EAAArC,GADAoC,EAAAnB,GAEAyB,KAAAV,IAAAK,EAAAK,KAAAV,KACAI,EAAA7B,EACAyB,EAAAA,EAAAW,QAAAP,EAAA,KAKA,KAAAD,IACAH,EAAAG,EAAAW,cAAAd,EAAAQ,OAAA,IAGAR,EA9jCAX,EAAAtH,QAAA,QAUAsH,EAAA0B,MAAA,GASA1B,EAAA0B,MAAAC,MAAAtD,EAQApF,KANA,SAAA2I,GACAvD,EAAAwD,SAAAA,QAAAF,MACAE,QAAAF,KAAAC,KAiBA5B,EAAA0B,MAAAI,SAAA,SAAAC,GACA,OAAAA,MAAAA,EACA,GAEAA,EAAAC,YAoBAhC,EAAA0B,MAAAO,MAAA,SAAAF,GACA,GAAAA,MAAAA,EACA,OAAAA,EAMA,IAHA,IAAAE,EAAA7K,OAAA8K,OAAA,MACAC,EAAA/K,OAAA+K,KAAAJ,GAEAhK,EAAA,EAAAA,EAAAoK,EAAAnK,OAAAD,IAAA,CACA,IAAAqK,EAAAD,EAAApK,GACAsK,EAAAN,EAAAK,GAEA,GAAAzL,MAAA2L,QAAAD,GACAJ,EAAAG,GAAAC,EAAAvH,YADA,CAKA,GAAA,iBAAAuH,GACA,iBAAAA,GACA,kBAAAA,EAKA,MAAA,IAAAE,UAAA,yDAJAN,EAAAG,GAAAC,GAOA,OAAAJ,GAEAjC,EAAAwC,SAAA,SAAAC,EAAAC,EAAAC,GACA1J,KAAAwJ,OAAAA,EACAxJ,KAAAyJ,UAAAA,EACAzJ,KAAA2J,aAAAD,GAGA3C,EAAAwC,SAAAK,OAAA,IAEA7C,EAAAwC,SAAAM,WAAA,SAAAhK,GACA,IAAAiK,EAAAjK,EAAAkK,QAAAhD,EAAAwC,SAAAK,QAEA,IAAA,IAAAE,EACA,KAAA,6BAGA,IAAAE,EAAAnK,EAAAgC,MAAA,EAAAiI,GACAN,EAAA3J,EAAAgC,MAAAiI,EAAA,GAEA,OAAA,IAAA/C,EAAAwC,SAAAC,EAAAQ,EAAAnK,IAGAkH,EAAAwC,SAAA3H,UAAAmH,SAAA,WAKA,OAJAkB,MAAAjK,KAAA2J,eACA3J,KAAA2J,aAAA3J,KAAAyJ,UAAA1C,EAAAwC,SAAAK,OAAA5J,KAAAwJ,QAGAxJ,KAAA2J,cAYA5C,EAAAmD,IAAA,SAAAC,GAGA,GAFAnK,KAAAmK,SAAAhM,OAAA8K,OAAA,MAEAkB,EAAA,CACAnK,KAAAjB,OAAAoL,EAAApL,OAEA,IAAA,IAAAD,EAAA,EAAAA,EAAAkB,KAAAjB,OAAAD,IACAkB,KAAAmK,SAAAA,EAAArL,KAAA,OAGAkB,KAAAjB,OAAA,GAWAgI,EAAAmD,IAAAE,SAAA,CACAC,UAAA,SAAAC,GACA,OAAAA,GAGAC,MAAA,SAAAD,GACA,OAAAA,GAGA1J,SAAA,WACA,OAAA,IAWAmG,EAAAmD,IAAAM,MAAA,CACAH,UAAA,WACA,OAAArK,MAGAuK,MAAA,SAAAD,GACA,OAAAA,GAGA1J,SAAA,WACA,OAAA,IAUAmG,EAAAmD,IAAAtI,UAAAhB,SAAA,SAAA6J,GACA,QAAAzK,KAAAmK,SAAAM,IAWA1D,EAAAmD,IAAAtI,UAAAyI,UAAA,SAAAC,GACA,IAAAI,EAAAC,EAAAR,EAAAS,EAAA,GAEA,GAAAN,IAAAvD,EAAAmD,IAAAE,SACA,OAAApK,KAGA,GAAAsK,IAAAvD,EAAAmD,IAAAM,MACA,OAAAF,EAKAK,EAFA3K,KAAAjB,OAAAuL,EAAAvL,QACA2L,EAAA1K,KACAsK,IAEAI,EAAAJ,EACAtK,MAGAmK,EAAAhM,OAAA+K,KAAAwB,EAAAP,UAEA,IAAA,IAAArL,EAAA,EAAAA,EAAAqL,EAAApL,OAAAD,IAAA,CACA,IAAA9B,EAAAmN,EAAArL,GACA9B,KAAA2N,EAAAR,UACAS,EAAAC,KAAA7N,GAIA,OAAA,IAAA+J,EAAAmD,IAAAU,IAUA7D,EAAAmD,IAAAtI,UAAA2I,MAAA,SAAAD,GACA,OAAAA,IAAAvD,EAAAmD,IAAAE,SACArD,EAAAmD,IAAAE,SAGAE,IAAAvD,EAAAmD,IAAAM,MACAxK,KAGA,IAAA+G,EAAAmD,IAAA/L,OAAA+K,KAAAlJ,KAAAmK,UAAAW,OAAA3M,OAAA+K,KAAAoB,EAAAH,aAUApD,EAAAgE,IAAA,SAAAC,EAAAC,GACA,IAAAC,EAAA,EAEA,IAAA,IAAAzB,KAAAuB,EACA,UAAAvB,IACAyB,GAAA/M,OAAA+K,KAAA8B,EAAAvB,IAAA1K,QAGA,IAAAoB,GAAA8K,EAAAC,EAAA,KAAAA,EAAA,IAEA,OAAAC,KAAAC,IAAA,EAAAD,KAAAE,IAAAlL,KAWA4G,EAAAuE,MAAA,SAAAC,EAAAC,GACAxL,KAAAuL,IAAAA,GAAA,GACAvL,KAAAwL,SAAAA,GAAA,IAQAzE,EAAAuE,MAAA1J,UAAAmH,SAAA,WACA,OAAA/I,KAAAuL,KAuBAxE,EAAAuE,MAAA1J,UAAA6J,OAAA,SAAAC,GAEA,OADA1L,KAAAuL,IAAAG,EAAA1L,KAAAuL,IAAAvL,KAAAwL,UACAxL,MAUA+G,EAAAuE,MAAA1J,UAAAoH,MAAA,SAAA0C,GAEA,OADAA,EAAAA,GAAA,SAAA7L,GAAA,OAAAA,GACA,IAAAkH,EAAAuE,MAAAI,EAAA1L,KAAAuL,IAAAvL,KAAAwL,UAAAxL,KAAAwL,WAyBAzE,EAAA4E,UAAA,SAAA7C,EAAA0C,GACA,GAAA,MAAA1C,GAAAmB,MAAAnB,EACA,MAAA,GAGA,GAAApL,MAAA2L,QAAAP,GACA,OAAAA,EAAA8C,IAAA,SAAAC,GACA,OAAA,IAAA9E,EAAAuE,MACAvE,EAAA0B,MAAAI,SAAAgD,GAAArD,cACAzB,EAAA0B,MAAAO,MAAAwC,MASA,IAJA,IAAAD,EAAAzC,EAAAC,WAAA+C,OAAAtD,cACAuD,EAAAR,EAAAxM,OACAiN,EAAA,GAEAC,EAAA,EAAAC,EAAA,EAAAD,GAAAF,EAAAE,IAAA,CACA,IACAE,EAAAF,EAAAC,EAEA,GAHAX,EAAAa,OAAAH,GAGAI,MAAAtF,EAAA4E,UAAAW,YAAAL,GAAAF,EAAA,CAEA,GAAA,EAAAI,EAAA,CACA,IAAAI,EAAAxF,EAAA0B,MAAAO,MAAAwC,IAAA,GACAe,EAAA,SAAA,CAAAL,EAAAC,GACAI,EAAA,MAAAP,EAAAjN,OAEAiN,EAAAnB,KACA,IAAA9D,EAAAuE,MACAC,EAAA1J,MAAAqK,EAAAD,GACAM,IAKAL,EAAAD,EAAA,GAKA,OAAAD,GAUAjF,EAAA4E,UAAAW,UAAA,UAmCAvF,EAAAyF,SAAA,WACAxM,KAAAyM,OAAA,IAGA1F,EAAAyF,SAAAE,oBAAAvO,OAAA8K,OAAA,MAmCAlC,EAAAyF,SAAAG,iBAAA,SAAAjB,EAAAkB,GACAA,KAAA5M,KAAA0M,qBACA3F,EAAA0B,MAAAC,KAAA,6CAAAkE,GAGAlB,EAAAkB,MAAAA,EACA7F,EAAAyF,SAAAE,oBAAAhB,EAAAkB,OAAAlB,GASA3E,EAAAyF,SAAAK,4BAAA,SAAAnB,GACAA,EAAAkB,OAAAlB,EAAAkB,SAAA5M,KAAA0M,qBAGA3F,EAAA0B,MAAAC,KAAA,kGAAAgD,IAcA3E,EAAAyF,SAAAM,KAAA,SAAAC,GACA,IAAA5F,EAAA,IAAAJ,EAAAyF,SAYA,OAVAO,EAAA1O,QAAA,SAAA2O,GACA,IAAAtB,EAAA3E,EAAAyF,SAAAE,oBAAAM,GAEA,IAAAtB,EAGA,MAAA,IAAAuB,MAAA,sCAAAD,GAFA7F,EAAA1J,IAAAiO,KAMAvE,GAUAJ,EAAAyF,SAAA5K,UAAAnE,IAAA,WACAC,MAAAkE,UAAAC,MAAAC,KAAAoL,WAEA7O,QAAA,SAAAqN,GACA3E,EAAAyF,SAAAK,4BAAAnB,GACA1L,KAAAyM,OAAA5B,KAAAa,IACA1L,OAYA+G,EAAAyF,SAAA5K,UAAAuL,MAAA,SAAAC,EAAAC,GACAtG,EAAAyF,SAAAK,4BAAAQ,GAEA,IAAAC,EAAAtN,KAAAyM,OAAA1C,QAAAqD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGAK,GAAA,EACAtN,KAAAyM,OAAA1J,OAAAuK,EAAA,EAAAD,IAYAtG,EAAAyF,SAAA5K,UAAA2L,OAAA,SAAAH,EAAAC,GACAtG,EAAAyF,SAAAK,4BAAAQ,GAEA,IAAAC,EAAAtN,KAAAyM,OAAA1C,QAAAqD,GACA,IAAA,GAAAE,EACA,MAAA,IAAAL,MAAA,0BAGAjN,KAAAyM,OAAA1J,OAAAuK,EAAA,EAAAD,IAQAtG,EAAAyF,SAAA5K,UAAArE,OAAA,SAAAmO,GACA,IAAA4B,EAAAtN,KAAAyM,OAAA1C,QAAA2B,IACA,GAAA4B,GAIAtN,KAAAyM,OAAA1J,OAAAuK,EAAA,IAUAvG,EAAAyF,SAAA5K,UAAA4L,IAAA,SAAAxB,GAGA,IAFA,IAAAyB,EAAAzN,KAAAyM,OAAA1N,OAEAD,EAAA,EAAAA,EAAA2O,EAAA3O,IAAA,CAIA,IAHA,IAAA4M,EAAA1L,KAAAyM,OAAA3N,GACA4O,EAAA,GAEAC,EAAA,EAAAA,EAAA3B,EAAAjN,OAAA4O,IAAA,CACA,IAAAC,EAAAlC,EAAAM,EAAA2B,GAAAA,EAAA3B,GAEA,QAAA,IAAA4B,GAAA,KAAAA,EAEA,GAAAA,aAAAlQ,MACA,IAAA,IAAAmQ,EAAA,EAAAA,EAAAD,EAAA7O,OAAA8O,IACAH,EAAA7C,KAAA+C,EAAAC,SAGAH,EAAA7C,KAAA+C,GAIA5B,EAAA0B,EAGA,OAAA1B,GAaAjF,EAAAyF,SAAA5K,UAAAkM,UAAA,SAAAvC,EAAAC,GACA,IAAAuC,EAAA,IAAAhH,EAAAuE,MAAAC,EAAAC,GAEA,OAAAxL,KAAAwN,IAAA,CAAAO,IAAAnC,IAAA,SAAAC,GACA,OAAAA,EAAA9C,cAQAhC,EAAAyF,SAAA5K,UAAAoM,MAAA,WACAhO,KAAAyM,OAAA,IAUA1F,EAAAyF,SAAA5K,UAAAqM,OAAA,WACA,OAAAjO,KAAAyM,OAAAb,IAAA,SAAAF,GAGA,OAFA3E,EAAAyF,SAAAK,4BAAAnB,GAEAA,EAAAkB,SAwBA7F,EAAAmH,OAAA,SAAA/D,GACAnK,KAAAmO,WAAA,EACAnO,KAAAmK,SAAAA,GAAA,IAcApD,EAAAmH,OAAAtM,UAAAwM,iBAAA,SAAAC,GAEA,GAAA,GAAArO,KAAAmK,SAAApL,OACA,OAAA,EASA,IANA,IAAAuP,EAAA,EACAC,EAAAvO,KAAAmK,SAAApL,OAAA,EACAoN,EAAAoC,EAAAD,EACAE,EAAArD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAA1O,KAAAmK,SAAA,EAAAqE,GAEA,EAAArC,IACAuC,EAAAL,IACAC,EAAAE,GAGAH,EAAAK,IACAH,EAAAC,GAGAE,GAAAL,IAIAlC,EAAAoC,EAAAD,EACAE,EAAAF,EAAAnD,KAAAsD,MAAAtC,EAAA,GACAuC,EAAA1O,KAAAmK,SAAA,EAAAqE,GAGA,OAAAE,GAAAL,GAIAA,EAAAK,EAHA,EAAAF,EAOAE,EAAAL,EACA,GAAAG,EAAA,QADA,GAcAzH,EAAAmH,OAAAtM,UAAA+M,OAAA,SAAAC,EAAAxF,GACApJ,KAAA6O,OAAAD,EAAAxF,EAAA,WACA,KAAA,qBAYArC,EAAAmH,OAAAtM,UAAAiN,OAAA,SAAAD,EAAAxF,EAAAsC,GACA1L,KAAAmO,WAAA,EACA,IAAAW,EAAA9O,KAAAoO,iBAAAQ,GAEA5O,KAAAmK,SAAA2E,IAAAF,EACA5O,KAAAmK,SAAA2E,EAAA,GAAApD,EAAA1L,KAAAmK,SAAA2E,EAAA,GAAA1F,GAEApJ,KAAAmK,SAAApH,OAAA+L,EAAA,EAAAF,EAAAxF,IASArC,EAAAmH,OAAAtM,UAAAmN,UAAA,WACA,GAAA/O,KAAAmO,WAAA,OAAAnO,KAAAmO,WAKA,IAHA,IAAAa,EAAA,EACAC,EAAAjP,KAAAmK,SAAApL,OAEAD,EAAA,EAAAA,EAAAmQ,EAAAnQ,GAAA,EAAA,CACA,IAAAsK,EAAApJ,KAAAmK,SAAArL,GACAkQ,GAAA5F,EAAAA,EAGA,OAAApJ,KAAAmO,WAAAhD,KAAA+D,KAAAF,IASAjI,EAAAmH,OAAAtM,UAAAuN,IAAA,SAAAC,GAOA,IANA,IAAAC,EAAA,EACA3E,EAAA1K,KAAAmK,SAAAQ,EAAAyE,EAAAjF,SACAmF,EAAA5E,EAAA3L,OAAAwQ,EAAA5E,EAAA5L,OACAyQ,EAAA,EAAAC,EAAA,EACA3Q,EAAA,EAAA6O,EAAA,EAEA7O,EAAAwQ,GAAA3B,EAAA4B,IACAC,EAAA9E,EAAA5L,KAAA2Q,EAAA9E,EAAAgD,IAEA7O,GAAA,EACA2Q,EAAAD,EACA7B,GAAA,EACA6B,GAAAC,IACAJ,GAAA3E,EAAA5L,EAAA,GAAA6L,EAAAgD,EAAA,GACA7O,GAAA,EACA6O,GAAA,GAIA,OAAA0B,GAUAtI,EAAAmH,OAAAtM,UAAA8N,WAAA,SAAAN,GACA,OAAApP,KAAAmP,IAAAC,GAAApP,KAAA+O,aAAA,GAQAhI,EAAAmH,OAAAtM,UAAA+N,QAAA,WAGA,IAFA,IAAAC,EAAA,IAAAlS,MAAAsC,KAAAmK,SAAApL,OAAA,GAEAD,EAAA,EAAA6O,EAAA,EAAA7O,EAAAkB,KAAAmK,SAAApL,OAAAD,GAAA,EAAA6O,IACAiC,EAAAjC,GAAA3N,KAAAmK,SAAArL,GAGA,OAAA8Q,GAQA7I,EAAAmH,OAAAtM,UAAAqM,OAAA,WACA,OAAAjO,KAAAmK,UAoBApD,EAAAO,SACAjC,EAAA,CACAwK,QAAA,MACAC,OAAA,OACAC,KAAA,OACAC,KAAA,OACAC,KAAA,MACAC,IAAA,MACAC,KAAA,KACAC,MAAA,MACAC,IAAA,IACAC,MAAA,MACAC,QAAA,MACAC,MAAA,MACAC,KAAA,MACAC,MAAA,KACAC,QAAA,MACAC,QAAA,MACAC,QAAA,MACAC,MAAA,KACAC,MAAA,MACAC,OAAA,MACAC,KAAA,OAGA3L,EAAA,CACA4L,MAAA,KACAC,MAAA,GACAC,MAAA,KACAC,MAAA,KACAC,KAAA,KACAC,IAAA,GACAC,KAAA,IAIAjM,EAAA,WACAC,EAAAiM,qBAQAhM,EAAA,IAAAiM,OALA,4DAMAhM,EAAA,IAAAgM,OAJA,8FAKA/L,EAAA,IAAA+L,OANA,gFAOA9L,EAAA,IAAA8L,OALA,kCAOA7L,EAAA,kBACAC,EAAA,iBACAC,EAAA,aACAC,EAAA,kBACAC,EAAA,KACAC,EAAA,cACAC,EAAA,IAAAuL,OAAA,sBACAtL,EAAA,IAAAsL,OAAA,IAAAlM,EAAAD,EAAA,gBAEAc,EAAA,mBACAC,EAAA,2IAEAC,EAAA,iDAEAC,EAAA,sFACAC,EAAA,oBAEAC,EAAA,WACAC,EAAA,MACAC,EAAA,IAAA8K,OAAA,IAAAlM,EAAAD,EAAA,gBAkIA,SAAAwI,GACA,OAAAA,EAAAtC,OAAAhE,KAIAV,EAAAyF,SAAAG,iBAAA5F,EAAAO,QAAA,WAmBAP,EAAA4K,uBAAA,SAAAC,GACA,IAAAC,EAAAD,EAAAE,OAAA,SAAApE,EAAAqE,GAEA,OADArE,EAAAqE,GAAAA,EACArE,GACA,IAEA,OAAA,SAAAK,GACA,GAAAA,GAAA8D,EAAA9D,EAAAhF,cAAAgF,EAAAhF,WAAA,OAAAgF,IAiBAhH,EAAAM,eAAAN,EAAA4K,uBAAA,CACA,IACA,OACA,QACA,SACA,QACA,MACA,SACA,OACA,KACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,UACA,OACA,MACA,KACA,MACA,SACA,QACA,OACA,MACA,KACA,OACA,SACA,OACA,OACA,QACA,MACA,OACA,MACA,MACA,MACA,MACA,OACA,KACA,MACA,OACA,MACA,MACA,MACA,UACA,IACA,KACA,KACA,OACA,KACA,KACA,MACA,OACA,QACA,MACA,OACA,SACA,MACA,KACA,QACA,OACA,OACA,KACA,UACA,KACA,MACA,MACA,KACA,MACA,QACA,KACA,OACA,KACA,QACA,MACA,MACA,SACA,OACA,MACA,OACA,MACA,SACA,QACA,KACA,OACA,OACA,OACA,MACA,QACA,OACA,OACA,QACA,QACA,OACA,OACA,MACA,KACA,MACA,OACA,KACA,QACA,MACA,KACA,OACA,OACA,OACA,QACA,QACA,QACA,MACA,OACA,MACA,OACA,OACA,QACA,MACA,MACA,SAGA5K,EAAAyF,SAAAG,iBAAA5F,EAAAM,eAAA,kBAqBAN,EAAAK,QAAA,SAAA2G,GACA,OAAAA,EAAAtC,OAAA,SAAA5L,GACA,OAAAA,EAAAwI,QAAA,OAAA,IAAAA,QAAA,OAAA,OAIAtB,EAAAyF,SAAAG,iBAAA5F,EAAAK,QAAA,WA2BAL,EAAAiL,SAAA,WACAhS,KAAAiS,OAAA,EACAjS,KAAAkS,MAAA,GACAlS,KAAAsE,GAAAyC,EAAAiL,SAAAG,QACApL,EAAAiL,SAAAG,SAAA,GAWApL,EAAAiL,SAAAG,QAAA,EASApL,EAAAiL,SAAAI,UAAA,SAAAC,GAGA,IAFA,IAAApL,EAAA,IAAAF,EAAAiL,SAAA9K,QAEApI,EAAA,EAAAiN,EAAAsG,EAAAtT,OAAAD,EAAAiN,EAAAjN,IACAmI,EAAA0H,OAAA0D,EAAAvT,IAIA,OADAmI,EAAAqL,SACArL,EAAAJ,MAYAE,EAAAiL,SAAAO,WAAA,SAAAC,GACA,MAAA,iBAAAA,EACAzL,EAAAiL,SAAAS,gBAAAD,EAAAE,KAAAF,EAAAG,cAEA5L,EAAAiL,SAAAnI,WAAA2I,EAAAE,OAmBA3L,EAAAiL,SAAAS,gBAAA,SAAAlH,EAAAoH,GASA,IARA,IAAA9L,EAAA,IAAAE,EAAAiL,SAEAY,EAAA,CAAA,CACAC,KAAAhM,EACAiM,eAAAH,EACApH,IAAAA,IAGAqH,EAAA7T,QAAA,CACA,IAKAgU,EAwBAC,EACAC,EA9BAC,EAAAN,EAAA9U,MAGA,GAAA,EAAAoV,EAAA3H,IAAAxM,QACAiU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAa,EAAAG,EAAAL,KAAAX,MAAAc,IAEAD,EAAA,IAAAhM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAD,GAGA,GAAAG,EAAA3H,IAAAxM,OACAgU,EAAAd,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAE,EACAD,eAAAI,EAAAJ,eACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAQA,GAAA,EAAAqR,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAAxM,QACAiU,EAAAE,EAAA3H,IAAAa,OAAA,MAGA8G,EAAAL,KAAAX,MACAe,EAAAC,EAAAL,KAAAX,MAAAc,IAEAC,EAAA,IAAAlM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAc,GAAAC,GAGAC,EAAA3H,IAAAxM,QAAA,EACAkU,EAAAhB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAI,EACAH,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAcA,GAPA,EAAAqR,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAAxM,SACAmU,EAAAL,KAAAZ,OAAA,GAMA,EAAAiB,EAAAJ,gBAAA,GAAAI,EAAA3H,IAAAxM,OAAA,CACA,GAAA,MAAAmU,EAAAL,KAAAX,MACA,IAAAiB,EAAAD,EAAAL,KAAAX,MAAA,SACA,CACAiB,EAAA,IAAApM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAA,KAAAiB,EAGA,GAAAD,EAAA3H,IAAAxM,OACAoU,EAAAlB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAM,EACAL,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,IAAA1J,MAAA,KAOA,GAAA,EAAAqR,EAAAJ,eAAA,CACA,GAAA,MAAAI,EAAAL,KAAAX,MACA,IAAAkB,EAAAF,EAAAL,KAAAX,MAAA,SACA,CACAkB,EAAA,IAAArM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAA,KAAAkB,EAGA,GAAAF,EAAA3H,IAAAxM,OACAqU,EAAAnB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAO,EACAN,eAAAI,EAAAJ,eAAA,EACAvH,IAAA2H,EAAA3H,MAQA,GAAA,EAAA2H,EAAAJ,gBAAA,EAAAI,EAAA3H,IAAAxM,OAAA,CACA,IAEAsU,EAFAC,EAAAJ,EAAA3H,IAAAa,OAAA,GACAmH,EAAAL,EAAA3H,IAAAa,OAAA,GAGAmH,KAAAL,EAAAL,KAAAX,MACAmB,EAAAH,EAAAL,KAAAX,MAAAqB,IAEAF,EAAA,IAAAtM,EAAAiL,SACAkB,EAAAL,KAAAX,MAAAqB,GAAAF,GAGA,GAAAH,EAAA3H,IAAAxM,OACAsU,EAAApB,OAAA,EAEAW,EAAA/H,KAAA,CACAgI,KAAAQ,EACAP,eAAAI,EAAAJ,eAAA,EACAvH,IAAA+H,EAAAJ,EAAA3H,IAAA1J,MAAA,MAMA,OAAAgF,GAaAE,EAAAiL,SAAAnI,WAAA,SAAA0B,GAYA,IAXA,IAAAsH,EAAA,IAAA9L,EAAAiL,SACAnL,EAAAgM,EAUA/T,EAAA,EAAAiN,EAAAR,EAAAxM,OAAAD,EAAAiN,EAAAjN,IAAA,CACA,IAAAkU,EAAAzH,EAAAzM,GACAmT,EAAAnT,GAAAiN,EAAA,EAEA,GAAA,KAAAiH,GACAH,EAAAX,MAAAc,GAAAH,GACAZ,MAAAA,MAEA,CACA,IAAAuB,EAAA,IAAAzM,EAAAiL,SACAwB,EAAAvB,MAAAA,EAEAY,EAAAX,MAAAc,GAAAQ,EACAX,EAAAW,GAIA,OAAA3M,GASAE,EAAAiL,SAAApQ,UAAA+N,QAAA,WAQA,IAPA,IAAAkC,EAAA,GAEAe,EAAA,CAAA,CACAa,OAAA,GACAZ,KAAA7S,OAGA4S,EAAA7T,QAAA,CACA,IAAAmU,EAAAN,EAAA9U,MACAoU,EAAA/T,OAAA+K,KAAAgK,EAAAL,KAAAX,OACAnG,EAAAmG,EAAAnT,OAEAmU,EAAAL,KAAAZ,QAKAiB,EAAAO,OAAArH,OAAA,GACAyF,EAAAhH,KAAAqI,EAAAO,SAGA,IAAA,IAAA3U,EAAA,EAAAA,EAAAiN,EAAAjN,IAAA,CACA,IAAA4U,EAAAxB,EAAApT,GAEA8T,EAAA/H,KAAA,CACA4I,OAAAP,EAAAO,OAAA3I,OAAA4I,GACAb,KAAAK,EAAAL,KAAAX,MAAAwB,MAKA,OAAA7B,GAaA9K,EAAAiL,SAAApQ,UAAAmH,SAAA,WASA,GAAA/I,KAAA2T,KACA,OAAA3T,KAAA2T,KAOA,IAJA,IAAApI,EAAAvL,KAAAiS,MAAA,IAAA,IACA2B,EAAAzV,OAAA+K,KAAAlJ,KAAAkS,OAAA2B,OACA9H,EAAA6H,EAAA7U,OAEAD,EAAA,EAAAA,EAAAiN,EAAAjN,IAAA,CACA,IAAA8N,EAAAgH,EAAA9U,GAGAyM,EAAAA,EAAAqB,EAFA5M,KAAAkS,MAAAtF,GAEAtI,GAGA,OAAAiH,GAaAxE,EAAAiL,SAAApQ,UAAAyI,UAAA,SAAAM,GAUA,IATA,IAAAiF,EAAA,IAAA7I,EAAAiL,SACAkB,OAAAjJ,EAEA2I,EAAA,CAAA,CACAkB,MAAAnJ,EACAiF,OAAAA,EACAiD,KAAA7S,OAGA4S,EAAA7T,QAAA,CACAmU,EAAAN,EAAA9U,MAWA,IALA,IAAAiW,EAAA5V,OAAA+K,KAAAgK,EAAAY,MAAA5B,OACA8B,EAAAD,EAAAhV,OACAkV,EAAA9V,OAAA+K,KAAAgK,EAAAL,KAAAX,OACAgC,EAAAD,EAAAlV,OAEAoV,EAAA,EAAAA,EAAAH,EAAAG,IAGA,IAFA,IAAAC,EAAAL,EAAAI,GAEArK,EAAA,EAAAA,EAAAoK,EAAApK,IAAA,CACA,IAAAuK,EAAAJ,EAAAnK,GAEA,GAAAuK,GAAAD,GAAA,KAAAA,EAAA,CACA,IAAAvB,EAAAK,EAAAL,KAAAX,MAAAmC,GACAP,EAAAZ,EAAAY,MAAA5B,MAAAkC,GACAnC,EAAAY,EAAAZ,OAAA6B,EAAA7B,MACAuB,OAAAvJ,EAEAoK,KAAAnB,EAAAtD,OAAAsC,OAIAsB,EAAAN,EAAAtD,OAAAsC,MAAAmC,IACApC,MAAAuB,EAAAvB,OAAAA,IAMAuB,EAAA,IAAAzM,EAAAiL,UACAC,MAAAA,EACAiB,EAAAtD,OAAAsC,MAAAmC,GAAAb,GAGAZ,EAAA/H,KAAA,CACAiJ,MAAAA,EACAlE,OAAA4D,EACAX,KAAAA,MAOA,OAAAjD,GAEA7I,EAAAiL,SAAA9K,QAAA,WACAlH,KAAAsU,aAAA,GACAtU,KAAA6G,KAAA,IAAAE,EAAAiL,SACAhS,KAAAuU,eAAA,GACAvU,KAAAwU,eAAA,IAGAzN,EAAAiL,SAAA9K,QAAAtF,UAAA+M,OAAA,SAAA8F,GACA,IAAA5B,EACA6B,EAAA,EAEA,GAAAD,EAAAzU,KAAAsU,aACA,MAAA,IAAArH,MAAA,+BAGA,IAAA,IAAAnO,EAAA,EAAAA,EAAA2V,EAAA1V,QAAAD,EAAAkB,KAAAsU,aAAAvV,QACA0V,EAAA3V,IAAAkB,KAAAsU,aAAAxV,GADAA,IAEA4V,IAGA1U,KAAA2U,SAAAD,GAGA7B,EADA,GAAA7S,KAAAuU,eAAAxV,OACAiB,KAAA6G,KAEA7G,KAAAuU,eAAAvU,KAAAuU,eAAAxV,OAAA,GAAA6V,MAGA,IAAA9V,EAAA4V,EAAA5V,EAAA2V,EAAA1V,OAAAD,IAAA,CACA,IAAA+V,EAAA,IAAA9N,EAAAiL,SACAgB,EAAAyB,EAAA3V,GAEA+T,EAAAX,MAAAc,GAAA6B,EAEA7U,KAAAuU,eAAA1J,KAAA,CACAiK,OAAAjC,EACAG,KAAAA,EACA4B,MAAAC,IAGAhC,EAAAgC,EAGAhC,EAAAZ,OAAA,EACAjS,KAAAsU,aAAAG,GAGA1N,EAAAiL,SAAA9K,QAAAtF,UAAA0Q,OAAA,WACAtS,KAAA2U,SAAA,IAGA5N,EAAAiL,SAAA9K,QAAAtF,UAAA+S,SAAA,SAAAI,GACA,IAAA,IAAAjW,EAAAkB,KAAAuU,eAAAxV,OAAA,EAAAgW,GAAAjW,EAAAA,IAAA,CACA,IAAA+T,EAAA7S,KAAAuU,eAAAzV,GACAkW,EAAAnC,EAAA+B,MAAA7L,WAEAiM,KAAAhV,KAAAwU,eACA3B,EAAAiC,OAAA5C,MAAAW,EAAAG,MAAAhT,KAAAwU,eAAAQ,IAIAnC,EAAA+B,MAAAjB,KAAAqB,EAEAhV,KAAAwU,eAAAQ,GAAAnC,EAAA+B,OAGA5U,KAAAuU,eAAAzW,QAwBAiJ,EAAAkO,MAAA,SAAAC,GACAlV,KAAAmV,cAAAD,EAAAC,cACAnV,KAAAoV,aAAAF,EAAAE,aACApV,KAAAqV,SAAAH,EAAAG,SACArV,KAAAsV,OAAAJ,EAAAI,OACAtV,KAAAmH,SAAA+N,EAAA/N,UA0EAJ,EAAAkO,MAAArT,UAAA2T,OAAA,SAAAC,GACA,OAAAxV,KAAAyV,MAAA,SAAAA,GACA,IAAA1O,EAAA2O,YAAAF,EAAAC,GACAlW,WA6BAwH,EAAAkO,MAAArT,UAAA6T,MAAA,SAAA/J,GAoBA,IAZA,IAAA+J,EAAA,IAAA1O,EAAA4O,MAAA3V,KAAAsV,QACAM,EAAAzX,OAAA8K,OAAA,MACA4M,EAAA1X,OAAA8K,OAAA,MACA6M,EAAA3X,OAAA8K,OAAA,MACA8M,EAAA5X,OAAA8K,OAAA,MACA+M,EAAA7X,OAAA8K,OAAA,MAOAnK,EAAA,EAAAA,EAAAkB,KAAAsV,OAAAvW,OAAAD,IACA+W,EAAA7V,KAAAsV,OAAAxW,IAAA,IAAAiI,EAAAmH,OAGAxC,EAAA5J,KAAA2T,EAAAA,GAEA,IAAA3W,EAAA,EAAAA,EAAA2W,EAAAQ,QAAAlX,OAAAD,IAAA,CASA,IAAA0T,EAAAiD,EAAAQ,QAAAnX,GACAoX,EAAA,KACAC,EAAApP,EAAAmD,IAAAE,SAGA8L,EADA1D,EAAA4D,YACApW,KAAAmH,SAAA2G,UAAA0E,EAAAE,KAAA,CACA4C,OAAA9C,EAAA8C,SAGA,CAAA9C,EAAAE,MAGA,IAAA,IAAA2D,EAAA,EAAAA,EAAAH,EAAAnX,OAAAsX,IAAA,CACA,IAAA3D,EAAAwD,EAAAG,GAQA7D,EAAAE,KAAAA,EAOA,IAAA4D,EAAAvP,EAAAiL,SAAAO,WAAAC,GACA+D,EAAAvW,KAAAqV,SAAAhL,UAAAiM,GAAA3G,UAQA,GAAA,IAAA4G,EAAAxX,QAAAyT,EAAAgE,WAAAzP,EAAA4O,MAAAa,SAAAC,SAAA,CACA,IAAA,IAAA5I,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CAEAkI,EADAW,EAAAlE,EAAA8C,OAAAzH,IACA9G,EAAAmD,IAAAM,MAGA,MAGA,IAAA,IAAAmD,EAAA,EAAAA,EAAA4I,EAAAxX,OAAA4O,IAKA,CAAA,IAAAgJ,EAAAJ,EAAA5I,GACA3C,EAAAhL,KAAAmV,cAAAwB,GACAC,EAAA5L,EAAA6L,OAEA,IAAAhJ,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CASA,IACAiJ,EAAA9L,EADA0L,EAAAlE,EAAA8C,OAAAzH,IAEAkJ,EAAA5Y,OAAA+K,KAAA4N,GACAE,EAAAL,EAAA,IAAAD,EACAO,EAAA,IAAAlQ,EAAAmD,IAAA6M,GAoBA,GAbAvE,EAAAgE,UAAAzP,EAAA4O,MAAAa,SAAAC,WACAN,EAAAA,EAAA5L,MAAA0M,QAEAhN,IAAA8L,EAAAW,KACAX,EAAAW,GAAA3P,EAAAmD,IAAAE,WASAoI,EAAAgE,UAAAzP,EAAA4O,MAAAa,SAAAU,YA4BA,GANArB,EAAAa,GAAA7H,OAAA+H,EAAApE,EAAA2E,MAAA,SAAAzM,EAAAC,GAAA,OAAAD,EAAAC,KAMAmL,EAAAkB,GAAA,CAIA,IAAA,IAAAI,EAAA,EAAAA,EAAAL,EAAAhY,OAAAqY,IAAA,CAOA,IAGAC,EAHAC,EAAAP,EAAAK,GACAG,EAAA,IAAAxQ,EAAAwC,SAAA+N,EAAAZ,GACAlL,EAAAsL,EAAAQ,QAGArN,KAAAoN,EAAAzB,EAAA2B,IACA3B,EAAA2B,GAAA,IAAAxQ,EAAAyQ,UAAAb,EAAAD,EAAAlL,GAEA6L,EAAA5Z,IAAAkZ,EAAAD,EAAAlL,GAKAsK,EAAAkB,IAAA,aAnDA/M,IAAA+L,EAAAU,KACAV,EAAAU,GAAA3P,EAAAmD,IAAAM,OAGAwL,EAAAU,GAAAV,EAAAU,GAAAnM,MAAA0M,KA0DA,GAAAzE,EAAAgE,WAAAzP,EAAA4O,MAAAa,SAAAC,SACA,IAAA5I,EAAA,EAAAA,EAAA2E,EAAA8C,OAAAvW,OAAA8O,IAAA,CAEAkI,EADAW,EAAAlE,EAAA8C,OAAAzH,IACAkI,EAAAW,GAAArM,UAAA8L,IAUA,IAAAsB,EAAA1Q,EAAAmD,IAAAE,SACAsN,EAAA3Q,EAAAmD,IAAAM,MAEA,IAAA1L,EAAA,EAAAA,EAAAkB,KAAAsV,OAAAvW,OAAAD,IAAA,CACA,IAAA4X,EAEAX,EAFAW,EAAA1W,KAAAsV,OAAAxW,MAGA2Y,EAAAA,EAAApN,UAAA0L,EAAAW,KAGAV,EAAAU,KACAgB,EAAAA,EAAAnN,MAAAyL,EAAAU,KAIA,IAAAiB,EAAAxZ,OAAA+K,KAAA0M,GACAgC,EAAA,GACAza,EAAAgB,OAAA8K,OAAA,MAYA,GAAAwM,EAAAoC,YAAA,CACAF,EAAAxZ,OAAA+K,KAAAlJ,KAAAoV,cAEA,IAAAtW,EAAA,EAAAA,EAAA6Y,EAAA5Y,OAAAD,IAAA,CACAyY,EAAAI,EAAA7Y,GAAA,IACAkL,EAAAjD,EAAAwC,SAAAM,WAAA0N,GACA3B,EAAA2B,GAAA,IAAAxQ,EAAAyQ,WAIA,IAAA1Y,EAAA,EAAAA,EAAA6Y,EAAA5Y,OAAAD,IAAA,CASA,IACA0K,GADAQ,EAAAjD,EAAAwC,SAAAM,WAAA8N,EAAA7Y,KACA0K,OAEA,GAAAiO,EAAA7W,SAAA4I,KAIAkO,EAAA9W,SAAA4I,GAAA,CAIA,IAEAsO,EAFAC,EAAA/X,KAAAoV,aAAApL,GACAgO,EAAAnC,EAAA7L,EAAAP,WAAAiG,WAAAqI,GAGA,QAAA9N,KAAA6N,EAAA3a,EAAAqM,IACAsO,EAAAE,OAAAA,EACAF,EAAAG,UAAAC,QAAAtC,EAAA5L,QACA,CACA,IAAAqC,EAAA,CACA8L,IAAA3O,EACAwO,MAAAA,EACAC,UAAArC,EAAA5L,IAEA7M,EAAAqM,GAAA6C,EACAuL,EAAA/M,KAAAwB,KAOA,OAAAuL,EAAA/D,KAAA,SAAAnJ,EAAAC,GACA,OAAAA,EAAAqN,MAAAtN,EAAAsN,SAYAjR,EAAAkO,MAAArT,UAAAqM,OAAA,WACA,IAAAkH,EAAAhX,OAAA+K,KAAAlJ,KAAAmV,eACAtB,OACAjI,IAAA,SAAA8G,GACA,MAAA,CAAAA,EAAA1S,KAAAmV,cAAAzC,KACA1S,MAEAoV,EAAAjX,OAAA+K,KAAAlJ,KAAAoV,cACAxJ,IAAA,SAAAuM,GACA,MAAA,CAAAA,EAAAnY,KAAAoV,aAAA+C,GAAAlK,WACAjO,MAEA,MAAA,CACAP,QAAAsH,EAAAtH,QACA6V,OAAAtV,KAAAsV,OACAF,aAAAA,EACAD,cAAAA,EACAhO,SAAAnH,KAAAmH,SAAA8G,WAUAlH,EAAAkO,MAAAnI,KAAA,SAAAsL,GACA,IAAAlD,EAAA,GACAE,EAAA,GACAiD,EAAAD,EAAAhD,aACAD,EAAA,GACAmD,EAAAF,EAAAjD,cACAoD,EAAA,IAAAxR,EAAAiL,SAAA9K,QACAC,EAAAJ,EAAAyF,SAAAM,KAAAsL,EAAAjR,UAEAiR,EAAA3Y,SAAAsH,EAAAtH,SACAsH,EAAA0B,MAAAC,KAAA,4EAAA3B,EAAAtH,QAAA,sCAAA2Y,EAAA3Y,QAAA,KAGA,IAAA,IAAAX,EAAA,EAAAA,EAAAuZ,EAAAtZ,OAAAD,IAAA,CACA,IACAqZ,GADAK,EAAAH,EAAAvZ,IACA,GACAqL,EAAAqO,EAAA,GAEApD,EAAA+C,GAAA,IAAApR,EAAAmH,OAAA/D,GAGA,IAAArL,EAAA,EAAAA,EAAAwZ,EAAAvZ,OAAAD,IAAA,CACA,IAAA0Z,EACA9F,GADA8F,EAAAF,EAAAxZ,IACA,GACAkM,EAAAwN,EAAA,GAEAD,EAAA5J,OAAA+D,GACAyC,EAAAzC,GAAA1H,EAYA,OATAuN,EAAAjG,SAEA4C,EAAAI,OAAA8C,EAAA9C,OAEAJ,EAAAE,aAAAA,EACAF,EAAAC,cAAAA,EACAD,EAAAG,SAAAkD,EAAA1R,KACAqO,EAAA/N,SAAAA,EAEA,IAAAJ,EAAAkO,MAAAC,IA+BAnO,EAAAG,QAAA,WACAlH,KAAAyY,KAAA,KACAzY,KAAA0Y,QAAAva,OAAA8K,OAAA,MACAjJ,KAAA2Y,WAAAxa,OAAA8K,OAAA,MACAjJ,KAAAmV,cAAAhX,OAAA8K,OAAA,MACAjJ,KAAA4Y,qBAAA,GACA5Y,KAAA6Y,aAAA,GACA7Y,KAAA2L,UAAA5E,EAAA4E,UACA3L,KAAAmH,SAAA,IAAAJ,EAAAyF,SACAxM,KAAAuH,eAAA,IAAAR,EAAAyF,SACAxM,KAAAiL,cAAA,EACAjL,KAAA8Y,GAAA,IACA9Y,KAAA+Y,IAAA,IACA/Y,KAAA4W,UAAA,EACA5W,KAAAgZ,kBAAA,IAeAjS,EAAAG,QAAAtF,UAAAuW,IAAA,SAAAA,GACAnY,KAAAyY,KAAAN,GAmCApR,EAAAG,QAAAtF,UAAA8U,MAAA,SAAAjN,EAAAwP,GACA,GAAA,KAAA7Q,KAAAqB,GACA,MAAA,IAAAyP,WAAA,UAAAzP,EAAA,oCAGAzJ,KAAA0Y,QAAAjP,GAAAwP,GAAA,IAWAlS,EAAAG,QAAAtF,UAAA+I,EAAA,SAAAwO,GAEAnZ,KAAA8Y,GADAK,EAAA,EACA,EACA,EAAAA,EACA,EAEAA,GAWApS,EAAAG,QAAAtF,UAAAwX,GAAA,SAAAD,GACAnZ,KAAA+Y,IAAAI,GAoBApS,EAAAG,QAAAtF,UAAAnE,IAAA,SAAA4b,EAAAJ,GACA,IAAAzP,EAAA6P,EAAArZ,KAAAyY,MACAnD,EAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SAEA1Y,KAAA2Y,WAAAnP,GAAAyP,GAAA,GACAjZ,KAAAiL,eAAA,EAEA,IAAA,IAAAnM,EAAA,EAAAA,EAAAwW,EAAAvW,OAAAD,IAAA,CACA,IAAA2K,EAAA6L,EAAAxW,GACAwa,EAAAtZ,KAAA0Y,QAAAjP,GAAA6P,UACA5C,EAAA4C,EAAAA,EAAAD,GAAAA,EAAA5P,GACAuC,EAAAhM,KAAA2L,UAAA+K,EAAA,CACApB,OAAA,CAAA7L,KAEAyM,EAAAlW,KAAAmH,SAAAqG,IAAAxB,GACAhC,EAAA,IAAAjD,EAAAwC,SAAAC,EAAAC,GACA8P,EAAApb,OAAA8K,OAAA,MAEAjJ,KAAA4Y,qBAAA5O,GAAAuP,EACAvZ,KAAA6Y,aAAA7O,GAAA,EAGAhK,KAAA6Y,aAAA7O,IAAAkM,EAAAnX,OAGA,IAAA,IAAA4O,EAAA,EAAAA,EAAAuI,EAAAnX,OAAA4O,IAAA,CACA,IAAA+E,EAAAwD,EAAAvI,GAUA,GARA1D,MAAAsP,EAAA7G,KACA6G,EAAA7G,GAAA,GAGA6G,EAAA7G,IAAA,EAIAzI,MAAAjK,KAAAmV,cAAAzC,GAAA,CACA,IAAA1H,EAAA7M,OAAA8K,OAAA,MACA+B,EAAA,OAAAhL,KAAA4W,UACA5W,KAAA4W,WAAA,EAEA,IAAA,IAAA/I,EAAA,EAAAA,EAAAyH,EAAAvW,OAAA8O,IACA7C,EAAAsK,EAAAzH,IAAA1P,OAAA8K,OAAA,MAGAjJ,KAAAmV,cAAAzC,GAAA1H,EAIAf,MAAAjK,KAAAmV,cAAAzC,GAAAjJ,GAAAD,KACAxJ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAArL,OAAA8K,OAAA,OAKA,IAAA,IAAAmO,EAAA,EAAAA,EAAApX,KAAAgZ,kBAAAja,OAAAqY,IAAA,CACA,IAAAoC,EAAAxZ,KAAAgZ,kBAAA5B,GACA5L,EAAAkH,EAAAlH,SAAAgO,GAEAvP,MAAAjK,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,KACAxZ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,GAAA,IAGAxZ,KAAAmV,cAAAzC,GAAAjJ,GAAAD,GAAAgQ,GAAA3O,KAAAW,OAYAzE,EAAAG,QAAAtF,UAAA6X,6BAAA,WAOA,IALA,IAAAC,EAAAvb,OAAA+K,KAAAlJ,KAAA6Y,cACAc,EAAAD,EAAA3a,OACA6a,EAAA,GACAC,EAAA,GAEA/a,EAAA,EAAAA,EAAA6a,EAAA7a,IAAA,CACA,IAAAkL,EAAAjD,EAAAwC,SAAAM,WAAA6P,EAAA5a,IACA4X,EAAA1M,EAAAP,UAEAoQ,EAAAnD,KAAAmD,EAAAnD,GAAA,GACAmD,EAAAnD,IAAA,EAEAkD,EAAAlD,KAAAkD,EAAAlD,GAAA,GACAkD,EAAAlD,IAAA1W,KAAA6Y,aAAA7O,GAGA,IAAAsL,EAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SAEA,IAAA5Z,EAAA,EAAAA,EAAAwW,EAAAvW,OAAAD,IAAA,CACA,IAAA2K,EAAA6L,EAAAxW,GACA8a,EAAAnQ,GAAAmQ,EAAAnQ,GAAAoQ,EAAApQ,GAGAzJ,KAAA8Z,mBAAAF,GAQA7S,EAAAG,QAAAtF,UAAAmY,mBAAA,WAMA,IALA,IAAA3E,EAAA,GACAsE,EAAAvb,OAAA+K,KAAAlJ,KAAA4Y,sBACAoB,EAAAN,EAAA3a,OACAkb,EAAA9b,OAAA8K,OAAA,MAEAnK,EAAA,EAAAA,EAAAkb,EAAAlb,IAAA,CAaA,IAZA,IAAAkL,EAAAjD,EAAAwC,SAAAM,WAAA6P,EAAA5a,IACA2K,EAAAO,EAAAP,UACAyQ,EAAAla,KAAA6Y,aAAA7O,GACA+N,EAAA,IAAAhR,EAAAmH,OACAiM,EAAAna,KAAA4Y,qBAAA5O,GACAkM,EAAA/X,OAAA+K,KAAAiR,GACAC,EAAAlE,EAAAnX,OAGAsb,EAAAra,KAAA0Y,QAAAjP,GAAA0N,OAAA,EACAmD,EAAAta,KAAA2Y,WAAA3O,EAAAR,QAAA2N,OAAA,EAEAxJ,EAAA,EAAAA,EAAAyM,EAAAzM,IAAA,CACA,IAGA5C,EAAAiN,EAAAuC,EAHA7H,EAAAwD,EAAAvI,GACA6M,EAAAL,EAAAzH,GACAkE,EAAA5W,KAAAmV,cAAAzC,GAAAmE,YAGA5M,IAAAgQ,EAAAvH,IACA3H,EAAAhE,EAAAgE,IAAA/K,KAAAmV,cAAAzC,GAAA1S,KAAAiL,eACAgP,EAAAvH,GAAA3H,GAEAA,EAAAkP,EAAAvH,GAGAsF,EAAAjN,IAAA/K,KAAA+Y,IAAA,GAAAyB,IAAAxa,KAAA+Y,KAAA,EAAA/Y,KAAA8Y,GAAA9Y,KAAA8Y,IAAAoB,EAAAla,KAAA8Z,mBAAArQ,KAAA+Q,GACAxC,GAAAqC,EACArC,GAAAsC,EACAC,EAAApP,KAAAsP,MAAA,IAAAzC,GAAA,IAQAD,EAAApJ,OAAAiI,EAAA2D,GAGAnF,EAAApL,GAAA+N,EAGA/X,KAAAoV,aAAAA,GAQArO,EAAAG,QAAAtF,UAAA8Y,eAAA,WACA1a,KAAAqV,SAAAtO,EAAAiL,SAAAI,UACAjU,OAAA+K,KAAAlJ,KAAAmV,eAAAtB,SAYA9M,EAAAG,QAAAtF,UAAA4F,MAAA,WAKA,OAJAxH,KAAAyZ,+BACAzZ,KAAA+Z,qBACA/Z,KAAA0a,iBAEA,IAAA3T,EAAAkO,MAAA,CACAE,cAAAnV,KAAAmV,cACAC,aAAApV,KAAAoV,aACAC,SAAArV,KAAAqV,SACAC,OAAAnX,OAAA+K,KAAAlJ,KAAA0Y,SACAvR,SAAAnH,KAAAuH,kBAkBAR,EAAAG,QAAAtF,UAAA+Y,IAAA,SAAAjP,GACA,IAAAkP,EAAAld,MAAAkE,UAAAC,MAAAC,KAAAoL,UAAA,GACA0N,EAAAC,QAAA7a,MACA0L,EAAAoP,MAAA9a,KAAA4a,IAcA7T,EAAAyQ,UAAA,SAAA9E,EAAAgE,EAAAlL,GASA,IARA,IAAAuP,EAAA5c,OAAA8K,OAAA,MACA+R,EAAA7c,OAAA+K,KAAAsC,GAAA,IAOA1M,EAAA,EAAAA,EAAAkc,EAAAjc,OAAAD,IAAA,CACA,IAAAqK,EAAA6R,EAAAlc,GACAic,EAAA5R,GAAAqC,EAAArC,GAAAtH,QAGA7B,KAAAwL,SAAArN,OAAA8K,OAAA,WAEAgB,IAAAyI,IACA1S,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,MACAjJ,KAAAwL,SAAAkH,GAAAgE,GAAAqE,IAaAhU,EAAAyQ,UAAA5V,UAAAsW,QAAA,SAAA+C,GAGA,IAFA,IAAA/E,EAAA/X,OAAA+K,KAAA+R,EAAAzP,UAEA1M,EAAA,EAAAA,EAAAoX,EAAAnX,OAAAD,IAAA,CACA,IAAA4T,EAAAwD,EAAApX,GACAwW,EAAAnX,OAAA+K,KAAA+R,EAAAzP,SAAAkH,IAEAzI,MAAAjK,KAAAwL,SAAAkH,KACA1S,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,OAGA,IAAA,IAAA0E,EAAA,EAAAA,EAAA2H,EAAAvW,OAAA4O,IAAA,CACA,IAAA+I,EAAApB,EAAA3H,GACAzE,EAAA/K,OAAA+K,KAAA+R,EAAAzP,SAAAkH,GAAAgE,IAEAzM,MAAAjK,KAAAwL,SAAAkH,GAAAgE,KACA1W,KAAAwL,SAAAkH,GAAAgE,GAAAvY,OAAA8K,OAAA,OAGA,IAAA,IAAA4E,EAAA,EAAAA,EAAA3E,EAAAnK,OAAA8O,IAAA,CACA,IAAA1E,EAAAD,EAAA2E,GAEA5D,MAAAjK,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GACAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA8R,EAAAzP,SAAAkH,GAAAgE,GAAAvN,GAEAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA2B,OAAAmQ,EAAAzP,SAAAkH,GAAAgE,GAAAvN,QAeApC,EAAAyQ,UAAA5V,UAAAnE,IAAA,SAAAiV,EAAAgE,EAAAlL,GACA,KAAAkH,KAAA1S,KAAAwL,UAGA,OAFAxL,KAAAwL,SAAAkH,GAAAvU,OAAA8K,OAAA,WACAjJ,KAAAwL,SAAAkH,GAAAgE,GAAAlL,GAIA,GAAAkL,KAAA1W,KAAAwL,SAAAkH,GAOA,IAFA,IAAAsI,EAAA7c,OAAA+K,KAAAsC,GAEA1M,EAAA,EAAAA,EAAAkc,EAAAjc,OAAAD,IAAA,CACA,IAAAqK,EAAA6R,EAAAlc,GAEAqK,KAAAnJ,KAAAwL,SAAAkH,GAAAgE,GACA1W,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAA2B,OAAAU,EAAArC,IAEAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAvN,GAAAqC,EAAArC,QAZAnJ,KAAAwL,SAAAkH,GAAAgE,GAAAlL,GA2BAzE,EAAA4O,MAAA,SAAAuF,GACAlb,KAAAiW,QAAA,GACAjW,KAAAkb,UAAAA,GA2BAnU,EAAA4O,MAAAwF,SAAA,IAAAC,OAAA,KACArU,EAAA4O,MAAAwF,SAAAE,KAAA,EACAtU,EAAA4O,MAAAwF,SAAAG,QAAA,EACAvU,EAAA4O,MAAAwF,SAAAI,SAAA,EAaAxU,EAAA4O,MAAAa,SAAA,CAIAgF,SAAA,EAMA/E,SAAA,EAMAS,WAAA,GA0BAnQ,EAAA4O,MAAA/T,UAAA4Q,OAAA,SAAAA,GA+BA,MA9BA,WAAAA,IACAA,EAAA8C,OAAAtV,KAAAkb,WAGA,UAAA1I,IACAA,EAAA2E,MAAA,GAGA,gBAAA3E,IACAA,EAAA4D,aAAA,GAGA,aAAA5D,IACAA,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAE,MAGA7I,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAG,SAAA9I,EAAAE,KAAAtG,OAAA,IAAArF,EAAA4O,MAAAwF,WACA3I,EAAAE,KAAA,IAAAF,EAAAE,MAGAF,EAAA2I,SAAApU,EAAA4O,MAAAwF,SAAAI,UAAA/I,EAAAE,KAAA7Q,OAAA,IAAAkF,EAAA4O,MAAAwF,WACA3I,EAAAE,KAAAF,EAAAE,KAAA,KAGA,aAAAF,IACAA,EAAAgE,SAAAzP,EAAA4O,MAAAa,SAAAgF,UAGAxb,KAAAiW,QAAApL,KAAA2H,GAEAxS,MAUA+G,EAAA4O,MAAA/T,UAAAiW,UAAA,WACA,IAAA,IAAA/Y,EAAA,EAAAA,EAAAkB,KAAAiW,QAAAlX,OAAAD,IACA,GAAAkB,KAAAiW,QAAAnX,GAAA0X,UAAAzP,EAAA4O,MAAAa,SAAAU,WACA,OAAA,EAIA,OAAA,GA6BAnQ,EAAA4O,MAAA/T,UAAA8Q,KAAA,SAAAA,EAAA9T,GACA,GAAAlB,MAAA2L,QAAAqJ,GAEA,OADAA,EAAArU,QAAA,SAAAwN,GAAA7L,KAAA0S,KAAA7G,EAAA9E,EAAA0B,MAAAO,MAAApK,KAAAoB,MACAA,KAGA,IAAAwS,EAAA5T,GAAA,GAKA,OAJA4T,EAAAE,KAAAA,EAAA3J,WAEA/I,KAAAwS,OAAAA,GAEAxS,MAEA+G,EAAA0U,gBAAA,SAAA9S,EAAA2F,EAAAC,GACAvO,KAAA0b,KAAA,kBACA1b,KAAA2I,QAAAA,EACA3I,KAAAsO,MAAAA,EACAtO,KAAAuO,IAAAA,GAGAxH,EAAA0U,gBAAA7Z,UAAA,IAAAqL,MACAlG,EAAA4U,WAAA,SAAApQ,GACAvL,KAAA4b,QAAA,GACA5b,KAAAuL,IAAAA,EACAvL,KAAAjB,OAAAwM,EAAAxM,OACAiB,KAAAsN,IAAA,EACAtN,KAAAsO,MAAA,EACAtO,KAAA6b,oBAAA,IAGA9U,EAAA4U,WAAA/Z,UAAA4L,IAAA,WAGA,IAFA,IAAAsO,EAAA/U,EAAA4U,WAAAI,QAEAD,GACAA,EAAAA,EAAA9b,OAIA+G,EAAA4U,WAAA/Z,UAAAoa,YAAA,WAKA,IAJA,IAAAC,EAAA,GACA/P,EAAAlM,KAAAsO,MACArC,EAAAjM,KAAAsN,IAEAxO,EAAA,EAAAA,EAAAkB,KAAA6b,oBAAA9c,OAAAD,IACAmN,EAAAjM,KAAA6b,oBAAA/c,GACAmd,EAAApR,KAAA7K,KAAAuL,IAAA1J,MAAAqK,EAAAD,IACAC,EAAAD,EAAA,EAMA,OAHAgQ,EAAApR,KAAA7K,KAAAuL,IAAA1J,MAAAqK,EAAAlM,KAAAsN,MACAtN,KAAA6b,oBAAA9c,OAAA,EAEAkd,EAAAjZ,KAAA,KAGA+D,EAAA4U,WAAA/Z,UAAAsa,KAAA,SAAAC,GACAnc,KAAA4b,QAAA/Q,KAAA,CACAsR,KAAAA,EACA5Q,IAAAvL,KAAAgc,cACA1N,MAAAtO,KAAAsO,MACAC,IAAAvO,KAAAsN,MAGAtN,KAAAsO,MAAAtO,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAAwa,gBAAA,WACApc,KAAA6b,oBAAAhR,KAAA7K,KAAAsN,IAAA,GACAtN,KAAAsN,KAAA,GAGAvG,EAAA4U,WAAA/Z,UAAA4R,KAAA,WACA,GAAAxT,KAAAsN,KAAAtN,KAAAjB,OACA,OAAAgI,EAAA4U,WAAAU,IAGA,IAAArJ,EAAAhT,KAAAuL,IAAAa,OAAApM,KAAAsN,KAEA,OADAtN,KAAAsN,KAAA,EACA0F,GAGAjM,EAAA4U,WAAA/Z,UAAA0a,MAAA,WACA,OAAAtc,KAAAsN,IAAAtN,KAAAsO,OAGAvH,EAAA4U,WAAA/Z,UAAA2a,OAAA,WACAvc,KAAAsO,OAAAtO,KAAAsN,MACAtN,KAAAsN,KAAA,GAGAtN,KAAAsO,MAAAtO,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAA4a,OAAA,aACAxc,KAAAsN,KAGAvG,EAAA4U,WAAA/Z,UAAA6a,eAAA,WAGA,IAFA,IAAAzJ,EAAA0J,EAKA,IADAA,GADA1J,EAAAhT,KAAAwT,QACAmJ,WAAA,KACAD,EAAA,KAEA1J,GAAAjM,EAAA4U,WAAAU,KACArc,KAAAwc,UAIAzV,EAAA4U,WAAA/Z,UAAAgb,KAAA,WACA,OAAA5c,KAAAsN,IAAAtN,KAAAjB,QAGAgI,EAAA4U,WAAAU,IAAA,MACAtV,EAAA4U,WAAAkB,MAAA,QACA9V,EAAA4U,WAAAmB,KAAA,OACA/V,EAAA4U,WAAAoB,cAAA,gBACAhW,EAAA4U,WAAAqB,MAAA,QACAjW,EAAA4U,WAAAsB,SAAA,WAEAlW,EAAA4U,WAAAuB,SAAA,SAAAC,GAIA,OAHAA,EAAAX,SACAW,EAAAjB,KAAAnV,EAAA4U,WAAAkB,OACAM,EAAAZ,SACAxV,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAAyB,QAAA,SAAAD,GAQA,GAPA,EAAAA,EAAAb,UACAa,EAAAX,SACAW,EAAAjB,KAAAnV,EAAA4U,WAAAmB,OAGAK,EAAAZ,SAEAY,EAAAP,OACA,OAAA7V,EAAA4U,WAAAI,SAIAhV,EAAA4U,WAAA0B,gBAAA,SAAAF,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAnV,EAAA4U,WAAAoB,eACAhW,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAA2B,SAAA,SAAAH,GAIA,OAHAA,EAAAZ,SACAY,EAAAV,iBACAU,EAAAjB,KAAAnV,EAAA4U,WAAAqB,OACAjW,EAAA4U,WAAAI,SAGAhV,EAAA4U,WAAA4B,OAAA,SAAAJ,GACA,EAAAA,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,OAeA/V,EAAA4U,WAAA6B,cAAAzW,EAAA4E,UAAAW,UAEAvF,EAAA4U,WAAAI,QAAA,SAAAoB,GACA,OAAA,CACA,IAAAnK,EAAAmK,EAAA3J,OAEA,GAAAR,GAAAjM,EAAA4U,WAAAU,IACA,OAAAtV,EAAA4U,WAAA4B,OAIA,GAAA,IAAAvK,EAAA2J,WAAA,GAAA,CAKA,GAAA,KAAA3J,EACA,OAAAjM,EAAA4U,WAAAuB,SAGA,GAAA,KAAAlK,EAKA,OAJAmK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,MAEA/V,EAAA4U,WAAA0B,gBAGA,GAAA,KAAArK,EAKA,OAJAmK,EAAAX,SACA,EAAAW,EAAAb,SACAa,EAAAjB,KAAAnV,EAAA4U,WAAAmB,MAEA/V,EAAA4U,WAAA2B,SAMA,GAAA,KAAAtK,GAAA,IAAAmK,EAAAb,QAEA,OADAa,EAAAjB,KAAAnV,EAAA4U,WAAAsB,UACAlW,EAAA4U,WAAAI,QAMA,GAAA,KAAA/I,GAAA,IAAAmK,EAAAb,QAEA,OADAa,EAAAjB,KAAAnV,EAAA4U,WAAAsB,UACAlW,EAAA4U,WAAAI,QAGA,GAAA/I,EAAA3G,MAAAtF,EAAA4U,WAAA6B,eACA,OAAAzW,EAAA4U,WAAAyB,aAzCAD,EAAAf,oBA8CArV,EAAA2O,YAAA,SAAAnK,EAAAkK,GACAzV,KAAAmd,MAAA,IAAApW,EAAA4U,WAAApQ,GACAvL,KAAAyV,MAAAA,EACAzV,KAAAyd,cAAA,GACAzd,KAAA0d,UAAA,GAGA3W,EAAA2O,YAAA9T,UAAArC,MAAA,WACAS,KAAAmd,MAAA3P,MACAxN,KAAA4b,QAAA5b,KAAAmd,MAAAvB,QAIA,IAFA,IAAAE,EAAA/U,EAAA2O,YAAAiI,YAEA7B,GACAA,EAAAA,EAAA9b,MAGA,OAAAA,KAAAyV,OAGA1O,EAAA2O,YAAA9T,UAAAgc,WAAA,WACA,OAAA5d,KAAA4b,QAAA5b,KAAA0d,YAGA3W,EAAA2O,YAAA9T,UAAAic,cAAA,WACA,IAAAC,EAAA9d,KAAA4d,aAEA,OADA5d,KAAA0d,WAAA,EACAI,GAGA/W,EAAA2O,YAAA9T,UAAAmc,WAAA,WACA,IAAAC,EAAAhe,KAAAyd,cACAzd,KAAAyV,MAAAjD,OAAAwL,GACAhe,KAAAyd,cAAA,IAGA1W,EAAA2O,YAAAiI,YAAA,SAAAM,GACA,IAAAH,EAAAG,EAAAL,aAEA,GAAA3T,MAAA6T,EAIA,OAAAA,EAAA3B,MACA,KAAApV,EAAA4U,WAAAsB,SACA,OAAAlW,EAAA2O,YAAAwI,cACA,KAAAnX,EAAA4U,WAAAkB,MACA,OAAA9V,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACA,IAAAC,EAAA,4CAAAP,EAAA3B,KAMA,MAJA,GAAA2B,EAAAvS,IAAAxM,SACAsf,GAAA,gBAAAP,EAAAvS,IAAA,KAGA,IAAAxE,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,OAIAxH,EAAA2O,YAAAwI,cAAA,SAAAD,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,OAAAA,EAAAvS,KACA,IAAA,IACA0S,EAAAR,cAAAjH,SAAAzP,EAAA4O,MAAAa,SAAAU,WACA,MACA,IAAA,IACA+G,EAAAR,cAAAjH,SAAAzP,EAAA4O,MAAAa,SAAAC,SACA,MACA,QACA,IAAA4H,EAAA,kCAAAP,EAAAvS,IAAA,IACA,MAAA,IAAAxE,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,IAAA+P,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAAA,CACAD,EAAA,yCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,OAAA+P,EAAAnC,MACA,KAAApV,EAAA4U,WAAAkB,MACA,OAAA9V,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACAC,EAAA,mCAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,QAIAxH,EAAA2O,YAAAyI,WAAA,SAAAF,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAA,GAAAG,EAAAxI,MAAAyF,UAAAnR,QAAA+T,EAAAvS,KAAA,CACA,IAAAgT,EAAAN,EAAAxI,MAAAyF,UAAAtP,IAAA,SAAA4S,GAAA,MAAA,IAAAA,EAAA,MAAAxb,KAAA,MACAqb,EAAA,uBAAAP,EAAAvS,IAAA,uBAAAgT,EAEA,MAAA,IAAAxX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAAnI,OAAA,CAAAwI,EAAAvS,KAEA,IAAA+S,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAAA,CACAD,EAAA,gCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA,OAAA+P,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KACA,OAAA/V,EAAA2O,YAAA0I,UACA,QACAC,EAAA,0BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,QAIAxH,EAAA2O,YAAA0I,UAAA,SAAAH,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIAG,EAAAR,cAAA/K,KAAAoL,EAAAvS,IAAA/C,eAEA,GAAAsV,EAAAvS,IAAAxB,QAAA,OACAkU,EAAAR,cAAArH,aAAA,GAGA,IAAAkI,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACA,IAAAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eAwBAhX,EAAA2O,YAAA+I,kBAAA,SAAAR,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAAnL,EAAAgM,SAAAb,EAAAvS,IAAA,IAEA,GAAAqT,MAAAjM,GAAA,CACA,IAAA0L,EAAA,gCACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAA9K,aAAAA,EAEA,IAAA2L,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eAwBAhX,EAAA2O,YAAAgJ,WAAA,SAAAT,GACA,IAAAH,EAAAG,EAAAJ,gBAEA,GAAA5T,MAAA6T,EAAA,CAIA,IAAA3G,EAAAwH,SAAAb,EAAAvS,IAAA,IAEA,GAAAqT,MAAAzH,GAAA,CACA,IAAAkH,EAAA,wBACA,MAAA,IAAAtX,EAAA0U,gBAAA4C,EAAAP,EAAAxP,MAAAwP,EAAAvP,KAGA0P,EAAAR,cAAAtG,MAAAA,EAEA,IAAAmH,EAAAL,EAAAL,aAEA,GAAA3T,MAAAqU,EAKA,OAAAA,EAAAnC,MACA,KAAApV,EAAA4U,WAAAmB,KAEA,OADAmB,EAAAF,aACAhX,EAAA2O,YAAA0I,UACA,KAAArX,EAAA4U,WAAAkB,MAEA,OADAoB,EAAAF,aACAhX,EAAA2O,YAAAyI,WACA,KAAApX,EAAA4U,WAAAoB,cACA,OAAAhW,EAAA2O,YAAA+I,kBACA,KAAA1X,EAAA4U,WAAAqB,MACA,OAAAjW,EAAA2O,YAAAgJ,WACA,KAAA3X,EAAA4U,WAAAsB,SAEA,OADAgB,EAAAF,aACAhX,EAAA2O,YAAAwI,cACA,QACAG,EAAA,2BAAAC,EAAAnC,KAAA,IACA,MAAA,IAAApV,EAAA0U,gBAAA4C,EAAAC,EAAAhQ,MAAAgQ,EAAA/P,UApBA0P,EAAAF,eA4BAlX,EAeA7G,KAfA8G,EAeA,WAMA,OAAAC,GApBA,mBAAA8X,QAAAA,OAAAC,IAEAD,OAAA/X,GACA,iBAAAiY,QAMAC,OAAAD,QAAAjY,IAGAD,EAAAE,KAAAD,IA34GA,GCNAlJ,SAAAkC,iBAAA,mBAAA,WACA,IAAAmf,EAAArhB,SAAAJ,cAAA,2BACA0hB,EAAAthB,SAAAJ,cAAA,sCACA2hB,EAAAvhB,SAAAJ,cAAA,uCAEA,SAAA4hB,IACA,IAAAC,EAAAzhB,SAAAkD,eAAA,gBACAue,EAAAxgB,MAAA,GACAwgB,EAAAC,cAAA,IAAAC,cAAA,YAGA,SAAAC,EAAAje,GAEA,IAAAke,EAAAle,EAAAme,SAAAne,EAAAoe,MAIA,OAHA,KAGAF,GAFA,KAEAA,EAGA,SAAAG,IACA,IAAA3e,EAAArD,SAAAJ,cAAA,QACA0D,EAAAtD,SAAAJ,cAAA,qBACAqiB,EAAAjiB,SAAAJ,cAAA,gCACAsiB,EAAAliB,SAAAJ,cAAA,YACAqiB,EAAAviB,UAAAsD,SAAA,SACAif,EAAAviB,UAAAC,OAAA,QACA0D,EAAA3D,UAAAG,IAAA,QACAyD,EAAA5D,UAAAG,IAAA,QACAqiB,EAAAxiB,UAAAG,IAAA,UAEAoiB,EAAAviB,UAAAG,IAAA,QACAwD,EAAA3D,UAAAC,OAAA,QAGA,KAAA2B,OAAAwC,WACAR,EAAA5D,UAAAC,OAAA,QAEAuiB,EAAAxiB,UAAAC,OAAA,SAIA,IAAAwiB,EAAAniB,SAAAJ,cAAA,yBACAwiB,EAAApiB,SAAAJ,cAAA,iDACAuiB,EAAAziB,UAAAsD,SAAA,SACAmf,EAAAziB,UAAAC,OAAA,QACAyiB,EAAA1iB,UAAAG,IAAA,UAEAsiB,EAAAziB,UAAAG,IAAA,QACAuiB,EAAA1iB,UAAAC,OAAA,SAKA0hB,EAAAnf,iBAAA,QAAA8f,GACAX,EAAAnf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACAqe,MAGA,iBAAA1gB,QACA+f,EAAAnf,iBAAA,eAAA8f,GAIAV,EAAApf,iBAAA,QAAA8f,GACAV,EAAApf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACAqe,MAGA,iBAAA1gB,QACAggB,EAAApf,iBAAA,eAAA8f,GAIAT,EAAArf,iBAAA,QAAAsf,GACAD,EAAArf,iBAAA,WAAA,SAAAyB,GACAie,EAAAje,IACA6d,MAGA,iBAAAlgB,QACAigB,EAAArf,iBAAA,eAAAsf,KAMAlgB,OAAA+gB,WAAA,SAAAlZ,GACA,IAAAsY,EAAAzhB,SAAAkD,eAAA,gBACA+e,EAAAjiB,SAAAyE,cAAA,OACA6d,EAAAtiB,SAAAJ,cAAA,SAKA,SAAA2iB,EAAA9G,EAAAvK,GACA,IAAAsR,EAAA,GACA9R,EAAAQ,EAAA,GACA/P,EAAA+P,EAAA,GAEAlM,EAAAyW,EAAAzW,KACAyd,EAAAziB,SAAAyE,cAAA,QACAge,EAAA/iB,UAAAG,IAAA,2BACA4iB,EAAA/d,UAAAM,EAAAsF,OAAAoG,EAAAvP,GAEA,IAAAwP,EAAAD,EAAAvP,EACAuhB,EAAA1d,EAAA7D,OAAA,EAEAwhB,EAAAD,EAAA/R,EADA,GACA+R,EAAA/R,EADA,GAEAiS,EAAAlS,EAFA,GAEA,EAAA,EAAAA,EAFA,GAgBA,OAbA,IAAAA,GAAAC,IAAA+R,EACAF,EAAAvV,KAAAwV,GACA,IAAA/R,GACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAAqG,EAAAgS,MACAhS,IAAA+R,GACAF,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,KAEAD,EAAAvV,KAAAjN,SAAA6iB,eAAA,MAAA7d,EAAAsF,OAAAsY,EAAAlS,EAAAkS,KACAJ,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAA7d,EAAAsF,OAAAqG,EAAAgS,EAAAhS,GAAA,SAEA6R,EAGA,SAAAM,EAAAC,EAAAtH,EAAAvK,GACA,IAMA8R,EANAR,EAAA,GACA9R,EAAAQ,EAAA,GACA/P,EAAA+P,EAAA,GAEAuR,EAAAziB,SAAAyE,cAAA,QACAge,EAAA/iB,UAAAG,IAAA,2BAGAmjB,EADAD,EACAtH,EAAAwH,OAAAC,OAAA,SAAArgB,GACA,OAAAA,EAAA6D,KAAAqc,IACA,GAAA/d,KAEAyW,EAAAuH,MAEAP,EAAA/d,UAAAse,EAAA1Y,OAAAoG,EAAAvP,GAEA,IAAAwP,EAAAD,EAAAvP,EACAgiB,EAAAH,EAAA7hB,OAAA,EAcA,OAbA,IAAAuP,GAAAC,IAAAwS,EACAX,EAAAvV,KAAAwV,GACA,IAAA/R,GACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAAnJ,EAAAgiB,MACAxS,IAAAwS,GACAX,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,KAEAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAA,EAAAoG,KACA8R,EAAAvV,KAAAwV,GACAD,EAAAvV,KAAAjN,SAAA6iB,eAAAG,EAAA1Y,OAAAqG,EAAAwS,MAEAX,EAsBA,SAAAY,EAAApT,EAAAqT,EAAAC,GACAtT,EAAAvP,QAAA,SAAAoC,GACA,IACAkgB,EADAQ,EAAA1gB,EAAA0X,IAEAgJ,EAAAC,SAAA,OACAT,EAAAQ,EAAAE,UAAAF,EAAApX,QAAA,KAAA,GACAoX,EAAAA,EAAA9Y,QAAA,IAAAsY,EAAA,KAEA,IAAAtH,EAAA4H,EAAAE,GAEAf,EA7BA,SAAA5U,EAAAmV,EAAAtH,GACA,IAAA+G,EAAA,GACA,IAAA,IAAArS,KAAAvC,EAAA,CACA,IAAA8J,EAAA9J,EAAAuC,GACA,IAAA,IAAA2I,KAAApB,EAAA,CACA,IAAAgM,EAAAhM,EAAAoB,GACA,GAAA4K,EAAAxS,SAAA,CACA,IAAAA,EAAAwS,EAAAxS,SAAA,GACA,UAAA4H,EACA0J,EAAAM,EAAAC,EAAAtH,EAAAvK,GACA,SAAA4H,IACA0J,EAAAD,EAAA9G,EAAAvK,MAKA,OAAAsR,EAaAmB,CADA9gB,EAAAwX,UAAAzM,SACAmV,EAAAtH,GACA6H,EAAArc,YAIA,SAAAwU,EAAA5Y,EAAA2f,GACA,IAAAoB,EAAA5jB,SAAAyE,cAAA,OACAmf,EAAAlkB,UAAAG,IAAA,gCACA+jB,EAAAlf,UAAA+W,EAAAuH,MACA,IAAAa,EAAA7jB,SAAAyE,cAAA,OACAof,EAAAnkB,UAAAG,IAAA,8BACA,IAAAikB,EAAA9jB,SAAAyE,cAAA,KACAqf,EAAAC,KAAAlhB,EAAA0X,IACAsJ,EAAA5c,YAAA6c,GACAtB,EAAA/hB,QAAA,SAAAujB,GACAF,EAAA7c,YAAA+c,KAEA,IAAAC,EAAAjkB,SAAAyE,cAAA,OAIA,OAHAwf,EAAAvkB,UAAAG,IAAA,sBACAokB,EAAAhd,YAAA2c,GACAK,EAAAhd,YAAA4c,GACAI,EApBAC,CAAAzI,EAAA5Y,EAAA2f,MAmDA,SAAA2B,EAAA1T,EAAA4S,EAAAre,GAEA,KAAAid,EAAAmC,YACAnC,EAAAoC,YAAApC,EAAAmC,YAEA,GAAA,KAAApf,EAAAkJ,OAAA,CAGA,IAxBAuC,EAAAzL,EAEAgL,EAsBAA,GAxBAhL,EAwBAA,EArBA,GADAgL,GAFAS,EAwBAA,GAtBAkH,OAAA3S,IACA7D,QAKA,GADA6O,EAAAS,EAAAkH,OAAA3S,EAAA,MACA7D,OAJA6O,EAQAA,EAAAS,EAAAkH,OAAA,IAAA3S,EAAA,MAaAse,EAAAtjB,SAAAyE,cAAA,OACA6e,EAAA5jB,UAAAG,IAAA,yBACAoiB,EAAAhb,YAAAqc,GACA,EAAAtT,EAAA7O,OACAiiB,EAAApT,EAAAqT,EAAAC,GAEAA,EAAArc,YA3CA,SAAAjC,GACA,IAAAif,EAAAjkB,SAAAyE,cAAA,OACAwf,EAAAvkB,UAAAG,IAAA,sBACA,IAAAgkB,EAAA7jB,SAAAyE,cAAA,OACAof,EAAAnkB,UAAAG,IAAA,8BACA,IAAAkL,EAAA/K,SAAAyE,cAAA,UAIA,OAHAsG,EAAArG,UAAA,+BAAAM,EAAA,IACA6e,EAAA5c,YAAA8D,GACAkZ,EAAAhd,YAAA4c,GACAI,EAkCAK,CAAAtf,KA6BA,OAnMAid,EAAAviB,UAAAG,IAAA,+BACAoiB,EAAAviB,UAAAG,IAAA,QACAyiB,EAAAzd,aAAAod,EAAAK,EAAA8B,YAiMA,CACAG,KAVA,SAAAC,GACA,IAjBAC,EAAAC,EAAAC,EACAC,EAgBAnU,EAAAlQ,OAAAskB,OAAA,CAAApU,MAAAtH,EAAAkO,MAAAnI,KAAAsV,EAAA/T,OAAA4S,MAAAmB,EAAAnB,QACA1L,GAlBA8M,EAkBA,WACAN,EAAA1T,EAAAA,MAAAA,EAAA4S,MAAA5B,EAAAxgB,QAnBAyjB,EAoBA,IAlBA,WACA,IAAAI,EAAA1iB,KACA4a,EAAA1N,UAKAyV,EAAAJ,IAAAC,EACAI,aAAAJ,GACAA,EAAA5d,WANA,WACA4d,EAAA,KACAD,GAAAF,EAAAvH,MAAA4H,EAAA9H,IAIA0H,GACAK,GAAAN,EAAAvH,MAAA4H,EAAA9H,KAUAyE,EAAAvf,iBAAA,UAAAyV,KApMA,CA0MArW,OAAA6H","file":"site.js","sourcesContent":[";(function () {\n  'use strict'\n\n  // expand nav to show current page\n  var currentPageItem = Array.from(document.querySelectorAll('.is-current-page')).pop().parentNode\n  expandParents(currentPageItem)\n\n  function expandParents(element) {\n    var panel = element.parentNode\n    if(!panel.matches(\".nav-children-panel\")){\n        return \n    }\n    var parentHeader = panel.previousElementSibling\n    panel.classList.remove('hide')\n    parentHeader.querySelector('.material-icons').classList.add('expanded')\n    expandParents(parentHeader)\n  }  \n\n  // persist version selections\n  var select = document.querySelectorAll('.select-version')\n  var versionVar = \"sdp-docs-versions\"\n  var versions = getVersions()\n\n  if (!versions){\n    versions = {}\n    for(var i = 0; i < select.length; i++){\n      versions[select[i].getAttribute('data-component')] = 0 \n    }\n    setVersions(versions)\n  } else { \n    Object.entries(versions).forEach(function(component){\n      var componentName = component[0]\n      var componentVersionIndex = component[1] \n      var componentSelectVersion = document.querySelector('select[data-component=\"' + componentName + '\"]')\n      componentSelectVersion.selectedIndex = componentVersionIndex\n      var componentVersion = componentSelectVersion.options[componentVersionIndex].value\n      setComponentVersion(componentName, componentVersion)\n    })\n  }\n\n  function setVersions(versions){\n    return window.sessionStorage.setItem(versionVar, JSON.stringify(versions))\n  }\n\n  function getVersions(){\n    return JSON.parse(window.sessionStorage.getItem(versionVar))\n  }\n\n  function setComponentVersion(component, version){\n    var showSelector = '.nav-container div[data-component=\"' + component + '\"][data-version=\"' + version + '\"]'\n    var hideSelector = '.nav-container div[data-component=\"' + component + '\"]:not(.hide)'\n    var navShow = document.querySelector(showSelector)\n    var navHide = document.querySelector(hideSelector)\n    navHide.classList.add('hide')\n    navShow.classList.remove('hide')\n  }\n\n  for(var i = 0; i < select.length; i++){\n    var s = select[i]\n    s.addEventListener('change', function(event){\n      var component = this.getAttribute('data-component')\n      var versionIndex = this.selectedIndex\n      var version = this.options[versionIndex].value\n      var versions = getVersions()\n      versions[component] = versionIndex\n      setVersions(versions)\n      setComponentVersion(component, version)\n    })\n\n    // Disable select if there is only one version\n    if (s.options.length === 1) {\n      s.classList.add('single-version');\n      s.disabled = true;\n    }\n  }\n\n\n  /// nav-tree\n  var x = document.querySelectorAll('.nav-item:not(.is-link), .nav-item.is-link .material-icons'); \n  for(var i = 0; i < x.length; i++){\n    mdc.ripple.MDCRipple.attachTo(x[i])\n    x[i].addEventListener('click', function(event){\n      var target = event.target\n      var item = target.matches('span') ? target.previousElementSibling : target\n      var panel = item.parentElement.nextElementSibling\n      if(item.classList.contains('expanded')){\n        item.classList.remove('expanded')\n        panel.classList.add('hide')\n      } else{\n        item.classList.add('expanded')\n        panel.classList.remove('hide')\n      }\n    })\n  }\n\n  // toolbar menu button \n  var navToggle = document.getElementById('toolbar-nav-toggle')\n  mdc.iconButton.MDCIconButtonToggle.attachTo(navToggle)\n  navToggle.addEventListener('click', function(){\n    // Toggle navigation and main content together\n    var mainContainer = document.querySelector('main')\n    var navContainer = document.querySelector('div.nav-container')\n    if(navContainer.classList.contains('hide')){\n      mainContainer.classList.add('hide')\n      navContainer.classList.remove('hide')\n\n    } else{\n      mainContainer.classList.remove('hide')\n      navContainer.classList.add('hide')\n    }\n  })\n\n})()\n","mdc.topAppBar.MDCTopAppBar.attachTo(document.querySelector('.mdc-top-app-bar'))",";(function () {\n  'use strict'\n\n  var toggle = document.querySelector('.page-versions .version-menu-toggle')\n  if (!toggle) return\n\n  var selector = document.querySelector('.page-versions')\n\n  toggle.addEventListener('click', function (e) {\n    selector.classList.toggle('is-active')\n    // don't let this event get smothered\n    e.stopPropagation()\n  })\n\n  document.documentElement.addEventListener('click', function () {\n    selector.classList.remove('is-active')\n  })\n})()\n","document.addEventListener('DOMContentLoaded', function () {\n  // Hide navbar on mobile\n  if (window.innerWidth <= 1024) {\n    var navContainer = document.querySelector('div.nav-container')\n    navContainer.classList.add('hide')\n  }\n\n  // Add event listeners to hamburger icons\n  var navbarToggles = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0)\n  if (navbarToggles.length === 0) return\n  navbarToggles.forEach(function (el) {\n    el.addEventListener('click', function (e) {\n      e.stopPropagation()\n      el.classList.toggle('is-active')\n      document.getElementById(el.dataset.target).classList.toggle('is-active')\n      document.documentElement.classList.toggle('is-clipped--navbar')\n    })\n  })\n})\n\n\nwindow.addEventListener('resize', function () {\n  // Only expand/unhide elements on resize if search isn't open\n  var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\n  if (searchTopBar.classList.contains('hide')) {\n    // Unhide main content\n    var mainContainer = document.querySelector('main')\n    if (mainContainer.classList.contains('hide')) {\n      mainContainer.classList.remove('hide')\n    }\n\n    // Expand navbar if window is resized from mobile to desktop\n    var navContainer = document.querySelector('div.nav-container')\n    if (window.innerWidth > 1024) {\n      if (navContainer.classList.contains('hide')) {\n        navContainer.classList.remove('hide')\n      }\n    }\n  }\n\n  // Hide navbar if window is resized from desktop to mobile\n  if (window.innerWidth < 1025) {\n    if (!navContainer.classList.contains('hide')) {\n      navContainer.classList.add('hide')\n    }\n  }\n});\n",";(function () {\n  \n  hljs.initHighlighting()\n\n})()\n  ",";(function () {\n    'use strict'\n    // <i class=\"material-icons mdc-icon-button search\" tabindex=\"0\" role=\"button\">search</i>\n    var codeBlocks = document.querySelectorAll('.doc .listingblock code')\n    var copyIcon = document.createElement('i')\n    copyIcon.classList = 'material-icons codeCopyButton'\n    copyIcon.innerText = 'file_copy'\n    for (var i = 0; i < codeBlocks.length; i++) {\n      var icon = copyIcon.cloneNode(true)\n      codeBlocks[i].insertBefore(icon, codeBlocks[i].childNodes[0])\n    }\n \n    /*global ClipboardJS*/\n    var clipboard = new ClipboardJS('.material-icons.codeCopyButton', {\n      text: function (target) { \n        var lines = target.parentNode.innerText.split(\"\\n\")\n        lines.splice(0,1)\n        return lines.join(\"\\n\") \n      },\n    })\n  \n    clipboard.on('success', function (e) {\n      e.trigger._tippy.setContent('copied!')\n    })\n  \n    tippy.delegate('.doc .listingblock code', {\n      target: '.material-icons.codeCopyButton',\n      content: 'copy to clipboard',\n      animation: 'shift-away',\n      theme: 'clipboard',\n      delay: [500, 0],\n      placement: 'bottom',\n      hideOnClick: false,\n      onHidden: function (instance) {\n        instance.setContent('copy to clipboard')\n      },\n    })\n  })()\n  ",";(function () {\n  'use strict'\n\n  // create table of contents \n  var headers = document.querySelector('.doc .contents').querySelectorAll('h1, h2, h3, h4, h5, h6')\n  var toc = document.getElementById('toc')\n  for(var i = 0; i < headers.length; i++){\n      var header = headers[i]        \n      var li = document.createElement('li')\n      li.classList.add('toc-item')\n      li.classList.add(header.tagName)\n      li.innerText = header.innerText \n      li.setAttribute('headerId', header.getAttribute('id'))\n      li.addEventListener('click', function() {\n          var h, id = this.getAttribute('headerId')\n          if(id != 'null'){ h = document.getElementById(id) } \n          else { h = document.querySelector('h1') }\n          window.scroll({\n              top: h.offsetTop + 30, // 30 to account for fixed header height \n              left: 0,\n              behavior: 'smooth'\n          })\n          h.classList.add('toc-highlight')\n          setTimeout(function(){ h.classList.remove('toc-highlight') }, 2000)\n      })\n      toc.appendChild(li)\n  }\n\n  // enable highlighted toc\n  var referenceElement = document.querySelector('article').parentNode\n  window.addEventListener('scroll', function () {\n    var activeHeader, lastActiveHeader = document.querySelector('.toc-item.active')\n    var referencePoint = referenceElement.offsetTop + 108.1 \n    for (var i = (headers.length - 1); i >= 0; i--) {\n      var hTop = headers[i].getBoundingClientRect().top\n      if (hTop < referencePoint) {\n        var activeId = headers[i].getAttribute('id')\n        activeHeader = document.querySelector('.toc-item[headerId=\"' + activeId + '\"]')\n        break\n      }\n    }\n\n    // there is currently an active header and it has changed\n    if(activeHeader && activeHeader !== lastActiveHeader){\n      activeHeader.classList.add('active')\n      if(lastActiveHeader){\n        lastActiveHeader.classList.remove('active')\n      }\n    }\n  })\n\n})()\n  ","/**\n * lunr - http://lunrjs.com - A bit like Solr, but much smaller and not as bright - 2.3.3\n * Copyright (C) 2018 Oliver Nightingale\n * @license MIT\n */\n\n;(function(){\n\n  /**\n   * A convenience function for configuring and constructing\n   * a new lunr Index.\n   *\n   * A lunr.Builder instance is created and the pipeline setup\n   * with a trimmer, stop word filter and stemmer.\n   *\n   * This builder object is yielded to the configuration function\n   * that is passed as a parameter, allowing the list of fields\n   * and other builder parameters to be customised.\n   *\n   * All documents _must_ be added within the passed config function.\n   *\n   * @example\n   * var idx = lunr(function () {\n   *   this.field('title')\n   *   this.field('body')\n   *   this.ref('id')\n   *\n   *   documents.forEach(function (doc) {\n   *     this.add(doc)\n   *   }, this)\n   * })\n   *\n   * @see {@link lunr.Builder}\n   * @see {@link lunr.Pipeline}\n   * @see {@link lunr.trimmer}\n   * @see {@link lunr.stopWordFilter}\n   * @see {@link lunr.stemmer}\n   * @namespace {function} lunr\n   */\n  var lunr = function (config) {\n    var builder = new lunr.Builder\n  \n    builder.pipeline.add(\n      lunr.trimmer,\n      lunr.stopWordFilter,\n      lunr.stemmer\n    )\n  \n    builder.searchPipeline.add(\n      lunr.stemmer\n    )\n  \n    config.call(builder, builder)\n    return builder.build()\n  }\n  \n  lunr.version = \"2.3.3\"\n  /*!\n   * lunr.utils\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A namespace containing utils for the rest of the lunr library\n   * @namespace lunr.utils\n   */\n  lunr.utils = {}\n  \n  /**\n   * Print a warning message to the console.\n   *\n   * @param {String} message The message to be printed.\n   * @memberOf lunr.utils\n   * @function\n   */\n  lunr.utils.warn = (function (global) {\n    /* eslint-disable no-console */\n    return function (message) {\n      if (global.console && console.warn) {\n        console.warn(message)\n      }\n    }\n    /* eslint-enable no-console */\n  })(this)\n  \n  /**\n   * Convert an object to a string.\n   *\n   * In the case of `null` and `undefined` the function returns\n   * the empty string, in all other cases the result of calling\n   * `toString` on the passed object is returned.\n   *\n   * @param {Any} obj The object to convert to a string.\n   * @return {String} string representation of the passed object.\n   * @memberOf lunr.utils\n   */\n  lunr.utils.asString = function (obj) {\n    if (obj === void 0 || obj === null) {\n      return \"\"\n    } else {\n      return obj.toString()\n    }\n  }\n  \n  /**\n   * Clones an object.\n   *\n   * Will create a copy of an existing object such that any mutations\n   * on the copy cannot affect the original.\n   *\n   * Only shallow objects are supported, passing a nested object to this\n   * function will cause a TypeError.\n   *\n   * Objects with primitives, and arrays of primitives are supported.\n   *\n   * @param {Object} obj The object to clone.\n   * @return {Object} a clone of the passed object.\n   * @throws {TypeError} when a nested object is passed.\n   * @memberOf Utils\n   */\n  lunr.utils.clone = function (obj) {\n    if (obj === null || obj === undefined) {\n      return obj\n    }\n  \n    var clone = Object.create(null),\n        keys = Object.keys(obj)\n  \n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i],\n          val = obj[key]\n  \n      if (Array.isArray(val)) {\n        clone[key] = val.slice()\n        continue\n      }\n  \n      if (typeof val === 'string' ||\n          typeof val === 'number' ||\n          typeof val === 'boolean') {\n        clone[key] = val\n        continue\n      }\n  \n      throw new TypeError(\"clone is not deep and does not support nested objects\")\n    }\n  \n    return clone\n  }\n  lunr.FieldRef = function (docRef, fieldName, stringValue) {\n    this.docRef = docRef\n    this.fieldName = fieldName\n    this._stringValue = stringValue\n  }\n  \n  lunr.FieldRef.joiner = \"/\"\n  \n  lunr.FieldRef.fromString = function (s) {\n    var n = s.indexOf(lunr.FieldRef.joiner)\n  \n    if (n === -1) {\n      throw \"malformed field ref string\"\n    }\n  \n    var fieldRef = s.slice(0, n),\n        docRef = s.slice(n + 1)\n  \n    return new lunr.FieldRef (docRef, fieldRef, s)\n  }\n  \n  lunr.FieldRef.prototype.toString = function () {\n    if (this._stringValue == undefined) {\n      this._stringValue = this.fieldName + lunr.FieldRef.joiner + this.docRef\n    }\n  \n    return this._stringValue\n  }\n  /*!\n   * lunr.Set\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A lunr set.\n   *\n   * @constructor\n   */\n  lunr.Set = function (elements) {\n    this.elements = Object.create(null)\n  \n    if (elements) {\n      this.length = elements.length\n  \n      for (var i = 0; i < this.length; i++) {\n        this.elements[elements[i]] = true\n      }\n    } else {\n      this.length = 0\n    }\n  }\n  \n  /**\n   * A complete set that contains all elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n  lunr.Set.complete = {\n    intersect: function (other) {\n      return other\n    },\n  \n    union: function (other) {\n      return other\n    },\n  \n    contains: function () {\n      return true\n    }\n  }\n  \n  /**\n   * An empty set that contains no elements.\n   *\n   * @static\n   * @readonly\n   * @type {lunr.Set}\n   */\n  lunr.Set.empty = {\n    intersect: function () {\n      return this\n    },\n  \n    union: function (other) {\n      return other\n    },\n  \n    contains: function () {\n      return false\n    }\n  }\n  \n  /**\n   * Returns true if this set contains the specified object.\n   *\n   * @param {object} object - Object whose presence in this set is to be tested.\n   * @returns {boolean} - True if this set contains the specified object.\n   */\n  lunr.Set.prototype.contains = function (object) {\n    return !!this.elements[object]\n  }\n  \n  /**\n   * Returns a new set containing only the elements that are present in both\n   * this set and the specified set.\n   *\n   * @param {lunr.Set} other - set to intersect with this set.\n   * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\n   */\n  \n  lunr.Set.prototype.intersect = function (other) {\n    var a, b, elements, intersection = []\n  \n    if (other === lunr.Set.complete) {\n      return this\n    }\n  \n    if (other === lunr.Set.empty) {\n      return other\n    }\n  \n    if (this.length < other.length) {\n      a = this\n      b = other\n    } else {\n      a = other\n      b = this\n    }\n  \n    elements = Object.keys(a.elements)\n  \n    for (var i = 0; i < elements.length; i++) {\n      var element = elements[i]\n      if (element in b.elements) {\n        intersection.push(element)\n      }\n    }\n  \n    return new lunr.Set (intersection)\n  }\n  \n  /**\n   * Returns a new set combining the elements of this and the specified set.\n   *\n   * @param {lunr.Set} other - set to union with this set.\n   * @return {lunr.Set} a new set that is the union of this and the specified set.\n   */\n  \n  lunr.Set.prototype.union = function (other) {\n    if (other === lunr.Set.complete) {\n      return lunr.Set.complete\n    }\n  \n    if (other === lunr.Set.empty) {\n      return this\n    }\n  \n    return new lunr.Set(Object.keys(this.elements).concat(Object.keys(other.elements)))\n  }\n  /**\n   * A function to calculate the inverse document frequency for\n   * a posting. This is shared between the builder and the index\n   *\n   * @private\n   * @param {object} posting - The posting for a given term\n   * @param {number} documentCount - The total number of documents.\n   */\n  lunr.idf = function (posting, documentCount) {\n    var documentsWithTerm = 0\n  \n    for (var fieldName in posting) {\n      if (fieldName == '_index') continue // Ignore the term index, its not a field\n      documentsWithTerm += Object.keys(posting[fieldName]).length\n    }\n  \n    var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5)\n  \n    return Math.log(1 + Math.abs(x))\n  }\n  \n  /**\n   * A token wraps a string representation of a token\n   * as it is passed through the text processing pipeline.\n   *\n   * @constructor\n   * @param {string} [str=''] - The string token being wrapped.\n   * @param {object} [metadata={}] - Metadata associated with this token.\n   */\n  lunr.Token = function (str, metadata) {\n    this.str = str || \"\"\n    this.metadata = metadata || {}\n  }\n  \n  /**\n   * Returns the token string that is being wrapped by this object.\n   *\n   * @returns {string}\n   */\n  lunr.Token.prototype.toString = function () {\n    return this.str\n  }\n  \n  /**\n   * A token update function is used when updating or optionally\n   * when cloning a token.\n   *\n   * @callback lunr.Token~updateFunction\n   * @param {string} str - The string representation of the token.\n   * @param {Object} metadata - All metadata associated with this token.\n   */\n  \n  /**\n   * Applies the given function to the wrapped string token.\n   *\n   * @example\n   * token.update(function (str, metadata) {\n   *   return str.toUpperCase()\n   * })\n   *\n   * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\n   * @returns {lunr.Token}\n   */\n  lunr.Token.prototype.update = function (fn) {\n    this.str = fn(this.str, this.metadata)\n    return this\n  }\n  \n  /**\n   * Creates a clone of this token. Optionally a function can be\n   * applied to the cloned token.\n   *\n   * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\n   * @returns {lunr.Token}\n   */\n  lunr.Token.prototype.clone = function (fn) {\n    fn = fn || function (s) { return s }\n    return new lunr.Token (fn(this.str, this.metadata), this.metadata)\n  }\n  /*!\n   * lunr.tokenizer\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A function for splitting a string into tokens ready to be inserted into\n   * the search index. Uses `lunr.tokenizer.separator` to split strings, change\n   * the value of this property to change how strings are split into tokens.\n   *\n   * This tokenizer will convert its parameter to a string by calling `toString` and\n   * then will split this string on the character in `lunr.tokenizer.separator`.\n   * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\n   *\n   * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\n   * added as metadata to every token that is created from the object to be tokenized.\n   *\n   * @static\n   * @param {?(string|object|object[])} obj - The object to convert into tokens\n   * @param {?object} metadata - Optional metadata to associate with every token\n   * @returns {lunr.Token[]}\n   * @see {@link lunr.Pipeline}\n   */\n  lunr.tokenizer = function (obj, metadata) {\n    if (obj == null || obj == undefined) {\n      return []\n    }\n  \n    if (Array.isArray(obj)) {\n      return obj.map(function (t) {\n        return new lunr.Token(\n          lunr.utils.asString(t).toLowerCase(),\n          lunr.utils.clone(metadata)\n        )\n      })\n    }\n  \n    var str = obj.toString().trim().toLowerCase(),\n        len = str.length,\n        tokens = []\n  \n    for (var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++) {\n      var char = str.charAt(sliceEnd),\n          sliceLength = sliceEnd - sliceStart\n  \n      if ((char.match(lunr.tokenizer.separator) || sliceEnd == len)) {\n  \n        if (sliceLength > 0) {\n          var tokenMetadata = lunr.utils.clone(metadata) || {}\n          tokenMetadata[\"position\"] = [sliceStart, sliceLength]\n          tokenMetadata[\"index\"] = tokens.length\n  \n          tokens.push(\n            new lunr.Token (\n              str.slice(sliceStart, sliceEnd),\n              tokenMetadata\n            )\n          )\n        }\n  \n        sliceStart = sliceEnd + 1\n      }\n  \n    }\n  \n    return tokens\n  }\n  \n  /**\n   * The separator used to split a string into tokens. Override this property to change the behaviour of\n   * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n   *\n   * @static\n   * @see lunr.tokenizer\n   */\n  lunr.tokenizer.separator = /[\\s\\-]+/\n  /*!\n   * lunr.Pipeline\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.Pipelines maintain an ordered list of functions to be applied to all\n   * tokens in documents entering the search index and queries being ran against\n   * the index.\n   *\n   * An instance of lunr.Index created with the lunr shortcut will contain a\n   * pipeline with a stop word filter and an English language stemmer. Extra\n   * functions can be added before or after either of these functions or these\n   * default functions can be removed.\n   *\n   * When run the pipeline will call each function in turn, passing a token, the\n   * index of that token in the original list of all tokens and finally a list of\n   * all the original tokens.\n   *\n   * The output of functions in the pipeline will be passed to the next function\n   * in the pipeline. To exclude a token from entering the index the function\n   * should return undefined, the rest of the pipeline will not be called with\n   * this token.\n   *\n   * For serialisation of pipelines to work, all functions used in an instance of\n   * a pipeline should be registered with lunr.Pipeline. Registered functions can\n   * then be loaded. If trying to load a serialised pipeline that uses functions\n   * that are not registered an error will be thrown.\n   *\n   * If not planning on serialising the pipeline then registering pipeline functions\n   * is not necessary.\n   *\n   * @constructor\n   */\n  lunr.Pipeline = function () {\n    this._stack = []\n  }\n  \n  lunr.Pipeline.registeredFunctions = Object.create(null)\n  \n  /**\n   * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\n   * string as well as all known metadata. A pipeline function can mutate the token string\n   * or mutate (or add) metadata for a given token.\n   *\n   * A pipeline function can indicate that the passed token should be discarded by returning\n   * null. This token will not be passed to any downstream pipeline functions and will not be\n   * added to the index.\n   *\n   * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\n   * to any downstream pipeline functions and all will returned tokens will be added to the index.\n   *\n   * Any number of pipeline functions may be chained together using a lunr.Pipeline.\n   *\n   * @interface lunr.PipelineFunction\n   * @param {lunr.Token} token - A token from the document being processed.\n   * @param {number} i - The index of this token in the complete list of tokens for this document/field.\n   * @param {lunr.Token[]} tokens - All tokens for this document/field.\n   * @returns {(?lunr.Token|lunr.Token[])}\n   */\n  \n  /**\n   * Register a function with the pipeline.\n   *\n   * Functions that are used in the pipeline should be registered if the pipeline\n   * needs to be serialised, or a serialised pipeline needs to be loaded.\n   *\n   * Registering a function does not add it to a pipeline, functions must still be\n   * added to instances of the pipeline for them to be used when running a pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @param {String} label - The label to register this function with\n   */\n  lunr.Pipeline.registerFunction = function (fn, label) {\n    if (label in this.registeredFunctions) {\n      lunr.utils.warn('Overwriting existing registered function: ' + label)\n    }\n  \n    fn.label = label\n    lunr.Pipeline.registeredFunctions[fn.label] = fn\n  }\n  \n  /**\n   * Warns if the function is not registered as a Pipeline function.\n   *\n   * @param {lunr.PipelineFunction} fn - The function to check for.\n   * @private\n   */\n  lunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n    var isRegistered = fn.label && (fn.label in this.registeredFunctions)\n  \n    if (!isRegistered) {\n      lunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn)\n    }\n  }\n  \n  /**\n   * Loads a previously serialised pipeline.\n   *\n   * All functions to be loaded must already be registered with lunr.Pipeline.\n   * If any function from the serialised data has not been registered then an\n   * error will be thrown.\n   *\n   * @param {Object} serialised - The serialised pipeline to load.\n   * @returns {lunr.Pipeline}\n   */\n  lunr.Pipeline.load = function (serialised) {\n    var pipeline = new lunr.Pipeline\n  \n    serialised.forEach(function (fnName) {\n      var fn = lunr.Pipeline.registeredFunctions[fnName]\n  \n      if (fn) {\n        pipeline.add(fn)\n      } else {\n        throw new Error('Cannot load unregistered function: ' + fnName)\n      }\n    })\n  \n    return pipeline\n  }\n  \n  /**\n   * Adds new functions to the end of the pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.add = function () {\n    var fns = Array.prototype.slice.call(arguments)\n  \n    fns.forEach(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n      this._stack.push(fn)\n    }, this)\n  }\n  \n  /**\n   * Adds a single function after a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.after = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n  \n    var pos = this._stack.indexOf(existingFn)\n    if (pos == -1) {\n      throw new Error('Cannot find existingFn')\n    }\n  \n    pos = pos + 1\n    this._stack.splice(pos, 0, newFn)\n  }\n  \n  /**\n   * Adds a single function before a function that already exists in the\n   * pipeline.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n   * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n   */\n  lunr.Pipeline.prototype.before = function (existingFn, newFn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n  \n    var pos = this._stack.indexOf(existingFn)\n    if (pos == -1) {\n      throw new Error('Cannot find existingFn')\n    }\n  \n    this._stack.splice(pos, 0, newFn)\n  }\n  \n  /**\n   * Removes a function from the pipeline.\n   *\n   * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\n   */\n  lunr.Pipeline.prototype.remove = function (fn) {\n    var pos = this._stack.indexOf(fn)\n    if (pos == -1) {\n      return\n    }\n  \n    this._stack.splice(pos, 1)\n  }\n  \n  /**\n   * Runs the current list of functions that make up the pipeline against the\n   * passed tokens.\n   *\n   * @param {Array} tokens The tokens to run through the pipeline.\n   * @returns {Array}\n   */\n  lunr.Pipeline.prototype.run = function (tokens) {\n    var stackLength = this._stack.length\n  \n    for (var i = 0; i < stackLength; i++) {\n      var fn = this._stack[i]\n      var memo = []\n  \n      for (var j = 0; j < tokens.length; j++) {\n        var result = fn(tokens[j], j, tokens)\n  \n        if (result === void 0 || result === '') continue\n  \n        if (result instanceof Array) {\n          for (var k = 0; k < result.length; k++) {\n            memo.push(result[k])\n          }\n        } else {\n          memo.push(result)\n        }\n      }\n  \n      tokens = memo\n    }\n  \n    return tokens\n  }\n  \n  /**\n   * Convenience method for passing a string through a pipeline and getting\n   * strings out. This method takes care of wrapping the passed string in a\n   * token and mapping the resulting tokens back to strings.\n   *\n   * @param {string} str - The string to pass through the pipeline.\n   * @param {?object} metadata - Optional metadata to associate with the token\n   * passed to the pipeline.\n   * @returns {string[]}\n   */\n  lunr.Pipeline.prototype.runString = function (str, metadata) {\n    var token = new lunr.Token (str, metadata)\n  \n    return this.run([token]).map(function (t) {\n      return t.toString()\n    })\n  }\n  \n  /**\n   * Resets the pipeline by removing any existing processors.\n   *\n   */\n  lunr.Pipeline.prototype.reset = function () {\n    this._stack = []\n  }\n  \n  /**\n   * Returns a representation of the pipeline ready for serialisation.\n   *\n   * Logs a warning if the function has not been registered.\n   *\n   * @returns {Array}\n   */\n  lunr.Pipeline.prototype.toJSON = function () {\n    return this._stack.map(function (fn) {\n      lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n  \n      return fn.label\n    })\n  }\n  /*!\n   * lunr.Vector\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A vector is used to construct the vector space of documents and queries. These\n   * vectors support operations to determine the similarity between two documents or\n   * a document and a query.\n   *\n   * Normally no parameters are required for initializing a vector, but in the case of\n   * loading a previously dumped vector the raw elements can be provided to the constructor.\n   *\n   * For performance reasons vectors are implemented with a flat array, where an elements\n   * index is immediately followed by its value. E.g. [index, value, index, value]. This\n   * allows the underlying array to be as sparse as possible and still offer decent\n   * performance when being used for vector calculations.\n   *\n   * @constructor\n   * @param {Number[]} [elements] - The flat list of element index and element value pairs.\n   */\n  lunr.Vector = function (elements) {\n    this._magnitude = 0\n    this.elements = elements || []\n  }\n  \n  \n  /**\n   * Calculates the position within the vector to insert a given index.\n   *\n   * This is used internally by insert and upsert. If there are duplicate indexes then\n   * the position is returned as if the value for that index were to be updated, but it\n   * is the callers responsibility to check whether there is a duplicate at that index\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.positionForIndex = function (index) {\n    // For an empty vector the tuple can be inserted at the beginning\n    if (this.elements.length == 0) {\n      return 0\n    }\n  \n    var start = 0,\n        end = this.elements.length / 2,\n        sliceLength = end - start,\n        pivotPoint = Math.floor(sliceLength / 2),\n        pivotIndex = this.elements[pivotPoint * 2]\n  \n    while (sliceLength > 1) {\n      if (pivotIndex < index) {\n        start = pivotPoint\n      }\n  \n      if (pivotIndex > index) {\n        end = pivotPoint\n      }\n  \n      if (pivotIndex == index) {\n        break\n      }\n  \n      sliceLength = end - start\n      pivotPoint = start + Math.floor(sliceLength / 2)\n      pivotIndex = this.elements[pivotPoint * 2]\n    }\n  \n    if (pivotIndex == index) {\n      return pivotPoint * 2\n    }\n  \n    if (pivotIndex > index) {\n      return pivotPoint * 2\n    }\n  \n    if (pivotIndex < index) {\n      return (pivotPoint + 1) * 2\n    }\n  }\n  \n  /**\n   * Inserts an element at an index within the vector.\n   *\n   * Does not allow duplicates, will throw an error if there is already an entry\n   * for this index.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   */\n  lunr.Vector.prototype.insert = function (insertIdx, val) {\n    this.upsert(insertIdx, val, function () {\n      throw \"duplicate index\"\n    })\n  }\n  \n  /**\n   * Inserts or updates an existing index within the vector.\n   *\n   * @param {Number} insertIdx - The index at which the element should be inserted.\n   * @param {Number} val - The value to be inserted into the vector.\n   * @param {function} fn - A function that is called for updates, the existing value and the\n   * requested value are passed as arguments\n   */\n  lunr.Vector.prototype.upsert = function (insertIdx, val, fn) {\n    this._magnitude = 0\n    var position = this.positionForIndex(insertIdx)\n  \n    if (this.elements[position] == insertIdx) {\n      this.elements[position + 1] = fn(this.elements[position + 1], val)\n    } else {\n      this.elements.splice(position, 0, insertIdx, val)\n    }\n  }\n  \n  /**\n   * Calculates the magnitude of this vector.\n   *\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.magnitude = function () {\n    if (this._magnitude) return this._magnitude\n  \n    var sumOfSquares = 0,\n        elementsLength = this.elements.length\n  \n    for (var i = 1; i < elementsLength; i += 2) {\n      var val = this.elements[i]\n      sumOfSquares += val * val\n    }\n  \n    return this._magnitude = Math.sqrt(sumOfSquares)\n  }\n  \n  /**\n   * Calculates the dot product of this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.dot = function (otherVector) {\n    var dotProduct = 0,\n        a = this.elements, b = otherVector.elements,\n        aLen = a.length, bLen = b.length,\n        aVal = 0, bVal = 0,\n        i = 0, j = 0\n  \n    while (i < aLen && j < bLen) {\n      aVal = a[i], bVal = b[j]\n      if (aVal < bVal) {\n        i += 2\n      } else if (aVal > bVal) {\n        j += 2\n      } else if (aVal == bVal) {\n        dotProduct += a[i + 1] * b[j + 1]\n        i += 2\n        j += 2\n      }\n    }\n  \n    return dotProduct\n  }\n  \n  /**\n   * Calculates the similarity between this vector and another vector.\n   *\n   * @param {lunr.Vector} otherVector - The other vector to calculate the\n   * similarity with.\n   * @returns {Number}\n   */\n  lunr.Vector.prototype.similarity = function (otherVector) {\n    return this.dot(otherVector) / this.magnitude() || 0\n  }\n  \n  /**\n   * Converts the vector to an array of the elements within the vector.\n   *\n   * @returns {Number[]}\n   */\n  lunr.Vector.prototype.toArray = function () {\n    var output = new Array (this.elements.length / 2)\n  \n    for (var i = 1, j = 0; i < this.elements.length; i += 2, j++) {\n      output[j] = this.elements[i]\n    }\n  \n    return output\n  }\n  \n  /**\n   * A JSON serializable representation of the vector.\n   *\n   * @returns {Number[]}\n   */\n  lunr.Vector.prototype.toJSON = function () {\n    return this.elements\n  }\n  /* eslint-disable */\n  /*!\n   * lunr.stemmer\n   * Copyright (C) 2018 Oliver Nightingale\n   * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n   */\n  \n  /**\n   * lunr.stemmer is an english language stemmer, this is a JavaScript\n   * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token - The string to stem\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   * @function\n   */\n  lunr.stemmer = (function(){\n    var step2list = {\n        \"ational\" : \"ate\",\n        \"tional\" : \"tion\",\n        \"enci\" : \"ence\",\n        \"anci\" : \"ance\",\n        \"izer\" : \"ize\",\n        \"bli\" : \"ble\",\n        \"alli\" : \"al\",\n        \"entli\" : \"ent\",\n        \"eli\" : \"e\",\n        \"ousli\" : \"ous\",\n        \"ization\" : \"ize\",\n        \"ation\" : \"ate\",\n        \"ator\" : \"ate\",\n        \"alism\" : \"al\",\n        \"iveness\" : \"ive\",\n        \"fulness\" : \"ful\",\n        \"ousness\" : \"ous\",\n        \"aliti\" : \"al\",\n        \"iviti\" : \"ive\",\n        \"biliti\" : \"ble\",\n        \"logi\" : \"log\"\n      },\n  \n      step3list = {\n        \"icate\" : \"ic\",\n        \"ative\" : \"\",\n        \"alize\" : \"al\",\n        \"iciti\" : \"ic\",\n        \"ical\" : \"ic\",\n        \"ful\" : \"\",\n        \"ness\" : \"\"\n      },\n  \n      c = \"[^aeiou]\",          // consonant\n      v = \"[aeiouy]\",          // vowel\n      C = c + \"[^aeiouy]*\",    // consonant sequence\n      V = v + \"[aeiou]*\",      // vowel sequence\n  \n      mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n      meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n      mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n      s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n  \n    var re_mgr0 = new RegExp(mgr0);\n    var re_mgr1 = new RegExp(mgr1);\n    var re_meq1 = new RegExp(meq1);\n    var re_s_v = new RegExp(s_v);\n  \n    var re_1a = /^(.+?)(ss|i)es$/;\n    var re2_1a = /^(.+?)([^s])s$/;\n    var re_1b = /^(.+?)eed$/;\n    var re2_1b = /^(.+?)(ed|ing)$/;\n    var re_1b_2 = /.$/;\n    var re2_1b_2 = /(at|bl|iz)$/;\n    var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n    var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n  \n    var re_1c = /^(.+?[^aeiou])y$/;\n    var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n  \n    var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n  \n    var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n    var re2_4 = /^(.+?)(s|t)(ion)$/;\n  \n    var re_5 = /^(.+?)e$/;\n    var re_5_1 = /ll$/;\n    var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n  \n    var porterStemmer = function porterStemmer(w) {\n      var stem,\n        suffix,\n        firstch,\n        re,\n        re2,\n        re3,\n        re4;\n  \n      if (w.length < 3) { return w; }\n  \n      firstch = w.substr(0,1);\n      if (firstch == \"y\") {\n        w = firstch.toUpperCase() + w.substr(1);\n      }\n  \n      // Step 1a\n      re = re_1a\n      re2 = re2_1a;\n  \n      if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n      else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n  \n      // Step 1b\n      re = re_1b;\n      re2 = re2_1b;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        re = re_mgr0;\n        if (re.test(fp[1])) {\n          re = re_1b_2;\n          w = w.replace(re,\"\");\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1];\n        re2 = re_s_v;\n        if (re2.test(stem)) {\n          w = stem;\n          re2 = re2_1b_2;\n          re3 = re3_1b_2;\n          re4 = re4_1b_2;\n          if (re2.test(w)) { w = w + \"e\"; }\n          else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n          else if (re4.test(w)) { w = w + \"e\"; }\n        }\n      }\n  \n      // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n      re = re_1c;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        w = stem + \"i\";\n      }\n  \n      // Step 2\n      re = re_2;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n        if (re.test(stem)) {\n          w = stem + step2list[suffix];\n        }\n      }\n  \n      // Step 3\n      re = re_3;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        suffix = fp[2];\n        re = re_mgr0;\n        if (re.test(stem)) {\n          w = stem + step3list[suffix];\n        }\n      }\n  \n      // Step 4\n      re = re_4;\n      re2 = re2_4;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n        if (re.test(stem)) {\n          w = stem;\n        }\n      } else if (re2.test(w)) {\n        var fp = re2.exec(w);\n        stem = fp[1] + fp[2];\n        re2 = re_mgr1;\n        if (re2.test(stem)) {\n          w = stem;\n        }\n      }\n  \n      // Step 5\n      re = re_5;\n      if (re.test(w)) {\n        var fp = re.exec(w);\n        stem = fp[1];\n        re = re_mgr1;\n        re2 = re_meq1;\n        re3 = re3_5;\n        if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n          w = stem;\n        }\n      }\n  \n      re = re_5_1;\n      re2 = re_mgr1;\n      if (re.test(w) && re2.test(w)) {\n        re = re_1b_2;\n        w = w.replace(re,\"\");\n      }\n  \n      // and turn initial Y back to y\n  \n      if (firstch == \"y\") {\n        w = firstch.toLowerCase() + w.substr(1);\n      }\n  \n      return w;\n    };\n  \n    return function (token) {\n      return token.update(porterStemmer);\n    }\n  })();\n  \n  lunr.Pipeline.registerFunction(lunr.stemmer, 'stemmer')\n  /*!\n   * lunr.stopWordFilter\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\n   * list of stop words.\n   *\n   * The built in lunr.stopWordFilter is built using this generator and can be used\n   * to generate custom stopWordFilters for applications or non English languages.\n   *\n   * @function\n   * @param {Array} token The token to pass through the filter\n   * @returns {lunr.PipelineFunction}\n   * @see lunr.Pipeline\n   * @see lunr.stopWordFilter\n   */\n  lunr.generateStopWordFilter = function (stopWords) {\n    var words = stopWords.reduce(function (memo, stopWord) {\n      memo[stopWord] = stopWord\n      return memo\n    }, {})\n  \n    return function (token) {\n      if (token && words[token.toString()] !== token.toString()) return token\n    }\n  }\n  \n  /**\n   * lunr.stopWordFilter is an English language stop word list filter, any words\n   * contained in the list will not be passed through the filter.\n   *\n   * This is intended to be used in the Pipeline. If the token does not pass the\n   * filter then undefined will be returned.\n   *\n   * @function\n   * @implements {lunr.PipelineFunction}\n   * @params {lunr.Token} token - A token to check for being a stop word.\n   * @returns {lunr.Token}\n   * @see {@link lunr.Pipeline}\n   */\n  lunr.stopWordFilter = lunr.generateStopWordFilter([\n    'a',\n    'able',\n    'about',\n    'across',\n    'after',\n    'all',\n    'almost',\n    'also',\n    'am',\n    'among',\n    'an',\n    'and',\n    'any',\n    'are',\n    'as',\n    'at',\n    'be',\n    'because',\n    'been',\n    'but',\n    'by',\n    'can',\n    'cannot',\n    'could',\n    'dear',\n    'did',\n    'do',\n    'does',\n    'either',\n    'else',\n    'ever',\n    'every',\n    'for',\n    'from',\n    'get',\n    'got',\n    'had',\n    'has',\n    'have',\n    'he',\n    'her',\n    'hers',\n    'him',\n    'his',\n    'how',\n    'however',\n    'i',\n    'if',\n    'in',\n    'into',\n    'is',\n    'it',\n    'its',\n    'just',\n    'least',\n    'let',\n    'like',\n    'likely',\n    'may',\n    'me',\n    'might',\n    'most',\n    'must',\n    'my',\n    'neither',\n    'no',\n    'nor',\n    'not',\n    'of',\n    'off',\n    'often',\n    'on',\n    'only',\n    'or',\n    'other',\n    'our',\n    'own',\n    'rather',\n    'said',\n    'say',\n    'says',\n    'she',\n    'should',\n    'since',\n    'so',\n    'some',\n    'than',\n    'that',\n    'the',\n    'their',\n    'them',\n    'then',\n    'there',\n    'these',\n    'they',\n    'this',\n    'tis',\n    'to',\n    'too',\n    'twas',\n    'us',\n    'wants',\n    'was',\n    'we',\n    'were',\n    'what',\n    'when',\n    'where',\n    'which',\n    'while',\n    'who',\n    'whom',\n    'why',\n    'will',\n    'with',\n    'would',\n    'yet',\n    'you',\n    'your'\n  ])\n  \n  lunr.Pipeline.registerFunction(lunr.stopWordFilter, 'stopWordFilter')\n  /*!\n   * lunr.trimmer\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.trimmer is a pipeline function for trimming non word\n   * characters from the beginning and end of tokens before they\n   * enter the index.\n   *\n   * This implementation may not work correctly for non latin\n   * characters and should either be removed or adapted for use\n   * with languages with non-latin characters.\n   *\n   * @static\n   * @implements {lunr.PipelineFunction}\n   * @param {lunr.Token} token The token to pass through the filter\n   * @returns {lunr.Token}\n   * @see lunr.Pipeline\n   */\n  lunr.trimmer = function (token) {\n    return token.update(function (s) {\n      return s.replace(/^\\W+/, '').replace(/\\W+$/, '')\n    })\n  }\n  \n  lunr.Pipeline.registerFunction(lunr.trimmer, 'trimmer')\n  /*!\n   * lunr.TokenSet\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * A token set is used to store the unique list of all tokens\n   * within an index. Token sets are also used to represent an\n   * incoming query to the index, this query token set and index\n   * token set are then intersected to find which tokens to look\n   * up in the inverted index.\n   *\n   * A token set can hold multiple tokens, as in the case of the\n   * index token set, or it can hold a single token as in the\n   * case of a simple query token set.\n   *\n   * Additionally token sets are used to perform wildcard matching.\n   * Leading, contained and trailing wildcards are supported, and\n   * from this edit distance matching can also be provided.\n   *\n   * Token sets are implemented as a minimal finite state automata,\n   * where both common prefixes and suffixes are shared between tokens.\n   * This helps to reduce the space used for storing the token set.\n   *\n   * @constructor\n   */\n  lunr.TokenSet = function () {\n    this.final = false\n    this.edges = {}\n    this.id = lunr.TokenSet._nextId\n    lunr.TokenSet._nextId += 1\n  }\n  \n  /**\n   * Keeps track of the next, auto increment, identifier to assign\n   * to a new tokenSet.\n   *\n   * TokenSets require a unique identifier to be correctly minimised.\n   *\n   * @private\n   */\n  lunr.TokenSet._nextId = 1\n  \n  /**\n   * Creates a TokenSet instance from the given sorted array of words.\n   *\n   * @param {String[]} arr - A sorted array of strings to create the set from.\n   * @returns {lunr.TokenSet}\n   * @throws Will throw an error if the input array is not sorted.\n   */\n  lunr.TokenSet.fromArray = function (arr) {\n    var builder = new lunr.TokenSet.Builder\n  \n    for (var i = 0, len = arr.length; i < len; i++) {\n      builder.insert(arr[i])\n    }\n  \n    builder.finish()\n    return builder.root\n  }\n  \n  /**\n   * Creates a token set from a query clause.\n   *\n   * @private\n   * @param {Object} clause - A single clause from lunr.Query.\n   * @param {string} clause.term - The query clause term.\n   * @param {number} [clause.editDistance] - The optional edit distance for the term.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.fromClause = function (clause) {\n    if ('editDistance' in clause) {\n      return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance)\n    } else {\n      return lunr.TokenSet.fromString(clause.term)\n    }\n  }\n  \n  /**\n   * Creates a token set representing a single string with a specified\n   * edit distance.\n   *\n   * Insertions, deletions, substitutions and transpositions are each\n   * treated as an edit distance of 1.\n   *\n   * Increasing the allowed edit distance will have a dramatic impact\n   * on the performance of both creating and intersecting these TokenSets.\n   * It is advised to keep the edit distance less than 3.\n   *\n   * @param {string} str - The string to create the token set from.\n   * @param {number} editDistance - The allowed edit distance to match.\n   * @returns {lunr.Vector}\n   */\n  lunr.TokenSet.fromFuzzyString = function (str, editDistance) {\n    var root = new lunr.TokenSet\n  \n    var stack = [{\n      node: root,\n      editsRemaining: editDistance,\n      str: str\n    }]\n  \n    while (stack.length) {\n      var frame = stack.pop()\n  \n      // no edit\n      if (frame.str.length > 0) {\n        var char = frame.str.charAt(0),\n            noEditNode\n  \n        if (char in frame.node.edges) {\n          noEditNode = frame.node.edges[char]\n        } else {\n          noEditNode = new lunr.TokenSet\n          frame.node.edges[char] = noEditNode\n        }\n  \n        if (frame.str.length == 1) {\n          noEditNode.final = true\n        } else {\n          stack.push({\n            node: noEditNode,\n            editsRemaining: frame.editsRemaining,\n            str: frame.str.slice(1)\n          })\n        }\n      }\n  \n      // deletion\n      // can only do a deletion if we have enough edits remaining\n      // and if there are characters left to delete in the string\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\n        var char = frame.str.charAt(1),\n            deletionNode\n  \n        if (char in frame.node.edges) {\n          deletionNode = frame.node.edges[char]\n        } else {\n          deletionNode = new lunr.TokenSet\n          frame.node.edges[char] = deletionNode\n        }\n  \n        if (frame.str.length <= 2) {\n          deletionNode.final = true\n        } else {\n          stack.push({\n            node: deletionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str.slice(2)\n          })\n        }\n      }\n  \n      // deletion\n      // just removing the last character from the str\n      if (frame.editsRemaining > 0 && frame.str.length == 1) {\n        frame.node.final = true\n      }\n  \n      // substitution\n      // can only do a substitution if we have enough edits remaining\n      // and if there are characters left to substitute\n      if (frame.editsRemaining > 0 && frame.str.length >= 1) {\n        if (\"*\" in frame.node.edges) {\n          var substitutionNode = frame.node.edges[\"*\"]\n        } else {\n          var substitutionNode = new lunr.TokenSet\n          frame.node.edges[\"*\"] = substitutionNode\n        }\n  \n        if (frame.str.length == 1) {\n          substitutionNode.final = true\n        } else {\n          stack.push({\n            node: substitutionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str.slice(1)\n          })\n        }\n      }\n  \n      // insertion\n      // can only do insertion if there are edits remaining\n      if (frame.editsRemaining > 0) {\n        if (\"*\" in frame.node.edges) {\n          var insertionNode = frame.node.edges[\"*\"]\n        } else {\n          var insertionNode = new lunr.TokenSet\n          frame.node.edges[\"*\"] = insertionNode\n        }\n  \n        if (frame.str.length == 0) {\n          insertionNode.final = true\n        } else {\n          stack.push({\n            node: insertionNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: frame.str\n          })\n        }\n      }\n  \n      // transposition\n      // can only do a transposition if there are edits remaining\n      // and there are enough characters to transpose\n      if (frame.editsRemaining > 0 && frame.str.length > 1) {\n        var charA = frame.str.charAt(0),\n            charB = frame.str.charAt(1),\n            transposeNode\n  \n        if (charB in frame.node.edges) {\n          transposeNode = frame.node.edges[charB]\n        } else {\n          transposeNode = new lunr.TokenSet\n          frame.node.edges[charB] = transposeNode\n        }\n  \n        if (frame.str.length == 1) {\n          transposeNode.final = true\n        } else {\n          stack.push({\n            node: transposeNode,\n            editsRemaining: frame.editsRemaining - 1,\n            str: charA + frame.str.slice(2)\n          })\n        }\n      }\n    }\n  \n    return root\n  }\n  \n  /**\n   * Creates a TokenSet from a string.\n   *\n   * The string may contain one or more wildcard characters (*)\n   * that will allow wildcard matching when intersecting with\n   * another TokenSet.\n   *\n   * @param {string} str - The string to create a TokenSet from.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.fromString = function (str) {\n    var node = new lunr.TokenSet,\n        root = node\n  \n    /*\n     * Iterates through all characters within the passed string\n     * appending a node for each character.\n     *\n     * When a wildcard character is found then a self\n     * referencing edge is introduced to continually match\n     * any number of any characters.\n     */\n    for (var i = 0, len = str.length; i < len; i++) {\n      var char = str[i],\n          final = (i == len - 1)\n  \n      if (char == \"*\") {\n        node.edges[char] = node\n        node.final = final\n  \n      } else {\n        var next = new lunr.TokenSet\n        next.final = final\n  \n        node.edges[char] = next\n        node = next\n      }\n    }\n  \n    return root\n  }\n  \n  /**\n   * Converts this TokenSet into an array of strings\n   * contained within the TokenSet.\n   *\n   * @returns {string[]}\n   */\n  lunr.TokenSet.prototype.toArray = function () {\n    var words = []\n  \n    var stack = [{\n      prefix: \"\",\n      node: this\n    }]\n  \n    while (stack.length) {\n      var frame = stack.pop(),\n          edges = Object.keys(frame.node.edges),\n          len = edges.length\n  \n      if (frame.node.final) {\n        /* In Safari, at this point the prefix is sometimes corrupted, see:\n         * https://github.com/olivernn/lunr.js/issues/279 Calling any\n         * String.prototype method forces Safari to \"cast\" this string to what\n         * it's supposed to be, fixing the bug. */\n        frame.prefix.charAt(0)\n        words.push(frame.prefix)\n      }\n  \n      for (var i = 0; i < len; i++) {\n        var edge = edges[i]\n  \n        stack.push({\n          prefix: frame.prefix.concat(edge),\n          node: frame.node.edges[edge]\n        })\n      }\n    }\n  \n    return words\n  }\n  \n  /**\n   * Generates a string representation of a TokenSet.\n   *\n   * This is intended to allow TokenSets to be used as keys\n   * in objects, largely to aid the construction and minimisation\n   * of a TokenSet. As such it is not designed to be a human\n   * friendly representation of the TokenSet.\n   *\n   * @returns {string}\n   */\n  lunr.TokenSet.prototype.toString = function () {\n    // NOTE: Using Object.keys here as this.edges is very likely\n    // to enter 'hash-mode' with many keys being added\n    //\n    // avoiding a for-in loop here as it leads to the function\n    // being de-optimised (at least in V8). From some simple\n    // benchmarks the performance is comparable, but allowing\n    // V8 to optimize may mean easy performance wins in the future.\n  \n    if (this._str) {\n      return this._str\n    }\n  \n    var str = this.final ? '1' : '0',\n        labels = Object.keys(this.edges).sort(),\n        len = labels.length\n  \n    for (var i = 0; i < len; i++) {\n      var label = labels[i],\n          node = this.edges[label]\n  \n      str = str + label + node.id\n    }\n  \n    return str\n  }\n  \n  /**\n   * Returns a new TokenSet that is the intersection of\n   * this TokenSet and the passed TokenSet.\n   *\n   * This intersection will take into account any wildcards\n   * contained within the TokenSet.\n   *\n   * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\n   * @returns {lunr.TokenSet}\n   */\n  lunr.TokenSet.prototype.intersect = function (b) {\n    var output = new lunr.TokenSet,\n        frame = undefined\n  \n    var stack = [{\n      qNode: b,\n      output: output,\n      node: this\n    }]\n  \n    while (stack.length) {\n      frame = stack.pop()\n  \n      // NOTE: As with the #toString method, we are using\n      // Object.keys and a for loop instead of a for-in loop\n      // as both of these objects enter 'hash' mode, causing\n      // the function to be de-optimised in V8\n      var qEdges = Object.keys(frame.qNode.edges),\n          qLen = qEdges.length,\n          nEdges = Object.keys(frame.node.edges),\n          nLen = nEdges.length\n  \n      for (var q = 0; q < qLen; q++) {\n        var qEdge = qEdges[q]\n  \n        for (var n = 0; n < nLen; n++) {\n          var nEdge = nEdges[n]\n  \n          if (nEdge == qEdge || qEdge == '*') {\n            var node = frame.node.edges[nEdge],\n                qNode = frame.qNode.edges[qEdge],\n                final = node.final && qNode.final,\n                next = undefined\n  \n            if (nEdge in frame.output.edges) {\n              // an edge already exists for this character\n              // no need to create a new node, just set the finality\n              // bit unless this node is already final\n              next = frame.output.edges[nEdge]\n              next.final = next.final || final\n  \n            } else {\n              // no edge exists yet, must create one\n              // set the finality bit and insert it\n              // into the output\n              next = new lunr.TokenSet\n              next.final = final\n              frame.output.edges[nEdge] = next\n            }\n  \n            stack.push({\n              qNode: qNode,\n              output: next,\n              node: node\n            })\n          }\n        }\n      }\n    }\n  \n    return output\n  }\n  lunr.TokenSet.Builder = function () {\n    this.previousWord = \"\"\n    this.root = new lunr.TokenSet\n    this.uncheckedNodes = []\n    this.minimizedNodes = {}\n  }\n  \n  lunr.TokenSet.Builder.prototype.insert = function (word) {\n    var node,\n        commonPrefix = 0\n  \n    if (word < this.previousWord) {\n      throw new Error (\"Out of order word insertion\")\n    }\n  \n    for (var i = 0; i < word.length && i < this.previousWord.length; i++) {\n      if (word[i] != this.previousWord[i]) break\n      commonPrefix++\n    }\n  \n    this.minimize(commonPrefix)\n  \n    if (this.uncheckedNodes.length == 0) {\n      node = this.root\n    } else {\n      node = this.uncheckedNodes[this.uncheckedNodes.length - 1].child\n    }\n  \n    for (var i = commonPrefix; i < word.length; i++) {\n      var nextNode = new lunr.TokenSet,\n          char = word[i]\n  \n      node.edges[char] = nextNode\n  \n      this.uncheckedNodes.push({\n        parent: node,\n        char: char,\n        child: nextNode\n      })\n  \n      node = nextNode\n    }\n  \n    node.final = true\n    this.previousWord = word\n  }\n  \n  lunr.TokenSet.Builder.prototype.finish = function () {\n    this.minimize(0)\n  }\n  \n  lunr.TokenSet.Builder.prototype.minimize = function (downTo) {\n    for (var i = this.uncheckedNodes.length - 1; i >= downTo; i--) {\n      var node = this.uncheckedNodes[i],\n          childKey = node.child.toString()\n  \n      if (childKey in this.minimizedNodes) {\n        node.parent.edges[node.char] = this.minimizedNodes[childKey]\n      } else {\n        // Cache the key for this node since\n        // we know it can't change anymore\n        node.child._str = childKey\n  \n        this.minimizedNodes[childKey] = node.child\n      }\n  \n      this.uncheckedNodes.pop()\n    }\n  }\n  /*!\n   * lunr.Index\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * An index contains the built index of all documents and provides a query interface\n   * to the index.\n   *\n   * Usually instances of lunr.Index will not be created using this constructor, instead\n   * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\n   * used to load previously built and serialized indexes.\n   *\n   * @constructor\n   * @param {Object} attrs - The attributes of the built search index.\n   * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\n   * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\n   * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\n   * @param {string[]} attrs.fields - The names of indexed document fields.\n   * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\n   */\n  lunr.Index = function (attrs) {\n    this.invertedIndex = attrs.invertedIndex\n    this.fieldVectors = attrs.fieldVectors\n    this.tokenSet = attrs.tokenSet\n    this.fields = attrs.fields\n    this.pipeline = attrs.pipeline\n  }\n  \n  /**\n   * A result contains details of a document matching a search query.\n   * @typedef {Object} lunr.Index~Result\n   * @property {string} ref - The reference of the document this result represents.\n   * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\n   * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\n   */\n  \n  /**\n   * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\n   * query language which itself is parsed into an instance of lunr.Query.\n   *\n   * For programmatically building queries it is advised to directly use lunr.Query, the query language\n   * is best used for human entered text rather than program generated text.\n   *\n   * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\n   * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\n   * or 'world', though those that contain both will rank higher in the results.\n   *\n   * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\n   * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\n   * wildcards will increase the number of documents that will be found but can also have a negative\n   * impact on query performance, especially with wildcards at the beginning of a term.\n   *\n   * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\n   * hello in the title field will match this query. Using a field not present in the index will lead\n   * to an error being thrown.\n   *\n   * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\n   * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\n   * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\n   * Avoid large values for edit distance to improve query performance.\n   *\n   * Each term also supports a presence modifier. By default a term's presence in document is optional, however\n   * this can be changed to either required or prohibited. For a term's presence to be required in a document the\n   * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\n   * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\n   * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\n   *\n   * To escape special characters the backslash character '\\' can be used, this allows searches to include\n   * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\n   * of attempting to apply a boost of 2 to the search term \"foo\".\n   *\n   * @typedef {string} lunr.Index~QueryString\n   * @example <caption>Simple single term query</caption>\n   * hello\n   * @example <caption>Multiple term query</caption>\n   * hello world\n   * @example <caption>term scoped to a field</caption>\n   * title:hello\n   * @example <caption>term with a boost of 10</caption>\n   * hello^10\n   * @example <caption>term with an edit distance of 2</caption>\n   * hello~2\n   * @example <caption>terms with presence modifiers</caption>\n   * -foo +bar baz\n   */\n  \n  /**\n   * Performs a search against the index using lunr query syntax.\n   *\n   * Results will be returned sorted by their score, the most relevant results\n   * will be returned first.  For details on how the score is calculated, please see\n   * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\n   *\n   * For more programmatic querying use lunr.Index#query.\n   *\n   * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\n   * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\n   * @returns {lunr.Index~Result[]}\n   */\n  lunr.Index.prototype.search = function (queryString) {\n    return this.query(function (query) {\n      var parser = new lunr.QueryParser(queryString, query)\n      parser.parse()\n    })\n  }\n  \n  /**\n   * A query builder callback provides a query object to be used to express\n   * the query to perform on the index.\n   *\n   * @callback lunr.Index~queryBuilder\n   * @param {lunr.Query} query - The query object to build up.\n   * @this lunr.Query\n   */\n  \n  /**\n   * Performs a query against the index using the yielded lunr.Query object.\n   *\n   * If performing programmatic queries against the index, this method is preferred\n   * over lunr.Index#search so as to avoid the additional query parsing overhead.\n   *\n   * A query object is yielded to the supplied function which should be used to\n   * express the query to be run against the index.\n   *\n   * Note that although this function takes a callback parameter it is _not_ an\n   * asynchronous operation, the callback is just yielded a query object to be\n   * customized.\n   *\n   * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\n   * @returns {lunr.Index~Result[]}\n   */\n  lunr.Index.prototype.query = function (fn) {\n    // for each query clause\n    // * process terms\n    // * expand terms from token set\n    // * find matching documents and metadata\n    // * get document vectors\n    // * score documents\n  \n    var query = new lunr.Query(this.fields),\n        matchingFields = Object.create(null),\n        queryVectors = Object.create(null),\n        termFieldCache = Object.create(null),\n        requiredMatches = Object.create(null),\n        prohibitedMatches = Object.create(null)\n  \n    /*\n     * To support field level boosts a query vector is created per\n     * field. An empty vector is eagerly created to support negated\n     * queries.\n     */\n    for (var i = 0; i < this.fields.length; i++) {\n      queryVectors[this.fields[i]] = new lunr.Vector\n    }\n  \n    fn.call(query, query)\n  \n    for (var i = 0; i < query.clauses.length; i++) {\n      /*\n       * Unless the pipeline has been disabled for this term, which is\n       * the case for terms with wildcards, we need to pass the clause\n       * term through the search pipeline. A pipeline returns an array\n       * of processed terms. Pipeline functions may expand the passed\n       * term, which means we may end up performing multiple index lookups\n       * for a single query term.\n       */\n      var clause = query.clauses[i],\n          terms = null,\n          clauseMatches = lunr.Set.complete\n  \n      if (clause.usePipeline) {\n        terms = this.pipeline.runString(clause.term, {\n          fields: clause.fields\n        })\n      } else {\n        terms = [clause.term]\n      }\n  \n      for (var m = 0; m < terms.length; m++) {\n        var term = terms[m]\n  \n        /*\n         * Each term returned from the pipeline needs to use the same query\n         * clause object, e.g. the same boost and or edit distance. The\n         * simplest way to do this is to re-use the clause object but mutate\n         * its term property.\n         */\n        clause.term = term\n  \n        /*\n         * From the term in the clause we create a token set which will then\n         * be used to intersect the indexes token set to get a list of terms\n         * to lookup in the inverted index\n         */\n        var termTokenSet = lunr.TokenSet.fromClause(clause),\n            expandedTerms = this.tokenSet.intersect(termTokenSet).toArray()\n  \n        /*\n         * If a term marked as required does not exist in the tokenSet it is\n         * impossible for the search to return any matches. We set all the field\n         * scoped required matches set to empty and stop examining any further\n         * clauses.\n         */\n        if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\n          for (var k = 0; k < clause.fields.length; k++) {\n            var field = clause.fields[k]\n            requiredMatches[field] = lunr.Set.empty\n          }\n  \n          break\n        }\n  \n        for (var j = 0; j < expandedTerms.length; j++) {\n          /*\n           * For each term get the posting and termIndex, this is required for\n           * building the query vector.\n           */\n          var expandedTerm = expandedTerms[j],\n              posting = this.invertedIndex[expandedTerm],\n              termIndex = posting._index\n  \n          for (var k = 0; k < clause.fields.length; k++) {\n            /*\n             * For each field that this query term is scoped by (by default\n             * all fields are in scope) we need to get all the document refs\n             * that have this term in that field.\n             *\n             * The posting is the entry in the invertedIndex for the matching\n             * term from above.\n             */\n            var field = clause.fields[k],\n                fieldPosting = posting[field],\n                matchingDocumentRefs = Object.keys(fieldPosting),\n                termField = expandedTerm + \"/\" + field,\n                matchingDocumentsSet = new lunr.Set(matchingDocumentRefs)\n  \n            /*\n             * if the presence of this term is required ensure that the matching\n             * documents are added to the set of required matches for this clause.\n             *\n             */\n            if (clause.presence == lunr.Query.presence.REQUIRED) {\n              clauseMatches = clauseMatches.union(matchingDocumentsSet)\n  \n              if (requiredMatches[field] === undefined) {\n                requiredMatches[field] = lunr.Set.complete\n              }\n            }\n  \n            /*\n             * if the presence of this term is prohibited ensure that the matching\n             * documents are added to the set of prohibited matches for this field,\n             * creating that set if it does not yet exist.\n             */\n            if (clause.presence == lunr.Query.presence.PROHIBITED) {\n              if (prohibitedMatches[field] === undefined) {\n                prohibitedMatches[field] = lunr.Set.empty\n              }\n  \n              prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet)\n  \n              /*\n               * Prohibited matches should not be part of the query vector used for\n               * similarity scoring and no metadata should be extracted so we continue\n               * to the next field\n               */\n              continue\n            }\n  \n            /*\n             * The query field vector is populated using the termIndex found for\n             * the term and a unit value with the appropriate boost applied.\n             * Using upsert because there could already be an entry in the vector\n             * for the term we are working with. In that case we just add the scores\n             * together.\n             */\n            queryVectors[field].upsert(termIndex, clause.boost, function (a, b) { return a + b })\n  \n            /**\n             * If we've already seen this term, field combo then we've already collected\n             * the matching documents and metadata, no need to go through all that again\n             */\n            if (termFieldCache[termField]) {\n              continue\n            }\n  \n            for (var l = 0; l < matchingDocumentRefs.length; l++) {\n              /*\n               * All metadata for this term/field/document triple\n               * are then extracted and collected into an instance\n               * of lunr.MatchData ready to be returned in the query\n               * results\n               */\n              var matchingDocumentRef = matchingDocumentRefs[l],\n                  matchingFieldRef = new lunr.FieldRef (matchingDocumentRef, field),\n                  metadata = fieldPosting[matchingDocumentRef],\n                  fieldMatch\n  \n              if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) {\n                matchingFields[matchingFieldRef] = new lunr.MatchData (expandedTerm, field, metadata)\n              } else {\n                fieldMatch.add(expandedTerm, field, metadata)\n              }\n  \n            }\n  \n            termFieldCache[termField] = true\n          }\n        }\n      }\n  \n      /**\n       * If the presence was required we need to update the requiredMatches field sets.\n       * We do this after all fields for the term have collected their matches because\n       * the clause terms presence is required in _any_ of the fields not _all_ of the\n       * fields.\n       */\n      if (clause.presence === lunr.Query.presence.REQUIRED) {\n        for (var k = 0; k < clause.fields.length; k++) {\n          var field = clause.fields[k]\n          requiredMatches[field] = requiredMatches[field].intersect(clauseMatches)\n        }\n      }\n    }\n  \n    /**\n     * Need to combine the field scoped required and prohibited\n     * matching documents into a global set of required and prohibited\n     * matches\n     */\n    var allRequiredMatches = lunr.Set.complete,\n        allProhibitedMatches = lunr.Set.empty\n  \n    for (var i = 0; i < this.fields.length; i++) {\n      var field = this.fields[i]\n  \n      if (requiredMatches[field]) {\n        allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field])\n      }\n  \n      if (prohibitedMatches[field]) {\n        allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field])\n      }\n    }\n  \n    var matchingFieldRefs = Object.keys(matchingFields),\n        results = [],\n        matches = Object.create(null)\n  \n    /*\n     * If the query is negated (contains only prohibited terms)\n     * we need to get _all_ fieldRefs currently existing in the\n     * index. This is only done when we know that the query is\n     * entirely prohibited terms to avoid any cost of getting all\n     * fieldRefs unnecessarily.\n     *\n     * Additionally, blank MatchData must be created to correctly\n     * populate the results.\n     */\n    if (query.isNegated()) {\n      matchingFieldRefs = Object.keys(this.fieldVectors)\n  \n      for (var i = 0; i < matchingFieldRefs.length; i++) {\n        var matchingFieldRef = matchingFieldRefs[i]\n        var fieldRef = lunr.FieldRef.fromString(matchingFieldRef)\n        matchingFields[matchingFieldRef] = new lunr.MatchData\n      }\n    }\n  \n    for (var i = 0; i < matchingFieldRefs.length; i++) {\n      /*\n       * Currently we have document fields that match the query, but we\n       * need to return documents. The matchData and scores are combined\n       * from multiple fields belonging to the same document.\n       *\n       * Scores are calculated by field, using the query vectors created\n       * above, and combined into a final document score using addition.\n       */\n      var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]),\n          docRef = fieldRef.docRef\n  \n      if (!allRequiredMatches.contains(docRef)) {\n        continue\n      }\n  \n      if (allProhibitedMatches.contains(docRef)) {\n        continue\n      }\n  \n      var fieldVector = this.fieldVectors[fieldRef],\n          score = queryVectors[fieldRef.fieldName].similarity(fieldVector),\n          docMatch\n  \n      if ((docMatch = matches[docRef]) !== undefined) {\n        docMatch.score += score\n        docMatch.matchData.combine(matchingFields[fieldRef])\n      } else {\n        var match = {\n          ref: docRef,\n          score: score,\n          matchData: matchingFields[fieldRef]\n        }\n        matches[docRef] = match\n        results.push(match)\n      }\n    }\n  \n    /*\n     * Sort the results objects by score, highest first.\n     */\n    return results.sort(function (a, b) {\n      return b.score - a.score\n    })\n  }\n  \n  /**\n   * Prepares the index for JSON serialization.\n   *\n   * The schema for this JSON blob will be described in a\n   * separate JSON schema file.\n   *\n   * @returns {Object}\n   */\n  lunr.Index.prototype.toJSON = function () {\n    var invertedIndex = Object.keys(this.invertedIndex)\n      .sort()\n      .map(function (term) {\n        return [term, this.invertedIndex[term]]\n      }, this)\n  \n    var fieldVectors = Object.keys(this.fieldVectors)\n      .map(function (ref) {\n        return [ref, this.fieldVectors[ref].toJSON()]\n      }, this)\n  \n    return {\n      version: lunr.version,\n      fields: this.fields,\n      fieldVectors: fieldVectors,\n      invertedIndex: invertedIndex,\n      pipeline: this.pipeline.toJSON()\n    }\n  }\n  \n  /**\n   * Loads a previously serialized lunr.Index\n   *\n   * @param {Object} serializedIndex - A previously serialized lunr.Index\n   * @returns {lunr.Index}\n   */\n  lunr.Index.load = function (serializedIndex) {\n    var attrs = {},\n        fieldVectors = {},\n        serializedVectors = serializedIndex.fieldVectors,\n        invertedIndex = {},\n        serializedInvertedIndex = serializedIndex.invertedIndex,\n        tokenSetBuilder = new lunr.TokenSet.Builder,\n        pipeline = lunr.Pipeline.load(serializedIndex.pipeline)\n  \n    if (serializedIndex.version != lunr.version) {\n      lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\")\n    }\n  \n    for (var i = 0; i < serializedVectors.length; i++) {\n      var tuple = serializedVectors[i],\n          ref = tuple[0],\n          elements = tuple[1]\n  \n      fieldVectors[ref] = new lunr.Vector(elements)\n    }\n  \n    for (var i = 0; i < serializedInvertedIndex.length; i++) {\n      var tuple = serializedInvertedIndex[i],\n          term = tuple[0],\n          posting = tuple[1]\n  \n      tokenSetBuilder.insert(term)\n      invertedIndex[term] = posting\n    }\n  \n    tokenSetBuilder.finish()\n  \n    attrs.fields = serializedIndex.fields\n  \n    attrs.fieldVectors = fieldVectors\n    attrs.invertedIndex = invertedIndex\n    attrs.tokenSet = tokenSetBuilder.root\n    attrs.pipeline = pipeline\n  \n    return new lunr.Index(attrs)\n  }\n  /*!\n   * lunr.Builder\n   * Copyright (C) 2018 Oliver Nightingale\n   */\n  \n  /**\n   * lunr.Builder performs indexing on a set of documents and\n   * returns instances of lunr.Index ready for querying.\n   *\n   * All configuration of the index is done via the builder, the\n   * fields to index, the document reference, the text processing\n   * pipeline and document scoring parameters are all set on the\n   * builder before indexing.\n   *\n   * @constructor\n   * @property {string} _ref - Internal reference to the document reference field.\n   * @property {string[]} _fields - Internal reference to the document fields to index.\n   * @property {object} invertedIndex - The inverted index maps terms to document fields.\n   * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\n   * @property {object} documentLengths - Keeps track of the length of documents added to the index.\n   * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\n   * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\n   * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\n   * @property {number} documentCount - Keeps track of the total number of documents indexed.\n   * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\n   * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\n   * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\n   * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\n   */\n  lunr.Builder = function () {\n    this._ref = \"id\"\n    this._fields = Object.create(null)\n    this._documents = Object.create(null)\n    this.invertedIndex = Object.create(null)\n    this.fieldTermFrequencies = {}\n    this.fieldLengths = {}\n    this.tokenizer = lunr.tokenizer\n    this.pipeline = new lunr.Pipeline\n    this.searchPipeline = new lunr.Pipeline\n    this.documentCount = 0\n    this._b = 0.75\n    this._k1 = 1.2\n    this.termIndex = 0\n    this.metadataWhitelist = []\n  }\n  \n  /**\n   * Sets the document field used as the document reference. Every document must have this field.\n   * The type of this field in the document should be a string, if it is not a string it will be\n   * coerced into a string by calling toString.\n   *\n   * The default ref is 'id'.\n   *\n   * The ref should _not_ be changed during indexing, it should be set before any documents are\n   * added to the index. Changing it during indexing can lead to inconsistent results.\n   *\n   * @param {string} ref - The name of the reference field in the document.\n   */\n  lunr.Builder.prototype.ref = function (ref) {\n    this._ref = ref\n  }\n  \n  /**\n   * A function that is used to extract a field from a document.\n   *\n   * Lunr expects a field to be at the top level of a document, if however the field\n   * is deeply nested within a document an extractor function can be used to extract\n   * the right field for indexing.\n   *\n   * @callback fieldExtractor\n   * @param {object} doc - The document being added to the index.\n   * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\n   * @example <caption>Extracting a nested field</caption>\n   * function (doc) { return doc.nested.field }\n   */\n  \n  /**\n   * Adds a field to the list of document fields that will be indexed. Every document being\n   * indexed should have this field. Null values for this field in indexed documents will\n   * not cause errors but will limit the chance of that document being retrieved by searches.\n   *\n   * All fields should be added before adding documents to the index. Adding fields after\n   * a document has been indexed will have no effect on already indexed documents.\n   *\n   * Fields can be boosted at build time. This allows terms within that field to have more\n   * importance when ranking search results. Use a field boost to specify that matches within\n   * one field are more important than other fields.\n   *\n   * @param {string} fieldName - The name of a field to index in all documents.\n   * @param {object} attributes - Optional attributes associated with this field.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\n   * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\n   * @throws {RangeError} fieldName cannot contain unsupported characters '/'\n   */\n  lunr.Builder.prototype.field = function (fieldName, attributes) {\n    if (/\\//.test(fieldName)) {\n      throw new RangeError (\"Field '\" + fieldName + \"' contains illegal character '/'\")\n    }\n  \n    this._fields[fieldName] = attributes || {}\n  }\n  \n  /**\n   * A parameter to tune the amount of field length normalisation that is applied when\n   * calculating relevance scores. A value of 0 will completely disable any normalisation\n   * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\n   * will be clamped to the range 0 - 1.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n  lunr.Builder.prototype.b = function (number) {\n    if (number < 0) {\n      this._b = 0\n    } else if (number > 1) {\n      this._b = 1\n    } else {\n      this._b = number\n    }\n  }\n  \n  /**\n   * A parameter that controls the speed at which a rise in term frequency results in term\n   * frequency saturation. The default value is 1.2. Setting this to a higher value will give\n   * slower saturation levels, a lower value will result in quicker saturation.\n   *\n   * @param {number} number - The value to set for this tuning parameter.\n   */\n  lunr.Builder.prototype.k1 = function (number) {\n    this._k1 = number\n  }\n  \n  /**\n   * Adds a document to the index.\n   *\n   * Before adding fields to the index the index should have been fully setup, with the document\n   * ref and all fields to index already having been specified.\n   *\n   * The document must have a field name as specified by the ref (by default this is 'id') and\n   * it should have all fields defined for indexing, though null or undefined values will not\n   * cause errors.\n   *\n   * Entire documents can be boosted at build time. Applying a boost to a document indicates that\n   * this document should rank higher in search results than other documents.\n   *\n   * @param {object} doc - The document to add to the index.\n   * @param {object} attributes - Optional attributes associated with this document.\n   * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\n   */\n  lunr.Builder.prototype.add = function (doc, attributes) {\n    var docRef = doc[this._ref],\n        fields = Object.keys(this._fields)\n  \n    this._documents[docRef] = attributes || {}\n    this.documentCount += 1\n  \n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i],\n          extractor = this._fields[fieldName].extractor,\n          field = extractor ? extractor(doc) : doc[fieldName],\n          tokens = this.tokenizer(field, {\n            fields: [fieldName]\n          }),\n          terms = this.pipeline.run(tokens),\n          fieldRef = new lunr.FieldRef (docRef, fieldName),\n          fieldTerms = Object.create(null)\n  \n      this.fieldTermFrequencies[fieldRef] = fieldTerms\n      this.fieldLengths[fieldRef] = 0\n  \n      // store the length of this field for this document\n      this.fieldLengths[fieldRef] += terms.length\n  \n      // calculate term frequencies for this field\n      for (var j = 0; j < terms.length; j++) {\n        var term = terms[j]\n  \n        if (fieldTerms[term] == undefined) {\n          fieldTerms[term] = 0\n        }\n  \n        fieldTerms[term] += 1\n  \n        // add to inverted index\n        // create an initial posting if one doesn't exist\n        if (this.invertedIndex[term] == undefined) {\n          var posting = Object.create(null)\n          posting[\"_index\"] = this.termIndex\n          this.termIndex += 1\n  \n          for (var k = 0; k < fields.length; k++) {\n            posting[fields[k]] = Object.create(null)\n          }\n  \n          this.invertedIndex[term] = posting\n        }\n  \n        // add an entry for this term/fieldName/docRef to the invertedIndex\n        if (this.invertedIndex[term][fieldName][docRef] == undefined) {\n          this.invertedIndex[term][fieldName][docRef] = Object.create(null)\n        }\n  \n        // store all whitelisted metadata about this token in the\n        // inverted index\n        for (var l = 0; l < this.metadataWhitelist.length; l++) {\n          var metadataKey = this.metadataWhitelist[l],\n              metadata = term.metadata[metadataKey]\n  \n          if (this.invertedIndex[term][fieldName][docRef][metadataKey] == undefined) {\n            this.invertedIndex[term][fieldName][docRef][metadataKey] = []\n          }\n  \n          this.invertedIndex[term][fieldName][docRef][metadataKey].push(metadata)\n        }\n      }\n  \n    }\n  }\n  \n  /**\n   * Calculates the average document length for this index\n   *\n   * @private\n   */\n  lunr.Builder.prototype.calculateAverageFieldLengths = function () {\n  \n    var fieldRefs = Object.keys(this.fieldLengths),\n        numberOfFields = fieldRefs.length,\n        accumulator = {},\n        documentsWithField = {}\n  \n    for (var i = 0; i < numberOfFields; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          field = fieldRef.fieldName\n  \n      documentsWithField[field] || (documentsWithField[field] = 0)\n      documentsWithField[field] += 1\n  \n      accumulator[field] || (accumulator[field] = 0)\n      accumulator[field] += this.fieldLengths[fieldRef]\n    }\n  \n    var fields = Object.keys(this._fields)\n  \n    for (var i = 0; i < fields.length; i++) {\n      var fieldName = fields[i]\n      accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName]\n    }\n  \n    this.averageFieldLength = accumulator\n  }\n  \n  /**\n   * Builds a vector space model of every document using lunr.Vector\n   *\n   * @private\n   */\n  lunr.Builder.prototype.createFieldVectors = function () {\n    var fieldVectors = {},\n        fieldRefs = Object.keys(this.fieldTermFrequencies),\n        fieldRefsLength = fieldRefs.length,\n        termIdfCache = Object.create(null)\n  \n    for (var i = 0; i < fieldRefsLength; i++) {\n      var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n          fieldName = fieldRef.fieldName,\n          fieldLength = this.fieldLengths[fieldRef],\n          fieldVector = new lunr.Vector,\n          termFrequencies = this.fieldTermFrequencies[fieldRef],\n          terms = Object.keys(termFrequencies),\n          termsLength = terms.length\n  \n  \n      var fieldBoost = this._fields[fieldName].boost || 1,\n          docBoost = this._documents[fieldRef.docRef].boost || 1\n  \n      for (var j = 0; j < termsLength; j++) {\n        var term = terms[j],\n            tf = termFrequencies[term],\n            termIndex = this.invertedIndex[term]._index,\n            idf, score, scoreWithPrecision\n  \n        if (termIdfCache[term] === undefined) {\n          idf = lunr.idf(this.invertedIndex[term], this.documentCount)\n          termIdfCache[term] = idf\n        } else {\n          idf = termIdfCache[term]\n        }\n  \n        score = idf * ((this._k1 + 1) * tf) / (this._k1 * (1 - this._b + this._b * (fieldLength / this.averageFieldLength[fieldName])) + tf)\n        score *= fieldBoost\n        score *= docBoost\n        scoreWithPrecision = Math.round(score * 1000) / 1000\n        // Converts 1.23456789 to 1.234.\n        // Reducing the precision so that the vectors take up less\n        // space when serialised. Doing it now so that they behave\n        // the same before and after serialisation. Also, this is\n        // the fastest approach to reducing a number's precision in\n        // JavaScript.\n  \n        fieldVector.insert(termIndex, scoreWithPrecision)\n      }\n  \n      fieldVectors[fieldRef] = fieldVector\n    }\n  \n    this.fieldVectors = fieldVectors\n  }\n  \n  /**\n   * Creates a token set of all tokens in the index using lunr.TokenSet\n   *\n   * @private\n   */\n  lunr.Builder.prototype.createTokenSet = function () {\n    this.tokenSet = lunr.TokenSet.fromArray(\n      Object.keys(this.invertedIndex).sort()\n    )\n  }\n  \n  /**\n   * Builds the index, creating an instance of lunr.Index.\n   *\n   * This completes the indexing process and should only be called\n   * once all documents have been added to the index.\n   *\n   * @returns {lunr.Index}\n   */\n  lunr.Builder.prototype.build = function () {\n    this.calculateAverageFieldLengths()\n    this.createFieldVectors()\n    this.createTokenSet()\n  \n    return new lunr.Index({\n      invertedIndex: this.invertedIndex,\n      fieldVectors: this.fieldVectors,\n      tokenSet: this.tokenSet,\n      fields: Object.keys(this._fields),\n      pipeline: this.searchPipeline\n    })\n  }\n  \n  /**\n   * Applies a plugin to the index builder.\n   *\n   * A plugin is a function that is called with the index builder as its context.\n   * Plugins can be used to customise or extend the behaviour of the index\n   * in some way. A plugin is just a function, that encapsulated the custom\n   * behaviour that should be applied when building the index.\n   *\n   * The plugin function will be called with the index builder as its argument, additional\n   * arguments can also be passed when calling use. The function will be called\n   * with the index builder as its context.\n   *\n   * @param {Function} plugin The plugin to apply.\n   */\n  lunr.Builder.prototype.use = function (fn) {\n    var args = Array.prototype.slice.call(arguments, 1)\n    args.unshift(this)\n    fn.apply(this, args)\n  }\n  /**\n   * Contains and collects metadata about a matching document.\n   * A single instance of lunr.MatchData is returned as part of every\n   * lunr.Index~Result.\n   *\n   * @constructor\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   * @property {object} metadata - A cloned collection of metadata associated with this document.\n   * @see {@link lunr.Index~Result}\n   */\n  lunr.MatchData = function (term, field, metadata) {\n    var clonedMetadata = Object.create(null),\n        metadataKeys = Object.keys(metadata || {})\n  \n    // Cloning the metadata to prevent the original\n    // being mutated during match data combination.\n    // Metadata is kept in an array within the inverted\n    // index so cloning the data can be done with\n    // Array#slice\n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i]\n      clonedMetadata[key] = metadata[key].slice()\n    }\n  \n    this.metadata = Object.create(null)\n  \n    if (term !== undefined) {\n      this.metadata[term] = Object.create(null)\n      this.metadata[term][field] = clonedMetadata\n    }\n  }\n  \n  /**\n   * An instance of lunr.MatchData will be created for every term that matches a\n   * document. However only one instance is required in a lunr.Index~Result. This\n   * method combines metadata from another instance of lunr.MatchData with this\n   * objects metadata.\n   *\n   * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\n   * @see {@link lunr.Index~Result}\n   */\n  lunr.MatchData.prototype.combine = function (otherMatchData) {\n    var terms = Object.keys(otherMatchData.metadata)\n  \n    for (var i = 0; i < terms.length; i++) {\n      var term = terms[i],\n          fields = Object.keys(otherMatchData.metadata[term])\n  \n      if (this.metadata[term] == undefined) {\n        this.metadata[term] = Object.create(null)\n      }\n  \n      for (var j = 0; j < fields.length; j++) {\n        var field = fields[j],\n            keys = Object.keys(otherMatchData.metadata[term][field])\n  \n        if (this.metadata[term][field] == undefined) {\n          this.metadata[term][field] = Object.create(null)\n        }\n  \n        for (var k = 0; k < keys.length; k++) {\n          var key = keys[k]\n  \n          if (this.metadata[term][field][key] == undefined) {\n            this.metadata[term][field][key] = otherMatchData.metadata[term][field][key]\n          } else {\n            this.metadata[term][field][key] = this.metadata[term][field][key].concat(otherMatchData.metadata[term][field][key])\n          }\n  \n        }\n      }\n    }\n  }\n  \n  /**\n   * Add metadata for a term/field pair to this instance of match data.\n   *\n   * @param {string} term - The term this match data is associated with\n   * @param {string} field - The field in which the term was found\n   * @param {object} metadata - The metadata recorded about this term in this field\n   */\n  lunr.MatchData.prototype.add = function (term, field, metadata) {\n    if (!(term in this.metadata)) {\n      this.metadata[term] = Object.create(null)\n      this.metadata[term][field] = metadata\n      return\n    }\n  \n    if (!(field in this.metadata[term])) {\n      this.metadata[term][field] = metadata\n      return\n    }\n  \n    var metadataKeys = Object.keys(metadata)\n  \n    for (var i = 0; i < metadataKeys.length; i++) {\n      var key = metadataKeys[i]\n  \n      if (key in this.metadata[term][field]) {\n        this.metadata[term][field][key] = this.metadata[term][field][key].concat(metadata[key])\n      } else {\n        this.metadata[term][field][key] = metadata[key]\n      }\n    }\n  }\n  /**\n   * A lunr.Query provides a programmatic way of defining queries to be performed\n   * against a {@link lunr.Index}.\n   *\n   * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\n   * so the query object is pre-initialized with the right index fields.\n   *\n   * @constructor\n   * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\n   * @property {string[]} allFields - An array of all available fields in a lunr.Index.\n   */\n  lunr.Query = function (allFields) {\n    this.clauses = []\n    this.allFields = allFields\n  }\n  \n  /**\n   * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\n   *\n   * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\n   * concatenation.\n   *\n   * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\n   *\n   * @constant\n   * @default\n   * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\n   * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\n   * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with trailing wildcard</caption>\n   * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\n   * @example <caption>query term with leading and trailing wildcard</caption>\n   * query.term('foo', {\n   *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\n   * })\n   */\n  \n  lunr.Query.wildcard = new String (\"*\")\n  lunr.Query.wildcard.NONE = 0\n  lunr.Query.wildcard.LEADING = 1\n  lunr.Query.wildcard.TRAILING = 2\n  \n  /**\n   * Constants for indicating what kind of presence a term must have in matching documents.\n   *\n   * @constant\n   * @enum {number}\n   * @see lunr.Query~Clause\n   * @see lunr.Query#clause\n   * @see lunr.Query#term\n   * @example <caption>query term with required presence</caption>\n   * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\n   */\n  lunr.Query.presence = {\n    /**\n     * Term's presence in a document is optional, this is the default value.\n     */\n    OPTIONAL: 1,\n  \n    /**\n     * Term's presence in a document is required, documents that do not contain\n     * this term will not be returned.\n     */\n    REQUIRED: 2,\n  \n    /**\n     * Term's presence in a document is prohibited, documents that do contain\n     * this term will not be returned.\n     */\n    PROHIBITED: 3\n  }\n  \n  /**\n   * A single clause in a {@link lunr.Query} contains a term and details on how to\n   * match that term against a {@link lunr.Index}.\n   *\n   * @typedef {Object} lunr.Query~Clause\n   * @property {string[]} fields - The fields in an index this clause should be matched against.\n   * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\n   * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\n   * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\n   * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\n   * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\n   */\n  \n  /**\n   * Adds a {@link lunr.Query~Clause} to this query.\n   *\n   * Unless the clause contains the fields to be matched all fields will be matched. In addition\n   * a default boost of 1 is applied to the clause.\n   *\n   * @param {lunr.Query~Clause} clause - The clause to add to this query.\n   * @see lunr.Query~Clause\n   * @returns {lunr.Query}\n   */\n  lunr.Query.prototype.clause = function (clause) {\n    if (!('fields' in clause)) {\n      clause.fields = this.allFields\n    }\n  \n    if (!('boost' in clause)) {\n      clause.boost = 1\n    }\n  \n    if (!('usePipeline' in clause)) {\n      clause.usePipeline = true\n    }\n  \n    if (!('wildcard' in clause)) {\n      clause.wildcard = lunr.Query.wildcard.NONE\n    }\n  \n    if ((clause.wildcard & lunr.Query.wildcard.LEADING) && (clause.term.charAt(0) != lunr.Query.wildcard)) {\n      clause.term = \"*\" + clause.term\n    }\n  \n    if ((clause.wildcard & lunr.Query.wildcard.TRAILING) && (clause.term.slice(-1) != lunr.Query.wildcard)) {\n      clause.term = \"\" + clause.term + \"*\"\n    }\n  \n    if (!('presence' in clause)) {\n      clause.presence = lunr.Query.presence.OPTIONAL\n    }\n  \n    this.clauses.push(clause)\n  \n    return this\n  }\n  \n  /**\n   * A negated query is one in which every clause has a presence of\n   * prohibited. These queries require some special processing to return\n   * the expected results.\n   *\n   * @returns boolean\n   */\n  lunr.Query.prototype.isNegated = function () {\n    for (var i = 0; i < this.clauses.length; i++) {\n      if (this.clauses[i].presence != lunr.Query.presence.PROHIBITED) {\n        return false\n      }\n    }\n  \n    return true\n  }\n  \n  /**\n   * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\n   * to the list of clauses that make up this query.\n   *\n   * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\n   * to a token or token-like string should be done before calling this method.\n   *\n   * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\n   * array, each term in the array will share the same options.\n   *\n   * @param {object|object[]} term - The term(s) to add to the query.\n   * @param {object} [options] - Any additional properties to add to the query clause.\n   * @returns {lunr.Query}\n   * @see lunr.Query#clause\n   * @see lunr.Query~Clause\n   * @example <caption>adding a single term to a query</caption>\n   * query.term(\"foo\")\n   * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\n   * query.term(\"foo\", {\n   *   fields: [\"title\"],\n   *   boost: 10,\n   *   wildcard: lunr.Query.wildcard.TRAILING\n   * })\n   * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\n   * query.term(lunr.tokenizer(\"foo bar\"))\n   */\n  lunr.Query.prototype.term = function (term, options) {\n    if (Array.isArray(term)) {\n      term.forEach(function (t) { this.term(t, lunr.utils.clone(options)) }, this)\n      return this\n    }\n  \n    var clause = options || {}\n    clause.term = term.toString()\n  \n    this.clause(clause)\n  \n    return this\n  }\n  lunr.QueryParseError = function (message, start, end) {\n    this.name = \"QueryParseError\"\n    this.message = message\n    this.start = start\n    this.end = end\n  }\n  \n  lunr.QueryParseError.prototype = new Error\n  lunr.QueryLexer = function (str) {\n    this.lexemes = []\n    this.str = str\n    this.length = str.length\n    this.pos = 0\n    this.start = 0\n    this.escapeCharPositions = []\n  }\n  \n  lunr.QueryLexer.prototype.run = function () {\n    var state = lunr.QueryLexer.lexText\n  \n    while (state) {\n      state = state(this)\n    }\n  }\n  \n  lunr.QueryLexer.prototype.sliceString = function () {\n    var subSlices = [],\n        sliceStart = this.start,\n        sliceEnd = this.pos\n  \n    for (var i = 0; i < this.escapeCharPositions.length; i++) {\n      sliceEnd = this.escapeCharPositions[i]\n      subSlices.push(this.str.slice(sliceStart, sliceEnd))\n      sliceStart = sliceEnd + 1\n    }\n  \n    subSlices.push(this.str.slice(sliceStart, this.pos))\n    this.escapeCharPositions.length = 0\n  \n    return subSlices.join('')\n  }\n  \n  lunr.QueryLexer.prototype.emit = function (type) {\n    this.lexemes.push({\n      type: type,\n      str: this.sliceString(),\n      start: this.start,\n      end: this.pos\n    })\n  \n    this.start = this.pos\n  }\n  \n  lunr.QueryLexer.prototype.escapeCharacter = function () {\n    this.escapeCharPositions.push(this.pos - 1)\n    this.pos += 1\n  }\n  \n  lunr.QueryLexer.prototype.next = function () {\n    if (this.pos >= this.length) {\n      return lunr.QueryLexer.EOS\n    }\n  \n    var char = this.str.charAt(this.pos)\n    this.pos += 1\n    return char\n  }\n  \n  lunr.QueryLexer.prototype.width = function () {\n    return this.pos - this.start\n  }\n  \n  lunr.QueryLexer.prototype.ignore = function () {\n    if (this.start == this.pos) {\n      this.pos += 1\n    }\n  \n    this.start = this.pos\n  }\n  \n  lunr.QueryLexer.prototype.backup = function () {\n    this.pos -= 1\n  }\n  \n  lunr.QueryLexer.prototype.acceptDigitRun = function () {\n    var char, charCode\n  \n    do {\n      char = this.next()\n      charCode = char.charCodeAt(0)\n    } while (charCode > 47 && charCode < 58)\n  \n    if (char != lunr.QueryLexer.EOS) {\n      this.backup()\n    }\n  }\n  \n  lunr.QueryLexer.prototype.more = function () {\n    return this.pos < this.length\n  }\n  \n  lunr.QueryLexer.EOS = 'EOS'\n  lunr.QueryLexer.FIELD = 'FIELD'\n  lunr.QueryLexer.TERM = 'TERM'\n  lunr.QueryLexer.EDIT_DISTANCE = 'EDIT_DISTANCE'\n  lunr.QueryLexer.BOOST = 'BOOST'\n  lunr.QueryLexer.PRESENCE = 'PRESENCE'\n  \n  lunr.QueryLexer.lexField = function (lexer) {\n    lexer.backup()\n    lexer.emit(lunr.QueryLexer.FIELD)\n    lexer.ignore()\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexTerm = function (lexer) {\n    if (lexer.width() > 1) {\n      lexer.backup()\n      lexer.emit(lunr.QueryLexer.TERM)\n    }\n  \n    lexer.ignore()\n  \n    if (lexer.more()) {\n      return lunr.QueryLexer.lexText\n    }\n  }\n  \n  lunr.QueryLexer.lexEditDistance = function (lexer) {\n    lexer.ignore()\n    lexer.acceptDigitRun()\n    lexer.emit(lunr.QueryLexer.EDIT_DISTANCE)\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexBoost = function (lexer) {\n    lexer.ignore()\n    lexer.acceptDigitRun()\n    lexer.emit(lunr.QueryLexer.BOOST)\n    return lunr.QueryLexer.lexText\n  }\n  \n  lunr.QueryLexer.lexEOS = function (lexer) {\n    if (lexer.width() > 0) {\n      lexer.emit(lunr.QueryLexer.TERM)\n    }\n  }\n  \n  // This matches the separator used when tokenising fields\n  // within a document. These should match otherwise it is\n  // not possible to search for some tokens within a document.\n  //\n  // It is possible for the user to change the separator on the\n  // tokenizer so it _might_ clash with any other of the special\n  // characters already used within the search string, e.g. :.\n  //\n  // This means that it is possible to change the separator in\n  // such a way that makes some words unsearchable using a search\n  // string.\n  lunr.QueryLexer.termSeparator = lunr.tokenizer.separator\n  \n  lunr.QueryLexer.lexText = function (lexer) {\n    while (true) {\n      var char = lexer.next()\n  \n      if (char == lunr.QueryLexer.EOS) {\n        return lunr.QueryLexer.lexEOS\n      }\n  \n      // Escape character is '\\'\n      if (char.charCodeAt(0) == 92) {\n        lexer.escapeCharacter()\n        continue\n      }\n  \n      if (char == \":\") {\n        return lunr.QueryLexer.lexField\n      }\n  \n      if (char == \"~\") {\n        lexer.backup()\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM)\n        }\n        return lunr.QueryLexer.lexEditDistance\n      }\n  \n      if (char == \"^\") {\n        lexer.backup()\n        if (lexer.width() > 0) {\n          lexer.emit(lunr.QueryLexer.TERM)\n        }\n        return lunr.QueryLexer.lexBoost\n      }\n  \n      // \"+\" indicates term presence is required\n      // checking for length to ensure that only\n      // leading \"+\" are considered\n      if (char == \"+\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE)\n        return lunr.QueryLexer.lexText\n      }\n  \n      // \"-\" indicates term presence is prohibited\n      // checking for length to ensure that only\n      // leading \"-\" are considered\n      if (char == \"-\" && lexer.width() === 1) {\n        lexer.emit(lunr.QueryLexer.PRESENCE)\n        return lunr.QueryLexer.lexText\n      }\n  \n      if (char.match(lunr.QueryLexer.termSeparator)) {\n        return lunr.QueryLexer.lexTerm\n      }\n    }\n  }\n  \n  lunr.QueryParser = function (str, query) {\n    this.lexer = new lunr.QueryLexer (str)\n    this.query = query\n    this.currentClause = {}\n    this.lexemeIdx = 0\n  }\n  \n  lunr.QueryParser.prototype.parse = function () {\n    this.lexer.run()\n    this.lexemes = this.lexer.lexemes\n  \n    var state = lunr.QueryParser.parseClause\n  \n    while (state) {\n      state = state(this)\n    }\n  \n    return this.query\n  }\n  \n  lunr.QueryParser.prototype.peekLexeme = function () {\n    return this.lexemes[this.lexemeIdx]\n  }\n  \n  lunr.QueryParser.prototype.consumeLexeme = function () {\n    var lexeme = this.peekLexeme()\n    this.lexemeIdx += 1\n    return lexeme\n  }\n  \n  lunr.QueryParser.prototype.nextClause = function () {\n    var completedClause = this.currentClause\n    this.query.clause(completedClause)\n    this.currentClause = {}\n  }\n  \n  lunr.QueryParser.parseClause = function (parser) {\n    var lexeme = parser.peekLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    switch (lexeme.type) {\n      case lunr.QueryLexer.PRESENCE:\n        return lunr.QueryParser.parsePresence\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expected either a field or a term, found \" + lexeme.type\n  \n        if (lexeme.str.length >= 1) {\n          errorMessage += \" with value '\" + lexeme.str + \"'\"\n        }\n  \n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parsePresence = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    switch (lexeme.str) {\n      case \"-\":\n        parser.currentClause.presence = lunr.Query.presence.PROHIBITED\n        break\n      case \"+\":\n        parser.currentClause.presence = lunr.Query.presence.REQUIRED\n        break\n      default:\n        var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\"\n        throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term or field, found nothing\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.FIELD:\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseField = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    if (parser.query.allFields.indexOf(lexeme.str) == -1) {\n      var possibleFields = parser.query.allFields.map(function (f) { return \"'\" + f + \"'\" }).join(', '),\n          errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields\n  \n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.fields = [lexeme.str]\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      var errorMessage = \"expecting term, found nothing\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        return lunr.QueryParser.parseTerm\n      default:\n        var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseTerm = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    parser.currentClause.term = lexeme.str.toLowerCase()\n  \n    if (lexeme.str.indexOf(\"*\") != -1) {\n      parser.currentClause.usePipeline = false\n    }\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseEditDistance = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    var editDistance = parseInt(lexeme.str, 10)\n  \n    if (isNaN(editDistance)) {\n      var errorMessage = \"edit distance must be numeric\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.editDistance = editDistance\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n  lunr.QueryParser.parseBoost = function (parser) {\n    var lexeme = parser.consumeLexeme()\n  \n    if (lexeme == undefined) {\n      return\n    }\n  \n    var boost = parseInt(lexeme.str, 10)\n  \n    if (isNaN(boost)) {\n      var errorMessage = \"boost must be numeric\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n    }\n  \n    parser.currentClause.boost = boost\n  \n    var nextLexeme = parser.peekLexeme()\n  \n    if (nextLexeme == undefined) {\n      parser.nextClause()\n      return\n    }\n  \n    switch (nextLexeme.type) {\n      case lunr.QueryLexer.TERM:\n        parser.nextClause()\n        return lunr.QueryParser.parseTerm\n      case lunr.QueryLexer.FIELD:\n        parser.nextClause()\n        return lunr.QueryParser.parseField\n      case lunr.QueryLexer.EDIT_DISTANCE:\n        return lunr.QueryParser.parseEditDistance\n      case lunr.QueryLexer.BOOST:\n        return lunr.QueryParser.parseBoost\n      case lunr.QueryLexer.PRESENCE:\n        parser.nextClause()\n        return lunr.QueryParser.parsePresence\n      default:\n        var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n        throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n    }\n  }\n  \n    /**\n     * export the module via AMD, CommonJS or as a browser global\n     * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n     */\n    ;(function (root, factory) {\n      if (typeof define === 'function' && define.amd) {\n        // AMD. Register as an anonymous module.\n        define(factory)\n      } else if (typeof exports === 'object') {\n        /**\n         * Node. Does not work with strict CommonJS, but\n         * only CommonJS-like enviroments that support module.exports,\n         * like Node.\n         */\n        module.exports = factory()\n      } else {\n        // Browser globals (root is window)\n        root.lunr = factory()\n      }\n    }(this, function () {\n      /**\n       * Just return a value to define the module export.\n       * This example returns an object, but the module\n       * can return a function as the exported value.\n       */\n      return lunr\n    }))\n  })();","document.addEventListener('DOMContentLoaded', function () {\n  var searchButton = document.querySelector('.mdc-icon-button.search')\n  var searchCancelButton = document.querySelector('.mdc-icon-button.search-arrow-back')\n  var searchClearButton = document.querySelector('.mdc-icon-button.search-clear-query')\n\n  function clearSearch() {\n    var searchInput = document.getElementById('search-input')\n    searchInput.value = '';\n    searchInput.dispatchEvent(new KeyboardEvent('keydown')); // trigger rerender of results\n  }\n\n  function enterOrSpacebarPressed(e) {\n    // Need both, 'keyCode' and 'which' to work in all browsers.\n    var code = e.keyCode || e.which;\n    var enterKey = 13;\n    var spaceKey = 32;\n\n    return (code === enterKey || code === spaceKey);\n  }\n\n  function toggleSearch() {\n    var mainContainer = document.querySelector('main')\n    var navContainer = document.querySelector('div.nav-container')\n    var searchResult = document.querySelector('.search-result-dropdown-menu')\n    var toolbarContainer = document.querySelector('.toolbar')\n    if(searchResult.classList.contains('hide')){\n      searchResult.classList.remove('hide')\n      mainContainer.classList.add('hide')\n      navContainer.classList.add('hide')\n      toolbarContainer.classList.add('hide')\n    } else{\n      searchResult.classList.add('hide')\n      mainContainer.classList.remove('hide')\n\n      // Toolbar should stay hidden on desktop and navbar should stay hidden on mobile.\n      if (window.innerWidth > 1024) {\n        navContainer.classList.remove('hide')\n      } else {\n        toolbarContainer.classList.remove('hide')\n      }\n    }\n\n    var regularTopBar = document.querySelector('.mdc-top-app-bar__row')\n    var searchTopBar = document.querySelector('.mdc-top-app-bar__row.sdp-top-app-bar__search')\n    if(regularTopBar.classList.contains('hide')){\n      regularTopBar.classList.remove('hide')\n      searchTopBar.classList.add('hide')\n    } else{\n      regularTopBar.classList.add('hide')\n      searchTopBar.classList.remove('hide')\n    }\n  }\n\n  // Add event listeners to search icon\n  searchButton.addEventListener('click', toggleSearch)\n  searchButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      toggleSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchButton.addEventListener('ontouchstart', toggleSearch)\n  }\n\n  // Add event listeners to search back/cancel icon\n  searchCancelButton.addEventListener('click', toggleSearch)\n  searchCancelButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      toggleSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchCancelButton.addEventListener('ontouchstart', toggleSearch)\n  }\n\n  // Add event listeners to clear search button\n  searchClearButton.addEventListener('click', clearSearch)\n  searchClearButton.addEventListener('keypress', function (e) {\n    if (enterOrSpacebarPressed(e)) {\n      clearSearch()\n    }\n  })\n  if ('ontouchstart' in window) {\n    searchClearButton.addEventListener('ontouchstart', clearSearch)\n  }\n});\n\n\n/* eslint-env browser */\nwindow.antoraLunr = (function (lunr) {\n  var searchInput = document.getElementById('search-input')\n  var searchResult = document.createElement('div')\n  var body = document.querySelector('.body')\n  searchResult.classList.add('search-result-dropdown-menu')\n  searchResult.classList.add('hide')\n  body.insertBefore(searchResult, body.firstChild)\n\n  function highlightText (doc, position) {\n    var hits = []\n    var start = position[0]\n    var length = position[1]\n\n    var text = doc.text\n    var highlightSpan = document.createElement('span')\n    highlightSpan.classList.add('search-result-highlight')\n    highlightSpan.innerText = text.substr(start, length)\n\n    var end = start + length\n    var textEnd = text.length - 1\n    var contextOffset = 15\n    var contextAfter = end + contextOffset > textEnd ? textEnd : end + contextOffset\n    var contextBefore = start - contextOffset < 0 ? 0 : start - contextOffset\n    if (start === 0 && end === textEnd) {\n      hits.push(highlightSpan)\n    } else if (start === 0) {\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(text.substr(end, contextAfter)))\n    } else if (end === textEnd) {\n      hits.push(document.createTextNode(text.substr(0, start)))\n      hits.push(highlightSpan)\n    } else {\n      hits.push(document.createTextNode('...' + text.substr(contextBefore, start - contextBefore)))\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(text.substr(end, contextAfter - end) + '...'))\n    }\n    return hits\n  }\n\n  function highlightTitle (hash, doc, position) {\n    var hits = []\n    var start = position[0]\n    var length = position[1]\n\n    var highlightSpan = document.createElement('span')\n    highlightSpan.classList.add('search-result-highlight')\n    var title\n    if (hash) {\n      title = doc.titles.filter(function (item) {\n        return item.id === hash\n      })[0].text\n    } else {\n      title = doc.title\n    }\n    highlightSpan.innerText = title.substr(start, length)\n\n    var end = start + length\n    var titleEnd = title.length - 1\n    if (start === 0 && end === titleEnd) {\n      hits.push(highlightSpan)\n    } else if (start === 0) {\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(title.substr(length, titleEnd)))\n    } else if (end === titleEnd) {\n      hits.push(document.createTextNode(title.substr(0, start)))\n      hits.push(highlightSpan)\n    } else {\n      hits.push(document.createTextNode(title.substr(0, start)))\n      hits.push(highlightSpan)\n      hits.push(document.createTextNode(title.substr(end, titleEnd)))\n    }\n    return hits\n  }\n\n  function highlightHit (metadata, hash, doc) {\n    var hits = []\n    for (var token in metadata) {\n      var fields = metadata[token]\n      for (var field in fields) {\n        var positions = fields[field]\n        if (positions.position) {\n          var position = positions.position[0] // only higlight the first match\n          if (field === 'title') {\n            hits = highlightTitle(hash, doc, position)\n          } else if (field === 'text') {\n            hits = highlightText(doc, position)\n          }\n        }\n      }\n    }\n    return hits\n  }\n\n  function createSearchResult(result, store, searchResultDataset) {\n    result.forEach(function (item) {\n      var url = item.ref\n      var hash\n      if (url.includes('#')) {\n        hash = url.substring(url.indexOf('#') + 1)\n        url = url.replace('#' + hash, '')\n      }\n      var doc = store[url]\n      var metadata = item.matchData.metadata\n      var hits = highlightHit(metadata, hash, doc)\n      searchResultDataset.appendChild(createSearchResultItem(doc, item, hits))\n    })\n  }\n\n  function createSearchResultItem (doc, item, hits) {\n    var documentTitle = document.createElement('div')\n    documentTitle.classList.add('search-result-document-title')\n    documentTitle.innerText = doc.title\n    var documentHit = document.createElement('div')\n    documentHit.classList.add('search-result-document-hit')\n    var documentHitLink = document.createElement('a')\n    documentHitLink.href = item.ref\n    documentHit.appendChild(documentHitLink)\n    hits.forEach(function (hit) {\n      documentHitLink.appendChild(hit)\n    })\n    var searchResultItem = document.createElement('div')\n    searchResultItem.classList.add('search-result-item')\n    searchResultItem.appendChild(documentTitle)\n    searchResultItem.appendChild(documentHit)\n    return searchResultItem\n  }\n\n  function createNoResult (text) {\n    var searchResultItem = document.createElement('div')\n    searchResultItem.classList.add('search-result-item')\n    var documentHit = document.createElement('div')\n    documentHit.classList.add('search-result-document-hit')\n    var message = document.createElement('strong')\n    message.innerText = 'No results found for query \"' + text + '\"'\n    documentHit.appendChild(message)\n    searchResultItem.appendChild(documentHit)\n    return searchResultItem\n  }\n\n  function search (index, text) {\n    // execute an exact match search\n    var result = index.search(text)\n    if (result.length > 0) {\n      return result\n    }\n    // no result, use a begins with search\n    result = index.search(text + '*')\n    if (result.length > 0) {\n      return result\n    }\n    // no result, use a contains search\n    result = index.search('*' + text + '*')\n    return result\n  }\n\n  function searchIndex (index, store, text) {\n    // reset search result\n    while (searchResult.firstChild) {\n      searchResult.removeChild(searchResult.firstChild)\n    }\n    if (text.trim() === '') {\n      return\n    }\n    var result = search(index, text)\n    var searchResultDataset = document.createElement('div')\n    searchResultDataset.classList.add('search-result-dataset')\n    searchResult.appendChild(searchResultDataset)\n    if (result.length > 0) {\n      createSearchResult(result, store, searchResultDataset)\n    } else {\n      searchResultDataset.appendChild(createNoResult(text))\n    }\n  }\n\n  function debounce (func, wait, immediate) {\n    var timeout\n    return function () {\n      var context = this\n      var args = arguments\n      var later = function () {\n        timeout = null\n        if (!immediate) func.apply(context, args)\n      }\n      var callNow = immediate && !timeout\n      clearTimeout(timeout)\n      timeout = setTimeout(later, wait)\n      if (callNow) func.apply(context, args)\n    }\n  }\n\n  function init (data) {\n    var index = Object.assign({index: lunr.Index.load(data.index), store: data.store})\n    var search = debounce(function () {\n      searchIndex(index.index, index.store, searchInput.value)\n    }, 100)\n    // TODO listen to blur, focus and input events\n    searchInput.addEventListener('keydown', search)\n  }\n\n  return {\n    init: init,\n  }\n})(window.lunr)\n"]}